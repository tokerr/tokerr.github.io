<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>是滔不是涛</title>
  <icon>https://www.gravatar.com/avatar/3c2e7ddddb8b1987b870857a7f766c20</icon>
  <subtitle>nongyongtao</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://tokerr.github.io/"/>
  <updated>2020-04-19T06:50:18.542Z</updated>
  <id>https://tokerr.github.io/</id>
  
  <author>
    <name>nongyongtao</name>
    <email>nytom@foxmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>单例模式还可以用枚举来实现吗？</title>
    <link href="https://tokerr.github.io/2020/04/19/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%EF%BC%88singleton%EF%BC%89/"/>
    <id>https://tokerr.github.io/2020/04/19/单例模式（singleton）/</id>
    <published>2020-04-19T06:03:00.000Z</published>
    <updated>2020-04-19T06:50:18.542Z</updated>
    
    <content type="html"><![CDATA[<h2 id="单例模式（singleton）"><a href="#单例模式（singleton）" class="headerlink" title="单例模式（singleton）"></a>单例模式（singleton）</h2><h2 id="一、什么是单例模式？"><a href="#一、什么是单例模式？" class="headerlink" title="一、什么是单例模式？"></a>一、什么是单例模式？</h2><ul><li>确保内存当中一个类的实例对象只要一个</li></ul><h2 id="二、两种单例模式"><a href="#二、两种单例模式" class="headerlink" title="二、两种单例模式"></a>二、两种单例模式</h2><ul><li><h3 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h3><ul><li><p>步骤</p><ul><li><p>在单例类中定义与自己类型相同的常量，并初始化</p><ul><li>private static final SingletonClass INSTANCE= new SingletonClass();</li></ul></li><li><p>私有化单例类的构造方法</p></li><li>定义一个publish的getInstance方法，返回实例化的常量</li></ul></li><li><p>特点</p><ul><li>在类初始化阶段就完成了单例对象的初始化</li><li>不存在多线程安全问题</li></ul></li></ul></li></ul><a id="more"></a><ul><li><h3 id="懒汉式"><a href="#懒汉式" class="headerlink" title="懒汉式"></a>懒汉式</h3><ul><li><p>特点</p><ul><li>在第一次调用getInstance方法的时候才会初始化单例对象，这也是与‘饿汉式’的区别。</li></ul></li><li><p>实现步骤</p><ul><li><p>单例类中定义一个与自己类型相同的静态变量，不初始化</p><ul><li>private static SIngletonClass INSTANCE;</li></ul></li><li>同样需要私有化单例类的构造方法</li><li>实现getInstance方法</li></ul></li></ul></li><li><h4 id="实现方式一"><a href="#实现方式一" class="headerlink" title="实现方式一"></a>实现方式一</h4></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SIngletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line"><span class="keyword">if</span>(INSTANCE == <span class="keyword">null</span>)&#123;</div><div class="line"> INSTANCE=<span class="keyword">new</span> SingletonClass();</div><div class="line">&#125;</div><div class="line"><span class="keyword">return</span> INSTANCE;</div><div class="line">&#125;</div></pre></td></tr></table></figure><ul><li><p>存在的问题</p><ul><li>存在多线程安全的问题，可能两个线程分别得到不同的实例</li></ul></li><li><h4 id="实现方式二：synchronized"><a href="#实现方式二：synchronized" class="headerlink" title="实现方式二：synchronized"></a>实现方式二：synchronized</h4><ul><li>在方式一的基础上，给getInstance方法加synchronized关键字</li><li><p>存在的问题</p><ul><li>解决了方式一的多线程安全问题，但是会大大降低运行效率</li></ul></li></ul></li><li><h4 id="实现方式三"><a href="#实现方式三" class="headerlink" title="实现方式三"></a>实现方式三</h4></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SIngletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line"><span class="keyword">if</span>( INSTANCE == <span class="keyword">null</span>)&#123;</div><div class="line"> <span class="keyword">synchronized</span>(SIngletonClass.class)&#123;</div><div class="line">  INSTANCE=<span class="keyword">new</span> SIngletonClass();</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">return</span> INSTANCE;</div><div class="line">&#125;</div></pre></td></tr></table></figure><ul><li><p>缺陷：同样有多线程安全问题</p></li><li><h4 id="实现方式四：双重判断加锁"><a href="#实现方式四：双重判断加锁" class="headerlink" title="实现方式四：双重判断加锁"></a>实现方式四：双重判断加锁</h4><ol><li>在方式三的基础上，在synchronized加锁之后，再次对INSTANCE做一次空判断，如果也为空，再初始化单例对象。</li><li>需要使用volatile关键字修饰变量，防止JIT对指令进行重排序<ul><li>private static volatile SingletonClass INSTANCE;</li></ul></li><li>多线程安全的问题得以解决</li></ol></li></ul><ul><li><h4 id="实现方式五：使用内部类的方式实现懒汉式"><a href="#实现方式五：使用内部类的方式实现懒汉式" class="headerlink" title="实现方式五：使用内部类的方式实现懒汉式"></a>实现方式五：使用内部类的方式实现懒汉式</h4><ul><li><p>指导思想：</p><ol><li>JVM“只对每个类加载一次”的原则，保证了多线程安全</li><li>JVM加载外部类时不会加载内部类，这样可以实现懒加载</li></ol></li><li><p>代码实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonClass</span></span>&#123;</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="title">SingletonClass</span><span class="params">()</span></span>&#123;&#125;;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">InnerClass</span></span>&#123;</div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> SingletonClass INSTANCE=<span class="keyword">new</span> SingletonClass();</div><div class="line">&#125; </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line"><span class="keyword">return</span> InnerClass.INSTANCE;</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></li></ul></li><li><h4 id="实现方式六：使用枚举类的方式实现懒汉式"><a href="#实现方式六：使用枚举类的方式实现懒汉式" class="headerlink" title="实现方式六：使用枚举类的方式实现懒汉式"></a>实现方式六：使用枚举类的方式实现懒汉式</h4></li><li><p>好处：</p><ul><li><p>不仅可以解决多线程安全问题，还可以防止反序列化。想其他几种单例的实现方式，都是可以通过反射的方式再次创建实例的。（枚举类没有构造方法）</p></li><li><p>是最简单和安全的实现方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">enum</span> SingletonClass&#123;</div><div class="line">INSTANCE;</div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span></span>&#123;&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></li></ul></li></ul><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>这里列出了7种单例的实现方式，并不是说一定要用哪一种，而是应该结合项目的情况，选择一种合适的实现方式。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;单例模式（singleton）&quot;&gt;&lt;a href=&quot;#单例模式（singleton）&quot; class=&quot;headerlink&quot; title=&quot;单例模式（singleton）&quot;&gt;&lt;/a&gt;单例模式（singleton）&lt;/h2&gt;&lt;h2 id=&quot;一、什么是单例模式？&quot;&gt;&lt;a href=&quot;#一、什么是单例模式？&quot; class=&quot;headerlink&quot; title=&quot;一、什么是单例模式？&quot;&gt;&lt;/a&gt;一、什么是单例模式？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确保内存当中一个类的实例对象只要一个&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;二、两种单例模式&quot;&gt;&lt;a href=&quot;#二、两种单例模式&quot; class=&quot;headerlink&quot; title=&quot;二、两种单例模式&quot;&gt;&lt;/a&gt;二、两种单例模式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;饿汉式&quot;&gt;&lt;a href=&quot;#饿汉式&quot; class=&quot;headerlink&quot; title=&quot;饿汉式&quot;&gt;&lt;/a&gt;饿汉式&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;步骤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在单例类中定义与自己类型相同的常量，并初始化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;private static final SingletonClass INSTANCE= new SingletonClass();&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;私有化单例类的构造方法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;定义一个publish的getInstance方法，返回实例化的常量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在类初始化阶段就完成了单例对象的初始化&lt;/li&gt;
&lt;li&gt;不存在多线程安全问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="https://tokerr.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="DesignPattern" scheme="https://tokerr.github.io/tags/DesignPattern/"/>
    
  </entry>
  
  <entry>
    <title>代理模式（Proxy）</title>
    <link href="https://tokerr.github.io/2020/04/12/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%EF%BC%88Proxy%EF%BC%89/"/>
    <id>https://tokerr.github.io/2020/04/12/代理模式（Proxy）/</id>
    <published>2020-04-12T08:44:00.000Z</published>
    <updated>2020-04-19T07:07:18.235Z</updated>
    
    <content type="html"><![CDATA[<h2 id="代理模式（Proxy）"><a href="#代理模式（Proxy）" class="headerlink" title="代理模式（Proxy）"></a>代理模式（Proxy）</h2><h2 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h2><ul><li>本文当中出现的代码均为伪代码，可参考文章末尾列出的项目代码地址。</li><li>假设我们的jar包使用maven进行管理。</li></ul><h2 id="二、模式定义"><a href="#二、模式定义" class="headerlink" title="二、模式定义"></a>二、模式定义</h2><ul><li>对访问（或请求）实现拦截和权限的控制，以决定是否需要执行用户的请求。常见的代理体现有Spring AOP、javax.servlet.Filter，与装饰模式很像</li></ul><h2 id="三、静态代理"><a href="#三、静态代理" class="headerlink" title="三、静态代理"></a>三、静态代理</h2><ul><li>使用继承的方式实现代理</li><li>使用组合的方式实现代理</li></ul><a id="more"></a><ul><li><p>缺点</p><ul><li>需要为不同的代理逻辑编写新的代理类</li></ul></li><li><p>角色</p><ul><li>代理</li><li>被代理对象</li></ul></li><li><p>类图</p><ul><li>代理和被代理对象都实现了同一个接口</li></ul></li></ul><h2 id="四、动态代理"><a href="#四、动态代理" class="headerlink" title="四、动态代理"></a>四、动态代理</h2><ul><li><h3 id="4-1JDK动态代理（接口代理）"><a href="#4-1JDK动态代理（接口代理）" class="headerlink" title="4.1JDK动态代理（接口代理）"></a>4.1JDK动态代理（接口代理）</h3></li><li><p>局限</p><ul><li>被代理类必须要实现至少一个接口</li><li>通过反编译查看生成的代理类，其实实现了指定的接口</li></ul></li><li><p>使用步骤</p><p>1.先定义一个接口</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Moveable</span></span>&#123;</div><div class="line">   <span class="function"><span class="keyword">void</span> <span class="title">move</span><span class="params">()</span></span>;</div><div class="line"> &#125;</div></pre></td></tr></table></figure><p>​        2.定义InvacationHandler</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> MyInvocationhandler implement InvocationHandler&#123;</div><div class="line">Moveable object;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">MyInvocationhandler</span><span class="params">(Moveable object)</span></span>&#123;</div><div class="line"> <span class="keyword">this</span>.object=object;</div><div class="line">&#125;</div><div class="line">  </div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method , Object[] args)</span></span>&#123;</div><div class="line"></div><div class="line">System.out.println(<span class="string">"执行之前！"</span>);</div><div class="line"><span class="keyword">return</span> method.invoke(object,args);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>​        3.通过JDK API生成接口的代理对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Proxy.newProxyInstance(MoveableSub.class.getClassLoader(), <span class="keyword">new</span> Class[]&#123;Moveable.class&#125;,<span class="keyword">new</span> MyInvocationHandler(<span class="keyword">new</span> MoveableSub()))</div></pre></td></tr></table></figure><p>​        4.可以通过设置，将生成的字节码文件（代理类）保存到本地    </p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">System.setProperty(<span class="string">"sun.misc.ProxyGenerator.saveGeneratedFiles"</span>,<span class="string">"true"</span>)</div></pre></td></tr></table></figure><ul><li><p>原理</p><ul><li><p>a&gt; 使用的是一个小而快的字节码工具ASM，生成代理类。因此，Java的动态语言特性其实就是ASM。</p></li><li><p>b&gt; ASM可以直接修改class二进制字节码。</p></li></ul></li></ul><ul><li><h3 id="4-2-Instrument动态代理"><a href="#4-2-Instrument动态代理" class="headerlink" title="4.2 Instrument动态代理"></a>4.2 Instrument动态代理</h3><ul><li>Instrument是一个类似ASM的工具</li><li>原理是在将二进制字节码加载到JVM之前，篡改二进制字节码</li></ul></li><li><h3 id="4-3-CGLIB动态代理（子类代理）"><a href="#4-3-CGLIB动态代理（子类代理）" class="headerlink" title="4.3 CGLIB动态代理（子类代理）"></a>4.3 CGLIB动态代理（子类代理）</h3></li><li><p>局限</p><ul><li>不能对final修饰的类生成代理子类，但是ASM可以突破这种语法上的限制。</li></ul></li><li><p>原理</p><ul><li>底层也是使用ASM工具。</li></ul></li><li><p>使用步骤</p><p>​    1.引入maven依赖</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/cglib/cglib --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cglib<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>cglib<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure><p>​        2.编写一个需要被代理的类Example</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Example</span></span>&#123;</div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line">   System.out.println(<span class="string">"我是被代理对象！"</span>);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>​        3.编写代理逻辑（拦截的逻辑）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> MyInterceptor implement MethodInterceptor &#123;</div><div class="line"></div><div class="line"><span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">intercept</span><span class="params">(Object o, Method method, Object[] objects, MethodProxy methodProxy)</span> <span class="keyword">throws</span> Throwable </span>&#123;</div><div class="line">        System.out.println(<span class="string">"这个是产生的代理对象："</span>+o.getClass().getName());    </div><div class="line">    Object invoke =methodProxy.invokeSuper(o,objects);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> invoke;</div><div class="line"></div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>​        4.Main逻辑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Enhancer enhancer=<span class="keyword">new</span> Enhancer();</div><div class="line">enhancer.setSuperClass(Example.class);</div><div class="line">enhancer.setInterceptor(<span class="keyword">new</span> MyInterceptor());</div><div class="line">Example proxy=enhancer.create();</div><div class="line">proxy.action();</div></pre></td></tr></table></figure><h2 id="五、常见案例"><a href="#五、常见案例" class="headerlink" title="五、常见案例"></a>五、常见案例</h2><ul><li>Spring AOP使用了JDK动态代理和CGLIB子类代理</li></ul><h2 id="六、疑问？"><a href="#六、疑问？" class="headerlink" title="六、疑问？"></a>六、疑问？</h2><ul><li><p>JDK动态代理中如果接口当中定义了多个方法，是否生成的代理类中这些方法是否都调用了InvocationHandler::invoke()方法？</p><ul><li>是的，可以通过查看生成代理类的反编译源代码可以知道，代理子类中所有的方法都调用了InvocationHandler::invoke()</li></ul></li></ul><h2 id="七、项目GitHub地址"><a href="#七、项目GitHub地址" class="headerlink" title="七、项目GitHub地址"></a>七、项目GitHub地址</h2><p>​    <a href="https://github.com/tokerr/designpatterns/tree/master/src/main/java/com/nyt/proxy" target="_blank" rel="external">https://github.com/tokerr/designpatterns/tree/master/src/main/java/com/nyt/proxy</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;代理模式（Proxy）&quot;&gt;&lt;a href=&quot;#代理模式（Proxy）&quot; class=&quot;headerlink&quot; title=&quot;代理模式（Proxy）&quot;&gt;&lt;/a&gt;代理模式（Proxy）&lt;/h2&gt;&lt;h2 id=&quot;一、说明&quot;&gt;&lt;a href=&quot;#一、说明&quot; class=&quot;headerlink&quot; title=&quot;一、说明&quot;&gt;&lt;/a&gt;一、说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;本文当中出现的代码均为伪代码，可参考文章末尾列出的项目代码地址。&lt;/li&gt;
&lt;li&gt;假设我们的jar包使用maven进行管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;二、模式定义&quot;&gt;&lt;a href=&quot;#二、模式定义&quot; class=&quot;headerlink&quot; title=&quot;二、模式定义&quot;&gt;&lt;/a&gt;二、模式定义&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;对访问（或请求）实现拦截和权限的控制，以决定是否需要执行用户的请求。常见的代理体现有Spring AOP、javax.servlet.Filter，与装饰模式很像&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;三、静态代理&quot;&gt;&lt;a href=&quot;#三、静态代理&quot; class=&quot;headerlink&quot; title=&quot;三、静态代理&quot;&gt;&lt;/a&gt;三、静态代理&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;使用继承的方式实现代理&lt;/li&gt;
&lt;li&gt;使用组合的方式实现代理&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="https://tokerr.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="CGLIB" scheme="https://tokerr.github.io/tags/CGLIB/"/>
    
      <category term="DesignPattern" scheme="https://tokerr.github.io/tags/DesignPattern/"/>
    
  </entry>
  
  <entry>
    <title>Java线程池ThreadPoolExecutor</title>
    <link href="https://tokerr.github.io/2020/02/16/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor/"/>
    <id>https://tokerr.github.io/2020/02/16/Java线程池ThreadPoolExecutor/</id>
    <published>2020-02-16T09:56:00.000Z</published>
    <updated>2020-04-19T07:29:12.832Z</updated>
    
    <content type="html"><![CDATA[<p>ThreadPoolExecutor是JDK中线程池的重要体现，JDK中的Executors工厂类，提供了不同ThreaPoolExecutor的构建方法，本章的内容主要是对ThreadPoolExecutor的内部结构、运行原理和重点参数做介绍。</p><h1 id="一、继承关系图"><a href="#一、继承关系图" class="headerlink" title="一、继承关系图"></a>一、继承关系图</h1><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/3/3.png" alt="类继承关系图"></p><p>#二、内部结构组成</p><ul><li>核心线程数</li><li>最大线程数工作队列</li><li>工作队列</li></ul><a id="more"></a><h1 id="三、构造参数说明"><a href="#三、构造参数说明" class="headerlink" title="三、构造参数说明"></a>三、构造参数说明</h1><ul><li><p>corePoolSize：核心线程的数量</p></li><li><p>maximumPoolSize：最大线程的数量</p></li><li><p>keepAliveTime：普通线程空间之后的存活时间</p></li><li><p>workQueue：类型为BlockingQueue的工作队列，用于保存等待执行任务的任务阻塞队列，有以下几种：</p><pre><code>1） ArrayBlockingQueue：是一个基于数组实现的有界阻塞队列  2）LinkedBlockingQueue：一个基于链表结构的无解阻塞队列  3）SynchronousQueue：一个不存储元素的阻塞队列，每一个插入操作都必须等待另一个线程调用移除操作，否则一直处于阻塞状态</code></pre></li><li><p>RejectedExecutionHandler：饱和策略</p><p>1）CallerRunPolicy：只用调用者所在的线程来处理任务</p><p>2）AbortPolicy（默认）：表示无法处理新任务时抛出异常<br>3）DiscardPolicy：不处理，直接丢弃<br>4）DiscardOldestPolicy：丢弃工作队列里最近的一个任务，并执行当前任务</p></li></ul><h1 id="四、内部运行原理"><a href="#四、内部运行原理" class="headerlink" title="四、内部运行原理"></a>四、内部运行原理</h1><p>​        线程池初始化完毕之后，内部先创建的线程属于核心线程<br>​        假设n为线程池中当前未完成的任务数量；因为有可能会出现类似CacheThreadPool的线程池（它的corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE） ，因此以下情况我们假设：corePoolSize &lt; maximumPoolSize。</p><ol><li>当n &lt; corePoolSize时，对于新提交的任务，将创建新的线程去执行<pre><code>执行这一步需要获取全局锁</code></pre></li><li>当n &gt;= corePoolSize时，对于提交的新任务，将任务保存到工作队列中，当核心线程中有执行完自己的任务，空闲下来后，则从工作队列中取出任务执行</li><li>如果工作队列任务已满，并且maximumPoolSize  &gt;= n &gt;时，对于新提交的任务，将创建新的线程去执行<pre><code>执行这一步需要获取全局锁        </code></pre></li><li>当 n &gt;maximumPoolSize 时，对于新提交的任务，将使用饱和策略进行处理</li></ol><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/3/2.png" alt="ThreadPoolExecutor执行图"></p><h1 id="五、向线程池提交任务的方法"><a href="#五、向线程池提交任务的方法" class="headerlink" title="五、向线程池提交任务的方法"></a>五、向线程池提交任务的方法</h1><ol><li>Executor::execute()方法<pre><code>这个方法用于提交不需要返回值的任务，所以无法判断任务是否被线程执行成功，输入的类型是Runnable    </code></pre></li><li>ExecutorService::submit()方法<pre><code>这个方法用于提交需要返回值的任务，方法可以输入Runnable或者Callable，方法返回一个Future类型的对象，通过Future::get()获取返回值</code></pre></li></ol><h1 id="六、关闭线程池"><a href="#六、关闭线程池" class="headerlink" title="六、关闭线程池"></a>六、关闭线程池</h1><p>​        调用shutdown()或shutdownNow()方法来关闭线程池，他们的原理都是遍历线程池中的工作线程，然后逐个调用interrupt()方法中断线程。两者的区别在于，shutdownNow()首先将线程池的状态设置为STOP，然后尝试停止所有的正在执行的或者暂停任务的线程，并返回等待执行任务的列表。shutdown()只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ThreadPoolExecutor是JDK中线程池的重要体现，JDK中的Executors工厂类，提供了不同ThreaPoolExecutor的构建方法，本章的内容主要是对ThreadPoolExecutor的内部结构、运行原理和重点参数做介绍。&lt;/p&gt;
&lt;h1 id=&quot;一、继承关系图&quot;&gt;&lt;a href=&quot;#一、继承关系图&quot; class=&quot;headerlink&quot; title=&quot;一、继承关系图&quot;&gt;&lt;/a&gt;一、继承关系图&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/pic/master/img/3/3.png&quot; alt=&quot;类继承关系图&quot;&gt;&lt;/p&gt;
&lt;p&gt;#二、内部结构组成&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心线程数&lt;/li&gt;
&lt;li&gt;最大线程数工作队列&lt;/li&gt;
&lt;li&gt;工作队列&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="线程池" scheme="https://tokerr.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    
      <category term="多线程" scheme="https://tokerr.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>事务隔离级别</title>
    <link href="https://tokerr.github.io/2019/12/01/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
    <id>https://tokerr.github.io/2019/12/01/事务隔离级别/</id>
    <published>2019-12-01T11:40:11.000Z</published>
    <updated>2019-12-01T12:40:40.639Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​    本文就Mysql数据库的事务进行阐述，包括事务的ACID特性、事务的隔离级别、事务隔离级别解决的问题、事务隔离级别的实现等内容。</p><h2 id="事务的四大特性"><a href="#事务的四大特性" class="headerlink" title="事务的四大特性"></a>事务的四大特性</h2><p>事务的ACID特性，也称为事务的四大特性，分别是：</p><ul><li>原子性（Atomicity）</li><li>一致性（Consistency）</li><li>隔离性（Isolation）</li><li>持久性（Durability）</li></ul><h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><p>​    事务的隔离性，当数据库中有多个事务执行的时候，就有可能出现“脏读”、“不可重复读”、“幻读”的问题，为了解决这些问题，于是就有了事务的“隔离级别”，事务的隔离级别包括：</p><ul><li>读未提交（Read uncommitted）</li><li>读已提交（Read committed）</li><li>可重复读（Repeatable read）</li><li>串行化（Serializable）</li></ul><a id="more"></a><p>这里一张图可以清楚的看到，不同的隔离级别下可能会出现的问题（X表示不会出现，V表示可能出现）。</p><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/2.jpg" alt="1.png"></p><p>​    从上往下，事务的隔离级别依次递增，隔离级别越高导致数据库的处理效率越低。所以，需要选择适合自己业务系统的隔离级别，Mysql默认的隔离级别是“可重复读”、Oracle默认的隔离级别是“读已提交”。在将Oracle的数据迁移到Mysql的时候，记得将Mysql的事务隔离级别设置成“读已提交”。Mysql可以通过如下的方式查看和修改事务隔离级别。</p><p>​    使用 show variables 方式查询事务隔离级别：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">show variables like &quot;transaction_isolation&quot;;</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/1.png" alt="查看事务隔离级别"></p><p>修改事务隔离级别，可以通过修改配置文件，或者在线的方式修改。</p><ol><li><p>修改配置，在系统全局生效：</p><p>在my.cnf中添加或者修改如下配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[mysqld]</div><div class="line">transaction_isolation=REPEATABLE-READ</div></pre></td></tr></table></figure><p>transaction-isolation可选的值有READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ、SERIALIZABLE。</p><p>修改完成需要重启mysql。</p></li><li><p>修改当前会话的隔离级别（在线方式）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set session transaction isolation level read committed;</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/3.png" alt="3"></p></li><li><p>如果希望通过在线方式，全局修改事务隔离级别:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set global transaction isolation level read uncommitted;</div></pre></td></tr></table></figure><p>分别查看全局和当前会话的事务隔离级别：</p><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/4.png" alt="4"></p></li></ol><h2 id="事务隔离级别解决的问题"><a href="#事务隔离级别解决的问题" class="headerlink" title="事务隔离级别解决的问题"></a>事务隔离级别解决的问题</h2><p>事务的隔离级别解决的是“脏读（dirty read）”、“不可重复读（non-repeatable read）”、“幻读（phantom read）”的问题。</p><ul><li>脏读：指的是一个事务读取到另一个事务没有提交的数据。</li><li>不可重复读：指的是一个事务访问同一条数据多次，得到的是不同的结果。偏向于指数据的修改。</li><li>幻读：指的是一个事务访问到 同时后者后启动事务插入的数据。偏向于指数据的插入和删除。</li></ul><h2 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h2><ol><li><p>显示启动事务语句，begin或者start transaction。配套的提交语句是commit ，回滚语句是rollback;</p></li><li><p>set autocommit=0，这个语句会将线程的自动提交关闭。<strong>为了避免长事务</strong>，应将自动提交开启：set autocommit=1。mysql默认是开启的。</p><p>我们可以通过查询information_schema库的innodb_trx这个表中查询长事务。如下语句是查询持续时间超过60s事务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60;</div></pre></td></tr></table></figure></li></ol><h2 id="一致性读视图"><a href="#一致性读视图" class="headerlink" title="一致性读视图"></a>一致性读视图</h2><ol><li><p>使用begin或者start transaction的方式启动事务，一致性读视图是在执行第一个快照读语句的时候创建的。</p></li><li><p>使用如下语句启动事务，一致性读视图是在执行该语句的时候创建的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">start transaction with consistent snapshot;</div></pre></td></tr></table></figure></li></ol><p>注意，mysql里面有两个视图的概念：</p><ul><li>一个是view。是用查询语句定义的一个虚拟表，创建视图的语法是create view …，查询方式与表一样。</li><li>另一个就是这里提到的，在innodb里面MVCC用到的一致性读视图：consistent read view，用于支持‘读已提交’和‘可重复读’事务隔离级别的实现。</li></ul><h2 id="事务隔离级别的实现"><a href="#事务隔离级别的实现" class="headerlink" title="事务隔离级别的实现"></a>事务隔离级别的实现</h2><p>​    针对读已提交和可重复读两种事务隔离级别，在实现上，数据库会创建一个“一致性读视图”，事务访问的时候以一致性读视图的逻辑结果为准。可重复读级别的一致性读视图，是在事务启动的时候创建，整个时候存在期间都用这个视图；读已提交级别的一致性读视图是在每个SQL语句开始执行的时候创建的。读未提交级别直接返回记录上最新的记录，串行化级别使用加锁的方式避免并行访问，没有“一致性读视图”的概念。</p><p>​    InnoDB中每一行记录都有多个版本（MySQL默认使用InnoDB存储引擎），也就是数据库的多版本并发控制（MVCC）。</p><p>​    MySQL对每一条的记录更新都会记录一条回滚日志（undo log），记录最新的值，同时通过回滚日志可以得到上一个状态的值。</p><p>​    对于不同的‘一致性读视图’，可以通过对当前值，依次执行undo log回滚得到。</p><p>​    回滚日志什么时候删除？mysql会判断，当没有比这个回滚日志更早的一致性读视图时，会将这个回滚日志删除掉。因此，建议不要使用长事务，长事务会导致回滚日志很大，会导致大量占用存储空间。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;​    本文就Mysql数据库的事务进行阐述，包括事务的ACID特性、事务的隔离级别、事务隔离级别解决的问题、事务隔离级别的实现等内容。&lt;/p&gt;
&lt;h2 id=&quot;事务的四大特性&quot;&gt;&lt;a href=&quot;#事务的四大特性&quot; class=&quot;headerlink&quot; title=&quot;事务的四大特性&quot;&gt;&lt;/a&gt;事务的四大特性&lt;/h2&gt;&lt;p&gt;事务的ACID特性，也称为事务的四大特性，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原子性（Atomicity）&lt;/li&gt;
&lt;li&gt;一致性（Consistency）&lt;/li&gt;
&lt;li&gt;隔离性（Isolation）&lt;/li&gt;
&lt;li&gt;持久性（Durability）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;事务的隔离级别&quot;&gt;&lt;a href=&quot;#事务的隔离级别&quot; class=&quot;headerlink&quot; title=&quot;事务的隔离级别&quot;&gt;&lt;/a&gt;事务的隔离级别&lt;/h2&gt;&lt;p&gt;​    事务的隔离性，当数据库中有多个事务执行的时候，就有可能出现“脏读”、“不可重复读”、“幻读”的问题，为了解决这些问题，于是就有了事务的“隔离级别”，事务的隔离级别包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交（Read uncommitted）&lt;/li&gt;
&lt;li&gt;读已提交（Read committed）&lt;/li&gt;
&lt;li&gt;可重复读（Repeatable read）&lt;/li&gt;
&lt;li&gt;串行化（Serializable）&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="mysql" scheme="https://tokerr.github.io/tags/mysql/"/>
    
      <category term="事务" scheme="https://tokerr.github.io/tags/%E4%BA%8B%E5%8A%A1/"/>
    
      <category term="事务隔离级别" scheme="https://tokerr.github.io/tags/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>Java内存区域与内存溢出异常</title>
    <link href="https://tokerr.github.io/2018/06/02/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/"/>
    <id>https://tokerr.github.io/2018/06/02/Java内存区域与内存溢出异常/</id>
    <published>2018-06-02T15:48:41.000Z</published>
    <updated>2019-05-01T13:51:07.474Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。</p><p>Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。</p><p>无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。</p><p>通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。<br><a id="more"></a></p><h1 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h1><p>Java虚拟机在<strong>执行Java程序的过程</strong>中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和技术而简历和销毁的。Java虚拟所管理的内存区域将会包括一下几个运行时数据区域。</p><h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p><strong>介绍:</strong><br>程序计数器(Program counter register)是一块较小的内存控件，它的作用可以看做是当前线程所执行的字节码的行号指示器。</p><p><strong>作用：</strong><br>在虚拟机的概念模型里，字节码的解析器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程回复等基础功能都需要依赖这个计数器来完成。</p><p><strong>服务对象：</strong><br>由于Java虚拟机的多线程是通过线程的轮流切换并分配处理器执行时间的方式来时间的，在任何一个确定的时刻，一个处理器(对于多核处理器来说是一个内核)只会执行一条线程中的指令。因此，为了线程钱换后能回复到正确的执行为孩子，每条线程都需要有一个独立的程序计数器，各个线程之间的计数器互不影响，独立储存，我们称这块内存区域为”线程私有”的内存。</p><p>如果线程正在执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；此内存区域是唯一一个在Java虚拟规范中没有规定任何OutOfMemoryError情况的区域。</p><h2 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h2><p><strong>介绍：</strong><br>与程序计数器一样，Java虚拟机栈(JVM Stacks)也是线程自由的，他的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态连接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应这一个栈帧在虚拟机栈中从入栈和出栈的过程。</p><p>局部变量表存放了编译期可知的各种基本数据类型(boolean,byte,char,short,int,float,long,double)、对象引用和returnAddress类型(指向了一条字节码指令的地址)。局部变量表所需要的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p><p>在Java虚拟机规范中，对这个区域规定了两种异常状况:<br>如果线程的栈深度大于虚拟机所允许的深的，将抛出StackOverflowError异常；<br>如果虚拟机栈可以动态拓展，当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常。</p><h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p>本地方法栈(Native Method Stacks)与虚拟机栈所发挥的作用是非常的相似，其区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则是为虚拟机使用到的Navite方法服务。</p><p>简单地讲，一个Native Method就是一个java调用非java代码的接口，该方法的实现由非java语言实现。</p><h2 id="java堆"><a href="#java堆" class="headerlink" title="java堆"></a>java堆</h2><p>对于大多数的应用，Java堆(Java heap)是java虚拟机所管理的内存中最大的一块。java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例在这里分配内存。</p><p>java堆是垃圾收集器管理的主要区域，因此很多时候也被称为”GC堆”。</p><h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>方法区(Method Area)与java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。</p><h3 id="PermGen（永久代）"><a href="#PermGen（永久代）" class="headerlink" title="PermGen（永久代）"></a>PermGen（永久代）</h3><p>绝大部分 Java 程序员应该都见过 “java.lang.OutOfMemoryError: PermGen space “这个异常。这里的 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在 jsp 页面比较多的情况，容易出现永久代内存溢出。</p><p>在 JDK 1.8 中， HotSpot 已经没有 “PermGen space”这个区间了，取而代之是一个叫做 Metaspace（元空间） 的东西。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h1&gt;&lt;p&gt;Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。&lt;/p&gt;
&lt;p&gt;Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。&lt;/p&gt;
&lt;p&gt;无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。&lt;/p&gt;
&lt;p&gt;通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="jvm" scheme="https://tokerr.github.io/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>hadoop2.9.0 编译源码安装</title>
    <link href="https://tokerr.github.io/2017/12/17/hadoop2-9-0-%E7%BC%96%E8%AF%91%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85/"/>
    <id>https://tokerr.github.io/2017/12/17/hadoop2-9-0-编译源码安装/</id>
    <published>2017-12-17T11:10:01.000Z</published>
    <updated>2019-05-01T13:51:07.476Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-编译基础环境"><a href="#1-编译基础环境" class="headerlink" title="1.编译基础环境"></a>1.编译基础环境</h3><pre><code>Requirements:* Unix System (我这里使用的是centos 6.8)* JDK 1.8+* Maven 3.0 or later* Findbugs 1.3.9 (if running findbugs)* ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错）* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac* Zlib devel (if compiling native code)* openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance)* Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs)* Internet connection for first build (to fetch all Maven and Hadoop dependencies)* python (for releasedocs)* bats (for shell code testing)* Node.js / bower / Ember-cli (for YARN UI v2 building)</code></pre><a id="more"></a><p>备注：由于这里的教程基本都是使用在线安装的方式，包括后面的使用maven对hadoop2.9的源码进行编译，需要下载依赖包，因此请确保服务器连接外网，如果你使用的是vmware虚拟机，可以参考我另一篇博客 <a href="https://tokerr.github.io/2017/12/17/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/">vmware虚拟机host-only下配置与宿主机共享网络</a>。</p><h3 id="2-yum-源配置"><a href="#2-yum-源配置" class="headerlink" title="2.yum 源配置"></a>2.yum 源配置</h3><ul><li><p>首先安装wget （已安装则忽略）</p><p>  yum install -y wget</p></li><li><p>将CentOS的yum源更换为国内的阿里云源，我们使用默认的yum源，有时会连接到国外的镜像站导致yum下载比较慢。，所以将默认的yum源替换为阿里云的镜像站。</p></li></ul><p>阿里云Linux安装镜像源地址：<a href="http://mirrors.aliyun.com/" target="_blank" rel="external">http://mirrors.aliyun.com/</a></p><p>备份你的原镜像文件，以免出错后可以恢复。</p><pre><code>mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</code></pre><ul><li>下载新的CentOS-Base.repo 到/etc/yum.repos.d/</li></ul><p>CentOS 5 使用下面的链接</p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo</code></pre><p>CentOS 6 使用下面的链接</p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo</code></pre><p>CentOS 7 使用下面的链接</p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</code></pre><ul><li><p>运行yum makecache生成缓存</p><p>  yum clean all<br><br>  yum makecache</p></li></ul><h3 id="3-yum-安装gcc"><a href="#3-yum-安装gcc" class="headerlink" title="3.yum 安装gcc"></a>3.yum 安装gcc</h3><p>对于配备了yum的Linux发行版而言，安装gcc编译器就变得so easy。我们只需要分别执行如下命令即可：</p><pre><code>yum -y install gcc gcc-c++ kernel-devel</code></pre><h3 id="4-安装CMake"><a href="#4-安装CMake" class="headerlink" title="4.安装CMake"></a>4.安装CMake</h3><pre><code>#wget https://cmake.org/files/v3.3/cmake-3.3.2.tar.gz#tar -zxvf cmake-2.8.10.2.tar.gz#cd cmake-2.8.10.2#./bootstrap#gmake#gmake install</code></pre><h3 id="5-下载Hadoop源码包"><a href="#5-下载Hadoop源码包" class="headerlink" title="5.下载Hadoop源码包"></a>5.下载Hadoop源码包</h3><pre><code>[root@hadoop001 sourcecode]# mkdir -p /opt/sourcecode[root@hadoop001 sourcecode]#wget http://apache.mirrors.tds.net/hadoop/common/stable/hadoop-2.9.0-src.tar.gz[root@hadoop001 sourcecode]#tar -xzvf hadoop-2.9.0-src.tar.gz[root@hadoop001 sourcecode]#cat ./hadoop-2.9.0-src/BUILDING.txt#从BUILDING文件中我们可以看到编译的要求</code></pre><h3 id="6-JDK安装"><a href="#6-JDK安装" class="headerlink" title="6.JDK安装"></a>6.JDK安装</h3><p>这个安装起来相对简单，官网下载个tar包，解压配置环境变量就可以。可以自行百度和google ,可参考我如下系统环境变量配置文件：</p><pre><code># cat /etc/profileJAVA_HOME=/usr/local/work/jdk1.8.0_144MAVEN_HOME=/home/package/apache-maven-3.5.2FINDBUGS_HOME=/home/package/findbugs-3.0.1PROTOBUF_HOME=/usr/local/protobufHADOOP_HOME=/home/hadoop/hadoop-2.9.0CLASSPATH=.:$JAVA_HOME/lib/tools.jarPATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$FINDBUGS_HOME/bin:$PROTOBUF_HOME/bin:$HADOOP_HOME/bin:$PATHexport JAVA_HOME MAVEN_HOME FINDBUGS_HOME PROTOBUF_HOME HADOOP_HOME CLASSPATH PATH</code></pre><h3 id="7-Maven安装"><a href="#7-Maven安装" class="headerlink" title="7.Maven安装"></a>7.Maven安装</h3><pre><code>#wget 获取tar包#解压#配置环境变量mvn --version #验证</code></pre><h3 id="8-protobuf安装"><a href="#8-protobuf安装" class="headerlink" title="8.protobuf安装"></a>8.protobuf安装</h3><p>protobuf要编译安装，需安装gcc、gcc-c++、 make</p><pre><code>上传 protobuf-2.5.0.tar.gztar -xzvf protobuf-2.5.0.tar.gzcd protobuf-2.5.0yum install -y gcc gcc-c++ make./configure --prefix=/usr/local/protobufmake &amp;&amp; make install#添加protobuf环境变量source /etc/profileprotoc --version</code></pre><h3 id="9-Findbugs安装"><a href="#9-Findbugs安装" class="headerlink" title="9.Findbugs安装"></a>9.Findbugs安装</h3><p>下载tar包，解压，配置环境变量</p><h3 id="10-安装snappy1-1-4-使Hadoop支持snappy压缩10-Snappy压缩库安装"><a href="#10-安装snappy1-1-4-使Hadoop支持snappy压缩10-Snappy压缩库安装" class="headerlink" title="10.安装snappy1.1.4,使Hadoop支持snappy压缩10.Snappy压缩库安装"></a>10.安装snappy1.1.4,使Hadoop支持snappy压缩10.Snappy压缩库安装</h3><pre><code>wget https://github.com/google/snappy/releases/download/1.1.4/snappy-1.1.4.tar.gztar -zxvf snappy-1.1.4.tar.gzcd snappy-1.1.4./configuremake &amp;&amp; make installll -h /usr/local/lib |grep snappy</code></pre><h3 id="11-其他依赖安装"><a href="#11-其他依赖安装" class="headerlink" title="11.其他依赖安装"></a>11.其他依赖安装</h3><pre><code>yum install -y ant openssl openssl-devel svn ncurses-devel zlib-devel libtool svnyum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automake</code></pre><h3 id="12-编译"><a href="#12-编译" class="headerlink" title="12.编译"></a>12.编译</h3><p>进入Hadooop源码目录</p><pre><code>cd hadoop-2.9.0-srcmvn clean package -DskipTests -Pdist,native -Dtar -Dsnappy.lib=/usr/local/lib -Dbundle.snappy</code></pre><h3 id="13-生成tar包"><a href="#13-生成tar包" class="headerlink" title="13.生成tar包"></a>13.生成tar包</h3><p>/home/hadoop/hadoop-2.9.0-src/hadoop-dist/target/hadoop-2.9.0.tar.gz</p><p>以下是我maven编译完成的信息，时间还是比较长的，跟网络也有关系：</p><pre><code>[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 02:44 h[INFO] Finished at: 2017-12-17T15:26:30+08:00[INFO] Final Memory: 129M/237M[INFO] ------------------------------------------------------------------------</code></pre><p>注意事项：</p><ul><li>由于Maven仓库在墙外，Maven在编译项目时下载包卡住情况，ctrl+c 中断，重新执行编译。</li><li>如果出现提示缺少了某个文件的情况，则要先清理maven(使用命令 mvn clean) 再重新编译。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-编译基础环境&quot;&gt;&lt;a href=&quot;#1-编译基础环境&quot; class=&quot;headerlink&quot; title=&quot;1.编译基础环境&quot;&gt;&lt;/a&gt;1.编译基础环境&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;Requirements:
* Unix System (我这里使用的是centos 6.8)
* JDK 1.8+
* Maven 3.0 or later
* Findbugs 1.3.9 (if running findbugs)
* ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错）
* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac
* Zlib devel (if compiling native code)
* openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance)
* Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs)
* Internet connection for first build (to fetch all Maven and Hadoop dependencies)
* python (for releasedocs)
* bats (for shell code testing)
* Node.js / bower / Ember-cli (for YARN UI v2 building)
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>虚拟机host-only下配置与宿主机共享网络</title>
    <link href="https://tokerr.github.io/2017/12/17/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/"/>
    <id>https://tokerr.github.io/2017/12/17/虚拟机host-only下配置与宿主机共享网络/</id>
    <published>2017-12-17T10:52:41.000Z</published>
    <updated>2019-05-01T13:51:07.481Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>示例环境：</li><li>宿主机：windows7</li><li>虚拟机软件：vmware 12 pro</li><li>虚拟机：centos 6.8</li></ul><p>备注：假设以上的环境已经全部安装完毕</p><h2 id="1-在windows下打开网络适配器设置页面"><a href="#1-在windows下打开网络适配器设置页面" class="headerlink" title="1.在windows下打开网络适配器设置页面"></a>1.在windows下打开网络适配器设置页面</h2><p><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/1.png?raw=true" alt=""><br><a id="more"></a><br>点击进去，看到如下界面：<br><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/2.png?raw=true" alt=""></p><h2 id="2-宿主机所连接的外网通过windows网络共享给VMnet1"><a href="#2-宿主机所连接的外网通过windows网络共享给VMnet1" class="headerlink" title="2.宿主机所连接的外网通过windows网络共享给VMnet1"></a>2.宿主机所连接的外网通过windows网络共享给VMnet1</h2><p>截图可以看到我宿主机所连接的网络是‘无线网络连接’，右键点击其属性，然后切换到共享网卡，勾选“允许其他网络用户通过此计算机的Internet连接来连接”，“请选择一个专用连接”下拉框选择“VMware Network Adapter VMnet1”，点击确定。<br><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/3.png?raw=true" alt=""></p><p>此时会提示VMware Network Adapter VMnet1的IP地址被修改为192.168.137.1，客户机网络配置要用到这个信息（本例为192.168.137.1，<strong>注意，这里经过试验，尽量不要修改这个ip地址，否则会出现配置不成功的现象</strong>）。</p><h2 id="3-准备Linux环境"><a href="#3-准备Linux环境" class="headerlink" title="3.准备Linux环境"></a>3.准备Linux环境</h2><p>3.1点击VMware快捷方式，右键打开文件所在位置 -&gt; 双击vmnetcfg.exe -&gt; VMnet1 host-only -&gt;修改subnet ip 设置网段：192.168.137.0 子网掩码：255.255.255.0 –&gt; 同时关闭DHCP服务-&gt; apply -&gt; ok<br><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/4.png?raw=true" alt=""><br>在虚拟软件上 –My Computer -&gt; 选中虚拟机 -&gt; 右键 -&gt; settings -&gt; network adapter -&gt; host only -&gt; ok </p><p>3.3修改IP/配置DNS</p><p>vim /etc/sysconfig/network-scripts/ifcfg-eth0</p><pre><code>DEVICE=eth0TYPE=EthernetUUID=6169d30a-2243-4a7d-9f03-455d9e0cefa6ONBOOT=noNM_CONTROLLED=yes#BOOTPROTO=dhcpBOOTPROTO=static  ##设置静态IPADDR=192.168.137.101 ##配置ipNETMASK=255.255.255.0 ##配置子网GATEWAY=192.168.137.2 ##配置网关PREFIX=24DNS1=8.8.8.8 ##配置dnsDEFROUTE=yesIPV4_FAILURE_FATAL=yesIPV6INIT=noNAME=&quot;System eth0&quot;HWADDR=00:0C:29:44:CB:D8LAST_CONNECT=1513431454</code></pre><p>保存退出，重启网络服务：</p><pre><code>service network restart</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;示例环境：&lt;/li&gt;
&lt;li&gt;宿主机：windows7&lt;/li&gt;
&lt;li&gt;虚拟机软件：vmware 12 pro&lt;/li&gt;
&lt;li&gt;虚拟机：centos 6.8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;备注：假设以上的环境已经全部安装完毕&lt;/p&gt;
&lt;h2 id=&quot;1-在windows下打开网络适配器设置页面&quot;&gt;&lt;a href=&quot;#1-在windows下打开网络适配器设置页面&quot; class=&quot;headerlink&quot; title=&quot;1.在windows下打开网络适配器设置页面&quot;&gt;&lt;/a&gt;1.在windows下打开网络适配器设置页面&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/1.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="vmware" scheme="https://tokerr.github.io/tags/vmware/"/>
    
  </entry>
  
  <entry>
    <title>负载均衡session共享解决方法整理</title>
    <link href="https://tokerr.github.io/2017/11/20/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1session%E5%85%B1%E4%BA%AB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
    <id>https://tokerr.github.io/2017/11/20/负载均衡session共享解决方法整理/</id>
    <published>2017-11-20T15:44:36.000Z</published>
    <updated>2019-05-01T13:51:07.482Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、背景："><a href="#一、背景：" class="headerlink" title="一、背景："></a>一、背景：</h2><p>最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！</p><p>项目属于JavaWeb项目，部署在Tomcat环境下。</p><h2 id="二、tomcat集群环境下session共享方法整理"><a href="#二、tomcat集群环境下session共享方法整理" class="headerlink" title="二、tomcat集群环境下session共享方法整理"></a>二、tomcat集群环境下session共享方法整理</h2><p>在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路：</p><p>一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；<br><a id="more"></a><br>二是在集群中左右的节点进行Session数据的同步拷贝，所有节点的均保存了所有的Session数据。</p><h3 id="2-1tomcat集群session同步方案有以下几种："><a href="#2-1tomcat集群session同步方案有以下几种：" class="headerlink" title="2.1tomcat集群session同步方案有以下几种："></a>2.1tomcat集群session同步方案有以下几种：</h3><p>1）使用tomcat自带的cluster方式，多个tomcat间自动实时复制session信息，配置起来很简单。使用组播的方式实现session的同步拷贝，但这个方案的效率比较低，在大并发下表现并不好。而且需要另外安装apache的HTTP Server，同样需要一台节点了协调session的拷贝，比较多余，使用的人少，网上的资料比较乱(建议去官网)。<strong>不推荐</strong>。</p><p>2）利用nginx的基于访问ip的hash路由策略，保证访问的ip始终被路由到同一个tomcat上，这个配置更简单。但如果应用是某一个局域网大量用户同时登录，这样负载均衡就没什么作用了。</p><p>3）利用nginx插件实现tomcat集群和session同步，nginx-upstream-jvm-route-0.1.tar.gz，是一个Nginx的扩展模块，用来实现基于Cookie的Session Sticky的功能。</p><p><strong>4）利用memcached实现（MSM工具）。memcached存储session，并把多个tomcat的session集中管理，前端在利用nginx负载均衡和动静态资源分离，在兼顾系统水平扩展的同时又能保证较高的性能。</strong></p><p><strong>5）利用redis实现。使用redis不仅仅可以将缓存的session持久化，还因为它支持的单个对象比较大，而且数据类型丰富，不只是缓存 session，还可以做其他用途，可以一举几得。</strong></p><p><strong>6）利用filter+cookie方式实现。这种方法比较推荐，因为它的服务器使用范围比较多，不仅限于tomcat ，而且实现的原理比较简单容易控制。</strong></p><p>最后三种方法是比较推荐，尝试过第一种方法，但是不推荐，原因已经写明；第四第五种方法，由于公司需要另外申请一台单独的session共享服务器，比较麻烦。最终还是选择了最后一种解决方案，思路简单，实现起来也不难。下面将介绍这种方案。</p><h2 id="三、cookie-filter解决session共享问题"><a href="#三、cookie-filter解决session共享问题" class="headerlink" title="三、cookie+filter解决session共享问题"></a>三、cookie+filter解决session共享问题</h2><p>下面是实现该方案涉及到的三个相关功能，重点在于过滤器的编写。</p><h3 id="3-1-登录成功通知浏览器保存cookie"><a href="#3-1-登录成功通知浏览器保存cookie" class="headerlink" title="3.1 登录成功通知浏览器保存cookie"></a>3.1 登录成功通知浏览器保存cookie</h3><pre><code>public static void setCookie(HttpServletResponse response, HttpServletRequest request, String cookieName,            String cookieValue) {        /**         * a.先判断是否存在cookie ，存在自己设置的cookie则重新设置过期的时间 b.不存在则创建自己cookie 通知客户端保存         * c.需要设置的属性如下： 设置value ,具体值视自己的业务而定，具体设置的之后可以通过构造方法设置name=value         * ，注意使用算法加密 设置编码 设置过期时间 ，设置与session过期时间一致 设置domain 设置path         */        // 声明 cookie        Cookie autoCookie = null;        // 获取所有的cookie        Cookie cookies[] = request.getCookies();        HttpSession session = request.getSession();        // session.getMaxInactiveInterval();//session失效时间，值小于等于0代表永不超时        // 遍历cookie        if (cookies != null &amp;&amp; cookies.length &gt; 0) {            for (Cookie cookie : cookies) {                // 判断是否存在自动登录记录                if (cookieName.equals(cookie.getName())) {                    autoCookie = cookie;// 赋值                    break;                }            }        }        if (autoCookie == null) {            // 不在创建            autoCookie = new Cookie(cookieName, cookieValue);        }        // 设置在执行秒数之后过期；负值意味着cookie不存储，浏览器退出则清除；值为零表示删除cookie        autoCookie.setMaxAge(expiry);// 设置7天之内过期        // 设置编码        // 设置域名domain 默认情况下，Cookie只会返回给发送它们的服务器。        autoCookie.setDomain(request.getServerName());        // 设置path        autoCookie.setPath(request.getContextPath());        // 浏览器的document对象中就看不到cookie        autoCookie.setHttpOnly(true);        response.addCookie(autoCookie);// 添加    }</code></pre><h3 id="3-2-登录退出通知浏览器清除cookie"><a href="#3-2-登录退出通知浏览器清除cookie" class="headerlink" title="3.2 登录退出通知浏览器清除cookie"></a>3.2 登录退出通知浏览器清除cookie</h3><pre><code>public static void cleanCookie(HttpServletRequest request, HttpServletResponse response, String cookieName) {        Cookie cookies[] = request.getCookies();        if (cookies != null &amp;&amp; cookies.length &gt; 0) {            for (Cookie cookie : cookies) {                if (cookieName.equals(cookie.getName())) {                    cookie.setPath(request.getContextPath());// 浏览器回以同Name同Path同Domain覆盖原来的cookie                    cookie.setDomain(request.getServerName());                    cookie.setMaxAge(0);// 通知浏览器删除                    response.addCookie(cookie);                }            }        }    }}</code></pre><h3 id="3-3-编写自动登录过滤器"><a href="#3-3-编写自动登录过滤器" class="headerlink" title="3.3 编写自动登录过滤器"></a>3.3 编写自动登录过滤器</h3><ul><li>1）获取cookie判断用户是否已经登录</li><li>2）未登录则放行</li><li>3）已登录并且本地服务器没有相关session会话信息，则执行自动登录流程</li><li><p>4）自动登录完毕放行</p><pre><code>@Override   public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain)           throws IOException, ServletException {       /**        * a.到session获取认证信息 ，存在则通过认证，放行并终止程序 不存在执行下一步 b.        * 不存在认证信息，获取cookie，遍历判断是否存在自己设置的cookie，不存在直接放行并终止程序 存在执行下一步        * c.执行自动登录流程，并查询用户必要的信息保存到session当中，执行完毕放行并终止程序        */       HttpServletRequest request = (HttpServletRequest) req;       HttpServletResponse response = (HttpServletResponse) resp;       HttpSession session = request.getSession();       Object token = session.getAttribute(Constant.USER_CONTEXT_LOGGED);       Cookie[] cookies = request.getCookies();       // 用户执行注销操作不进行自动登录       String uri = request.getRequestURI();       String logout = request.getParameter(&quot;logout&quot;);       if (uri.contains(&quot;/projectContextPath/index.html&quot;) &amp;&amp; logout != null &amp;&amp; &quot;true&quot;.equals(logout)) {           StringBuffer url = request.getRequestURL();           response.sendRedirect(url.toString());           return;       }       if (cookies != null &amp;&amp; cookies.length &gt; 0) {// 在session中没有获取到用户信息           Cookie autoCookie = null;// 已登录的cookie           for (Cookie cookie : cookies) {               // 未在本服务器登录，并且在客户端保存有响应的cookie，才会执行自动登录               if (Constant.COOKIE_NAME.equals(cookie.getName()) &amp;&amp; token == null) {// cookie存在                   autoCookie = cookie;               }           }           if (autoCookie != null ) {// 存在cookie                // 开始自动登录，视具体业务根据cookie中的信息查询用户的信息并保存到session中完成自动登录                                                                       startAutoLogin(request, response, autoCookie);           }       }       chain.doFilter(request, response);// 放行   }</code></pre></li></ul><p><em>另外， 安全性问题考虑，由于使用的是cookie保存了用户的信息，容易被黑客拦截篡改。通常cookie中会保存用户名、密码等敏感经过加密，很难反向破解，但也不是绝对的安全，黑客可以通过木马病毒盗取用户浏览器的cookie，直接骗取网站的信任。 最好是使用https。</em></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、背景：&quot;&gt;&lt;a href=&quot;#一、背景：&quot; class=&quot;headerlink&quot; title=&quot;一、背景：&quot;&gt;&lt;/a&gt;一、背景：&lt;/h2&gt;&lt;p&gt;最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！&lt;/p&gt;
&lt;p&gt;项目属于JavaWeb项目，部署在Tomcat环境下。&lt;/p&gt;
&lt;h2 id=&quot;二、tomcat集群环境下session共享方法整理&quot;&gt;&lt;a href=&quot;#二、tomcat集群环境下session共享方法整理&quot; class=&quot;headerlink&quot; title=&quot;二、tomcat集群环境下session共享方法整理&quot;&gt;&lt;/a&gt;二、tomcat集群环境下session共享方法整理&lt;/h2&gt;&lt;p&gt;在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路：&lt;/p&gt;
&lt;p&gt;一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="session" scheme="https://tokerr.github.io/tags/session/"/>
    
      <category term="cookie" scheme="https://tokerr.github.io/tags/cookie/"/>
    
  </entry>
  
  <entry>
    <title>sqoop学习笔记</title>
    <link href="https://tokerr.github.io/2017/10/25/sqoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://tokerr.github.io/2017/10/25/sqoop学习笔记/</id>
    <published>2017-10-25T13:28:29.000Z</published>
    <updated>2019-05-01T13:51:07.478Z</updated>
    
    <content type="html"><![CDATA[<p><strong>说明：这里以hadoop2和mysql为例。</strong></p><h2 id="1-上传sqoop到Hadoop集群任意一个节点"><a href="#1-上传sqoop到Hadoop集群任意一个节点" class="headerlink" title="1.上传sqoop到Hadoop集群任意一个节点"></a>1.上传sqoop到Hadoop集群任意一个节点</h2><h2 id="2-安装和配置"><a href="#2-安装和配置" class="headerlink" title="2.安装和配置"></a>2.安装和配置</h2><h3 id="2-1-配置sqoop-env-sh文件"><a href="#2-1-配置sqoop-env-sh文件" class="headerlink" title="2.1 配置sqoop-env.sh文件"></a>2.1 配置sqoop-env.sh文件</h3><p>在sqoop中conf目录下新复制一个sqoop-env.sh文件：<br><br>[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh<br><br>修改配置sqoop-env.sh文件：<br><a id="more"></a><br>    export HADOOP_COMMON_HOME=/home/hadoop/hadoop/hadoop-2.3.0</p><pre><code>#Set path to where hadoop-*-core.jar is availableexport HADOOP_MAPRED_HOME=/home/hadoop/hadoop/hadoop-2.3.0#set the path to where bin/hbase is available#export HBASE_HOME=#Set the path to where bin/hive is available#export HIVE_HOME=#Set the path for where zookeper config dir is#export ZOOCFGDIR=</code></pre><p> 不配置该项会出现Please set $HADOOP_COMMON_HOME to the root的错误提示。</p><h3 id="2-2-添加数据库驱动"><a href="#2-2-添加数据库驱动" class="headerlink" title="2.2 添加数据库驱动"></a>2.2 添加数据库驱动</h3><p>将数据库连接驱动拷贝到$SQOOP_HOME/lib里。注意，这里使用的是Mysql驱动版本不能过低，尽量使用最新的版本，否则可能会出现一下错误：</p><pre><code>ERROR manager.SqlManager: Error reading from database: java.sql.SQLException: Streaming result set</code></pre><h2 id="3-配置mysql远程登录"><a href="#3-配置mysql远程登录" class="headerlink" title="3.配置mysql远程登录"></a>3.配置mysql远程登录</h2><h3 id="3-1-改表："><a href="#3-1-改表：" class="headerlink" title="3.1 改表："></a>3.1 改表：</h3><p>只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%”</p><p>登录数据库：mysql -u root -pvmware</p><p>mysql&gt;use mysql;</p><p>mysql&gt;update user set host = ‘%’ where user = ‘root’;</p><p>mysql&gt;select host, user from user;</p><p>mysql&gt;FLUSH RIVILEGES </p><h3 id="3-2-授权："><a href="#3-2-授权：" class="headerlink" title="3.2 授权："></a>3.2 授权：</h3><p>(1)例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。</p><p>第一步：root用户登录；mysql&gt;mysql -u root -p rootpassword;</p><p>第二步：赋予权限；mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser’@’%’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><p>第三步：mysql&gt;FLUSH   PRIVILEGES;</p><p>(2)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器，并使用mypassword作为密码</p><p> mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><p> mysql&gt;FLUSH   PRIVILEGES;</p><p>(3)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码</p><p> mysql&gt;GRANT ALL PRIVILEGES ON dk.* TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><p> mysql&gt;FLUSH   PRIVILEGES;</p><p>说明：这里我使用了第（1）种方法。没有允许mysql远程登录，在使用sqoop导入数据的时候，会出现以下错误：</p><pre><code>message from server: &quot;Host is not allowed to connect to this MySQL server</code></pre><h2 id="4-使用-amp-练习"><a href="#4-使用-amp-练习" class="headerlink" title="4.使用&amp;练习"></a>4.使用&amp;练习</h2><p><strong>第一类：数据库中的数据导入到HDFS上</strong></p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --columns &apos;id, account, income, expenses&apos;</code></pre><p>指定输出路径、指定数据分隔符</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td&apos; --fields-terminated-by &apos;\t&apos;</code></pre><p>指定Map数量 -m</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td1&apos; --fields-terminated-by &apos;\t&apos; -m 2</code></pre><p>增加where条件, 注意：条件必须用引号引起来</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --where &apos;id&gt;3&apos; --target-dir &apos;/sqoop/td2&apos;</code></pre><p>增加query语句(使用 \ 将语句换行)</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 \--query &apos;SELECT * FROM trade_detail where id &gt; 2 AND $CONDITIONS&apos; --split-by trade_detail.id --target-dir &apos;/sqoop/td3&apos;</code></pre><p><strong><em>注意：</em></strong></p><ul><li><p><em>如果使用–query这个命令的时候，需要注意的是where后面的参数，AND $CONDITIONS这个参数必须加上</em></p></li><li><p><em>而且存在单引号与双引号的区别，如果–query后面使用的是双引号，那么需要在$CONDITIONS前加上\即\$CONDITIONS</em></p></li><li><p><em>如果设置map数量为1个时即-m 1，不用加上–split-by ${tablename.column}，否则需要加上</em></p></li></ul><p><strong>第二类：将HDFS上的数据导出到数据库中(不要忘记指定分隔符)</strong></p><pre><code>sqoop export --connect jdbc:mysql://192.168.8.120:3306/nongyt --username root --password 123 --export-dir &apos;/td3&apos; --table td_bak -m 1 --fields-terminated-by &apos;,&apos;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;说明：这里以hadoop2和mysql为例。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-上传sqoop到Hadoop集群任意一个节点&quot;&gt;&lt;a href=&quot;#1-上传sqoop到Hadoop集群任意一个节点&quot; class=&quot;headerlink&quot; title=&quot;1.上传sqoop到Hadoop集群任意一个节点&quot;&gt;&lt;/a&gt;1.上传sqoop到Hadoop集群任意一个节点&lt;/h2&gt;&lt;h2 id=&quot;2-安装和配置&quot;&gt;&lt;a href=&quot;#2-安装和配置&quot; class=&quot;headerlink&quot; title=&quot;2.安装和配置&quot;&gt;&lt;/a&gt;2.安装和配置&lt;/h2&gt;&lt;h3 id=&quot;2-1-配置sqoop-env-sh文件&quot;&gt;&lt;a href=&quot;#2-1-配置sqoop-env-sh文件&quot; class=&quot;headerlink&quot; title=&quot;2.1 配置sqoop-env.sh文件&quot;&gt;&lt;/a&gt;2.1 配置sqoop-env.sh文件&lt;/h3&gt;&lt;p&gt;在sqoop中conf目录下新复制一个sqoop-env.sh文件：&lt;br&gt;&lt;br&gt;[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh&lt;br&gt;&lt;br&gt;修改配置sqoop-env.sh文件：&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="sqoop" scheme="https://tokerr.github.io/tags/sqoop/"/>
    
  </entry>
  
  <entry>
    <title>hadoop+zookeeper集群搭建</title>
    <link href="https://tokerr.github.io/2017/10/24/hadoop-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://tokerr.github.io/2017/10/24/hadoop-zookeeper集群搭建/</id>
    <published>2017-10-24T14:50:21.000Z</published>
    <updated>2019-12-01T11:58:23.066Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备:"></a>前期准备:</h2><p>hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA</p><p>1.修改Linux主机名<br><br>2.修改IP<br><br>3.修改主机名和IP的映射关系<br><a id="more"></a><br>    注意：<br>    如果你们公司是租用的服务器或是使用的云主机（如华为用主机、阿里云主机等）<br>    /etc/hosts里面要配置的是内网IP地址和主机名的映射关系<br>4.关闭防火墙<br><br>5.ssh免登陆 <br><br>6.安装JDK，配置环境变量等<br></p><h2 id="集群规划："><a href="#集群规划：" class="headerlink" title="集群规划："></a>集群规划：</h2><pre><code>主机名        IP                安装的软件                    运行的进程nongyt01    192.168.1.201    jdk、hadoop                    NameNode、DFSZKFailoverController(zkfc)nongyt02    192.168.1.202    jdk、hadoop                    NameNode、DFSZKFailoverController(zkfc)nongyt03    192.168.1.203    jdk、hadoop                    ResourceManagernongyt04    192.168.1.204    jdk、hadoop                    ResourceManagernongyt05    192.168.1.205    jdk、hadoop、zookeeper        DataNode、NodeManager、JournalNode、QuorumPeerMainnongyt06    192.168.1.206    jdk、hadoop、zookeeper        DataNode、NodeManager、JournalNode、QuorumPeerMainnongyt07    192.168.1.207    jdk、hadoop、zookeeper        DataNode、NodeManager、JournalNode、QuorumPeerMain</code></pre><h3 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h3><p>1.在hadoop2.0中通常由两个NameNode组成，一个处于active状态，另一个处于standby状态。Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步active namenode的状态，以便能够在它失败时快速进行切换。<br><br>hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode<br>这里还配置了一个zookeeper集群，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode为standby状态</p><p>2.hadoop-2.2.0中依然存在一个问题，就是ResourceManager只有一个，存在单点故障，hadoop-2.4.1解决了这个问题，有两个ResourceManager，一个是Active，一个是Standby，状态由zookeeper进行协调</p><h2 id="安装步骤："><a href="#安装步骤：" class="headerlink" title="安装步骤："></a>安装步骤：</h2><h3 id="1-安装配置zooekeeper集群（在nongyt05上）"><a href="#1-安装配置zooekeeper集群（在nongyt05上）" class="headerlink" title="1.安装配置zooekeeper集群（在nongyt05上）"></a>1.安装配置zooekeeper集群（在nongyt05上）</h3><pre><code>1.1解压    tar -zxvf zookeeper-3.4.5.tar.gz -C /nongyt/1.2修改配置    cd /nongyt/zookeeper-3.4.5/conf/    cp zoo_sample.cfg zoo.cfg    vim zoo.cfg    修改：dataDir=/nongyt/zookeeper-3.4.5/tmp    在最后添加：    server.1=nongyt05:2888:3888    server.2=nongyt06:2888:3888    server.3=nongyt07:2888:3888    保存退出    然后创建一个tmp文件夹    mkdir /nongyt/zookeeper-3.4.5/tmp    再创建一个空文件    touch /nongyt/zookeeper-3.4.5/tmp/myid    最后向该文件写入ID    echo 1 &gt; /nongyt/zookeeper-3.4.5/tmp/myid1.3将配置好的zookeeper拷贝到其他节点(首先分别在nongyt06、nongyt07根目录下创建一个nongyt目录：mkdir /nongyt)    scp -r /nongyt/zookeeper-3.4.5/ nongyt06:/nongyt/    scp -r /nongyt/zookeeper-3.4.5/ nongyt07:/nongyt/    注意：修改nongyt06、nongyt07对应/nongyt/zookeeper-3.4.5/tmp/myid内容    nongyt06：        echo 2 &gt; /nongyt/zookeeper-3.4.5/tmp/myid    nongyt07：        echo 3 &gt; /nongyt/zookeeper-3.4.5/tmp/myid</code></pre><h3 id="2-安装配置hadoop集群（在nongyt01上操作）"><a href="#2-安装配置hadoop集群（在nongyt01上操作）" class="headerlink" title="2.安装配置hadoop集群（在nongyt01上操作）"></a>2.安装配置hadoop集群（在nongyt01上操作）</h3><pre><code>    2.1解压        tar -zxvf hadoop-2.4.1.tar.gz -C /nongyt/    2.2配置HDFS（hadoop2.0所有的配置文件都在$HADOOP_HOME/etc/hadoop目录下）        #将hadoop添加到环境变量中        vim /etc/profile        export JAVA_HOME=/usr/java/jdk1.7.0_55        export HADOOP_HOME=/nongyt/hadoop-2.4.1        export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin        #hadoop2.0的配置文件全部在$HADOOP_HOME/etc/hadoop下        cd /nongyt/hadoop-2.4.1/etc/hadoop        2.2.1修改hadoo-env.sh            export JAVA_HOME=/usr/java/jdk1.7.0_55        2.2.2修改core-site.xml            &lt;configuration&gt;                &lt;!-- 指定hdfs的nameservice为ns1 --&gt;                &lt;property&gt;                    &lt;name&gt;fs.defaultFS&lt;/name&gt;                    &lt;value&gt;hdfs://ns1&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定hadoop临时目录 --&gt;                &lt;property&gt;                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                    &lt;value&gt;/nongyt/hadoop-2.4.1/tmp&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定zookeeper地址 --&gt;                &lt;property&gt;                    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;                    &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;        2.2.3修改hdfs-site.xml            &lt;configuration&gt;                &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.nameservices&lt;/name&gt;                    &lt;value&gt;ns1&lt;/value&gt;                &lt;/property&gt;                &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;                    &lt;value&gt;nn1,nn2&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn1的RPC通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;                    &lt;value&gt;nongyt01:9000&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn1的http通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;                    &lt;value&gt;nongyt01:50070&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn2的RPC通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;                    &lt;value&gt;nongyt02:9000&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn2的http通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;                    &lt;value&gt;nongyt02:50070&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;                    &lt;value&gt;qjournal://nongyt05:8485;nongyt06:8485;nongyt07:8485/ns1&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;                    &lt;value&gt;/nongyt/hadoop-2.4.1/journal&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 开启NameNode失败自动切换 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;                    &lt;value&gt;true&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 配置失败自动切换实现方式 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;                    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;                    &lt;value&gt;                        sshfence                        shell(/bin/true)                    &lt;/value&gt;                &lt;/property&gt;                &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;                    &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 配置sshfence隔离机制超时时间 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;                    &lt;value&gt;30000&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;        2.2.4修改mapred-site.xml            &lt;configuration&gt;                &lt;!-- 指定mr框架为yarn方式 --&gt;                &lt;property&gt;                    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                    &lt;value&gt;yarn&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;            2.2.5修改yarn-site.xml            &lt;configuration&gt;                &lt;!-- 开启RM高可靠 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;                   &lt;value&gt;true&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定RM的cluster id --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;                   &lt;value&gt;yrc&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定RM的名字 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;                   &lt;value&gt;rm1,rm2&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 分别指定RM的地址 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;                   &lt;value&gt;nongyt03&lt;/value&gt;                &lt;/property&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;                   &lt;value&gt;nongyt04&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定zk集群地址 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;                   &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt;                &lt;/property&gt;                &lt;property&gt;                   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;        2.2.6修改slaves(slaves是指定子节点的位置，因为要在nongyt01上启动HDFS、在nongyt03启动yarn，所以nongyt01上的slaves文件指定的是datanode的位置，nongyt03上的slaves文件指定的是nodemanager的位置)            nongyt05            nongyt06            nongyt07        2.2.7配置免密码登陆            #首先要配置nongyt01到nongyt02、nongyt03、nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆            #在nongyt01上生产一对钥匙            ssh-keygen -t rsa            #将公钥拷贝到其他节点，包括自己            ssh-coyp-id nongyt01            ssh-coyp-id nongyt02            ssh-coyp-id nongyt03            ssh-coyp-id nongyt04            ssh-coyp-id nongyt05            ssh-coyp-id nongyt06            ssh-coyp-id nongyt07            #配置nongyt03到nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆            #在nongyt03上生产一对钥匙            ssh-keygen -t rsa            #将公钥拷贝到其他节点            ssh-coyp-id nongyt04            ssh-coyp-id nongyt05            ssh-coyp-id nongyt06            ssh-coyp-id nongyt07            #注意：两个namenode之间要配置ssh免密码登陆，别忘了配置nongyt02到nongyt01的免登陆            在nongyt02上生产一对钥匙            ssh-keygen -t rsa            ssh-coyp-id -i nongyt01                    2.4将配置好的hadoop拷贝到其他节点        scp -r /nongyt/ nongyt02:/        scp -r /nongyt/ nongyt03:/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt04:/nongyt/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt05:/nongyt/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt06:/nongyt/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt07:/nongyt/    ###注意：严格按照下面的步骤    2.5启动zookeeper集群（分别在nongyt05、nongyt06、tcast07上启动zk）        cd /nongyt/zookeeper-3.4.5/bin/        ./zkServer.sh start        #查看状态：一个leader，两个follower        ./zkServer.sh status    2.6启动journalnode（分别在在nongyt05、nongyt06、tcast07上执行）        cd /nongyt/hadoop-2.4.1        sbin/hadoop-daemon.sh start journalnode        #运行jps命令检验，nongyt05、nongyt06、nongyt07上多了JournalNode进程    2.7格式化HDFS        #在nongyt01上执行命令:        hdfs namenode -format        #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/nongyt/hadoop-2.4.1/tmp，然后将/nongyt/hadoop-2.4.1/tmp拷贝到nongyt02的/nongyt/hadoop-2.4.1/下。        scp -r tmp/ nongyt02:/nongyt/hadoop-2.4.1/    2.8格式化ZK(在nongyt01上执行即可)        hdfs zkfc -formatZK    2.9启动HDFS(在nongyt01上执行)        sbin/start-dfs.sh    2.10启动YARN(#####注意#####：是在nongyt03上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动)        sbin/start-yarn.sh到此，hadoop-2.4.1配置完毕，可以统计浏览器访问:    http://192.168.1.201:50070    NameNode &apos;nongyt01:9000&apos; (active)    http://192.168.1.202:50070    NameNode &apos;nongyt02:9000&apos; (standby)验证HDFS HA    首先向hdfs上传一个文件    hadoop fs -put /etc/profile /profile    hadoop fs -ls /    然后再kill掉active的NameNode    kill -9 &lt;pid of NN&gt;    通过浏览器访问：http://192.168.1.202:50070    NameNode &apos;nongyt02:9000&apos; (active)    这个时候nongyt02上的NameNode变成了active    在执行命令：    hadoop fs -ls /    -rw-r--r--   3 root supergroup       1926 2014-02-06 15:36 /profile    刚才上传的文件依然存在！！！    手动启动那个挂掉的NameNode    sbin/hadoop-daemon.sh start namenode    通过浏览器访问：http://192.168.1.201:50070    NameNode &apos;nongyt01:9000&apos; (standby)验证YARN：    运行一下hadoop提供的demo中的WordCount程序：    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /outOK，大功告成！！！</code></pre><h2 id="zookeeper配置文件详解"><a href="#zookeeper配置文件详解" class="headerlink" title="zookeeper配置文件详解"></a>zookeeper配置文件详解</h2><p>zookeeper的默认配置文件为zookeeper/conf/zoo_sample.cfg，需要将其修改为zoo.cfg。其中各配置项的含义，解释如下：</p><ul><li><p>1.tickTime：CS通信心跳时间<br><br>Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。<br><br>tickTime=2000  </p></li><li><p>2.initLimit：LF初始通信时限<br><br>集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。<br><br>initLimit=5  </p></li><li><p>3.syncLimit：LF同步通信时限<br><br>集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。<br><br>syncLimit=2  </p></li><li><p>4.dataDir：数据文件目录<br><br>Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。<br>dataDir=/home/michael/opt/zookeeper/data  </p></li><li><p>5.clientPort：客户端连接端口<br><br>客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。<br><br>clientPort=2181 </p></li><li><p>6.服务器名称与地址：<br><br>  集群信息（服务器编号，服务器地址，LF通信端口，选举端口）<br><br>  这个配置项的书写格式比较特殊，规则如下：<br><br>  server.N=YYY:A:B <br><br>  server.1=nongyt05:2888:3888<br><br>  server.2=nongyt06:2888:3888<br><br>  server.3=nongyt07:2888:3888<br></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前期准备&quot;&gt;&lt;a href=&quot;#前期准备&quot; class=&quot;headerlink&quot; title=&quot;前期准备:&quot;&gt;&lt;/a&gt;前期准备:&lt;/h2&gt;&lt;p&gt;hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA&lt;/p&gt;
&lt;p&gt;1.修改Linux主机名&lt;br&gt;&lt;br&gt;2.修改IP&lt;br&gt;&lt;br&gt;3.修改主机名和IP的映射关系&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="zookeeper" scheme="https://tokerr.github.io/tags/zookeeper/"/>
    
      <category term="cluster" scheme="https://tokerr.github.io/tags/cluster/"/>
    
  </entry>
  
  <entry>
    <title>Linux下tomcat启动慢的问题</title>
    <link href="https://tokerr.github.io/2017/10/24/Linux%E4%B8%8Btomcat%E5%90%AF%E5%8A%A8%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://tokerr.github.io/2017/10/24/Linux下tomcat启动慢的问题/</id>
    <published>2017-10-24T14:37:32.000Z</published>
    <updated>2019-05-01T13:51:07.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="有两种解决办法："><a href="#有两种解决办法：" class="headerlink" title="有两种解决办法："></a>有两种解决办法：</h2><p>1）在Tomcat环境中解决</p><p>可以通过配置JRE使用非阻塞的Entropy Source。<br>在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。<br>加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。<br><a id="more"></a><br>2）在JVM环境中解决</p><p>打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容：<br><br>securerandom.source=file:/dev/urandom<br>替换成<br>securerandom.source=file:/dev/./urandom</p><h2 id="彻底解决"><a href="#彻底解决" class="headerlink" title="彻底解决"></a>彻底解决</h2><p>“Linux下的所有应用程序产生随机数都会用到这个，所以不仅仅是Tomcat可能被 阻塞 。如果你搜索会发现Apache、Nginx、OpenSSL都被这个问题坑过.”<br>由于《彻底找到Tomcat启动速度慢的元凶》这篇原文网上被引用过多，我也分不清那个是原文，所以此处就不贴原文地址了，大家可自行百度关键字：彻底找到Tomcat启动速度慢的元凶</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;有两种解决办法：&quot;&gt;&lt;a href=&quot;#有两种解决办法：&quot; class=&quot;headerlink&quot; title=&quot;有两种解决办法：&quot;&gt;&lt;/a&gt;有两种解决办法：&lt;/h2&gt;&lt;p&gt;1）在Tomcat环境中解决&lt;/p&gt;
&lt;p&gt;可以通过配置JRE使用非阻塞的Entropy Source。&lt;br&gt;在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。&lt;br&gt;加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。&lt;br&gt;
    
    </summary>
    
    
      <category term="tomcat" scheme="https://tokerr.github.io/tags/tomcat/"/>
    
  </entry>
  
  <entry>
    <title>HDFS架构及其执行原理</title>
    <link href="https://tokerr.github.io/2017/10/18/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/"/>
    <id>https://tokerr.github.io/2017/10/18/HDFS架构极其执行原理/</id>
    <published>2017-10-18T09:18:35.000Z</published>
    <updated>2019-05-01T13:51:07.472Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、前言："><a href="#一、前言：" class="headerlink" title="一、前言："></a>一、前言：</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。</p><h3 id="1-1、名词复习"><a href="#1-1、名词复习" class="headerlink" title="1.1、名词复习"></a>1.1、名词复习</h3><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统）<br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统）</p><pre><code>内部主从结构•主节点，只有一个: namenode•从节点，有很多个: datanode</code></pre><p> <strong>namenode负责：</strong><br><br><a id="more"></a></p><ul><li>接收用户操作请求</li><li>维护文件系统的目录结构</li><li><p>管理文件与block之间关系，block与datanode之间关系<br></p><p><strong>datanode负责：</strong></p></li><li><p>存储文件</p></li><li>文件被分成block存储在磁盘上</li><li>为保证数据安全，文件会有多个副本</li></ul><p>备注：还有另外一个SecondaryNameNode，作为NameNode的辅助组件，但是不能替代NameNode，下面会简单的介绍。</p><h3 id="1-2、Hadoop1-0和hadop2-0的对比"><a href="#1-2、Hadoop1-0和hadop2-0的对比" class="headerlink" title="1.2、Hadoop1.0和hadop2.0的对比"></a>1.2、Hadoop1.0和hadop2.0的对比</h3><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/1.png" alt=""></p><h2 id="二、分布式文件系统与HDFS"><a href="#二、分布式文件系统与HDFS" class="headerlink" title="二、分布式文件系统与HDFS"></a>二、分布式文件系统与HDFS</h2><ul><li><p>数据量越来越多，在一个操作系统管辖的范围存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，因此迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统 。</p></li><li><p>是一种允许文件通过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。</p></li><li><p>通透性。让实际上是通过网络来访问文件的动作，由程序与用户看来，就像是访问本地的磁盘一般。</p></li><li><p>容错。即使系统中有某些节点脱机，整体来说系统仍然可以持续运作而不会有数据损失。</p></li><li><p>分布式文件管理系统很多，hdfs只是其中一种。适用于一次写入多次查询的情况，不支持并发写情况，小文件不合适。</p></li></ul><h2 id="三、HDFS体系结构与基本概念"><a href="#三、HDFS体系结构与基本概念" class="headerlink" title="三、HDFS体系结构与基本概念"></a>三、HDFS体系结构与基本概念</h2><h3 id="3-1-HDFS架构"><a href="#3-1-HDFS架构" class="headerlink" title="3.1 HDFS架构"></a>3.1 HDFS架构</h3><p>包括NameNode，DataNode，Secondary NameNode</p><h3 id="3-2-原理图"><a href="#3-2-原理图" class="headerlink" title="3.2 原理图"></a>3.2 原理图</h3><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/2.jpg" alt=""></p><h3 id="3-3-NameNode"><a href="#3-3-NameNode" class="headerlink" title="3.3 NameNode"></a>3.3 NameNode</h3><p>是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求。</p><pre><code>文件包括(hdfs-site.xml的dfs.name.dir属性)：fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。edits:操作日志文件。fstime:保存最近一次checkpoint的时间以上这些文件是保存在linux的文件系统中。</code></pre><p>NameNode工作特点：</p><ul><li>Namenode始终在内存中保存metedata，用于处理“读请求”</li><li>到有“写请求”到来时，namenode会首先写editlog到磁盘，即向edits文件中写日志，成功返回后，才会修改内存，并且向客户端返回</li><li>Hadoop会维护一个fsimage文件，也就是namenode中metedata的镜像，但是fsimage不会随时与namenode内存中的metedata保持一致，而是每隔一段时间通过合并edits文件来更新内容。Secondary namenode就是用来合并fsimage和edits文件来更新NameNode的metedata的。</li></ul><h3 id="3-4-SecondaryNameNode"><a href="#3-4-SecondaryNameNode" class="headerlink" title="3.4 SecondaryNameNode"></a>3.4 SecondaryNameNode</h3><ul><li>HA的一个解决方案。但不支持热备。配置即可。</li><li>执行过程：从NameNode上下载元数据信息（fsimage,edits），然后把二者合并，生成新的fsimage，在本地保存，并将其推送到NameNode，替换旧的fsimage.</li><li>默认在安装在NameNode节点上，但这样…不安全！</li></ul><p>SecondaryNameNode工作流程：</p><ol><li>secondary通知namenode切换edits文件</li><li>secondary从namenode获得fsimage和edits(通过http)</li><li>secondary将fsimage载入内存，然后开始合并edits</li><li>secondary将新的fsimage发回给namenode</li><li>namenode用新的fsimage替换旧的fsimage</li></ol><p>下图是NameNode和SecondaryNameNode工作相互协调的过程：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/3.png" alt=""></p><h3 id="3-5-DataNode"><a href="#3-5-DataNode" class="headerlink" title="3.5 DataNode"></a>3.5 DataNode</h3><ul><li>提供真实文件数据的存储服务。</li><li>文件块（block）：最基本的存储单位。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB，以一个256MB文件，共有256/128=2个Block.</li><li>不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间</li><li>Replication。多复本。默认是三个。</li></ul><h2 id="四、HDFS的shell操作"><a href="#四、HDFS的shell操作" class="headerlink" title="四、HDFS的shell操作"></a>四、HDFS的shell操作</h2><ul><li>调用文件系统(FS)Shell命令应使用bin/hadoop fs 的形式。</li><li>所有的FS shell命令使用URI路径作为参数。</li><li>URI格式是scheme://authority/。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。</li><li>例如：/parent/child可以表示成hdfs://namenode:namenodePort/parent/child，或者更简单的/parent/child（假设配置文件是namenode:namenodePort）</li><li>大多数FS Shell命令的行为和对应的Unix Shell命令类似。</li></ul><p>HDFS   fs命令</p><pre><code>-help [cmd]    //显示命令的帮助信息-ls(r) &lt;path&gt;    //显示当前目录下所有文件-du(s) &lt;path&gt;    //显示目录中所有文件大小-count[-q] &lt;path&gt;    //显示目录中文件数量-mv &lt;src&gt; &lt;dst&gt;    //移动多个文件到目标目录-cp &lt;src&gt; &lt;dst&gt;    //复制多个文件到目标目录-rm(r)        //删除文件(夹)-put &lt;localsrc&gt; &lt;dst&gt;    //本地文件复制到hdfs-copyFromLocal    //同put-moveFromLocal    //从本地文件移动到hdfs-get [-ignoreCrc] &lt;src&gt; &lt;localdst&gt;    //复制文件到本地，可以忽略crc校验-getmerge &lt;src&gt; &lt;localdst&gt;        //将源目录中的所有文件排序合并到一个文件中-cat &lt;src&gt;    //在终端显示文件内容-text &lt;src&gt;    //在终端显示文件内容-copyToLocal [-ignoreCrc] &lt;src&gt; &lt;localdst&gt;    //复制到本地-moveToLocal &lt;src&gt; &lt;localdst&gt;-mkdir &lt;path&gt;    //创建文件夹-touchz &lt;path&gt;    //创建一个空文件</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、前言：&quot;&gt;&lt;a href=&quot;#一、前言：&quot; class=&quot;headerlink&quot; title=&quot;一、前言：&quot;&gt;&lt;/a&gt;一、前言：&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。&lt;/p&gt;
&lt;h3 id=&quot;1-1、名词复习&quot;&gt;&lt;a href=&quot;#1-1、名词复习&quot; class=&quot;headerlink&quot; title=&quot;1.1、名词复习&quot;&gt;&lt;/a&gt;1.1、名词复习&lt;/h3&gt;&lt;p&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统）&lt;br&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;内部主从结构
•主节点，只有一个: namenode
•从节点，有很多个: datanode
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; &lt;strong&gt;namenode负责：&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="HDFS" scheme="https://tokerr.github.io/tags/HDFS/"/>
    
      <category term="YARN" scheme="https://tokerr.github.io/tags/YARN/"/>
    
  </entry>
  
  <entry>
    <title>Shuffle工作机制</title>
    <link href="https://tokerr.github.io/2017/10/16/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
    <id>https://tokerr.github.io/2017/10/16/Shuffle工作机制/</id>
    <published>2017-10-16T15:41:34.000Z</published>
    <updated>2019-05-01T13:51:07.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。</p><h2 id="二、什么是Shuffle"><a href="#二、什么是Shuffle" class="headerlink" title="二、什么是Shuffle?"></a>二、什么是Shuffle?</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/1.png" alt="MapReducer执行原理"><br><a id="more"></a></p><h2 id="三、Shuffle工作机制："><a href="#三、Shuffle工作机制：" class="headerlink" title="三、Shuffle工作机制："></a>三、Shuffle工作机制：</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从map端的输出开始。map函数开始产生输出时，不是简单地将它写到磁盘。这个过程更复杂，它利用缓冲的方式写到内存，井出于效率的考虑进行预排序。下图展示了这个过程每个map任务都有一个环形内存缓冲区，用于存储任务的输出。默认情况下，缓冲区的大为100MB，此值可以通过改变io.sort.mb属性来调整。一旦缓冲内容达到闹值(io.sort.spill.percent，默认为0.80，或80%)，一个后台线程便开始把内容写到(spill)磁盘中。在写磁盘过程中，map输出继续被写到缓冲区，但如果在此期间缓冲区被填楠，map会阻塞直到写磁盘过程完成。写磁盘将按轮询方式写到mapred.local.dir属性指定的作业特定子目录中的目录中。<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/2.png" alt="Shuffle工作机制"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在map输出写磁盘之前，线程首先根据数据最终要传送到的reducer把数据划分成相应的分区(partition)。在每个分区中，后台线程按键进行内排序，如果有一个combiner，它会在排序后的输出上运行。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦内存缓冲区达到溢出写的阀值，就会新建一个溢出写文件，因此在map任务写完其最后一个输出记录之后，会有几个溢出写文件。在任务完成之前，溢出写文件被合并成一个已分区且已排序的输出文件。配置属性io.sort.factor控制着一次最多能合并多少流，默认值是10.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果已经指定combiner，并且溢出写次数至少为3(min.num.spills.for.combine属性的取值)肘，则combiner就会在输出文件写到磁盘之前运行。combiner可以在输入上反复运行，如果combiner可拔插，添加Combiner绝不能改变最终的计算结果;不排除使用combiner作为在map端过滤数据的用途，比如空字符串或者其他无效的参数，这会影响reducer的计算结果。运行combiner的意义在于使map输出更紧凑，使得写到本地磁盘和传给reducer的数据更少。写盘时压缩map输出可以提高效率，因为这样会让写磁盘的速度更快，节约磁盘空间，并且减少传给reducer的数据量。默认情况下，输出是不压缩的，但只要将mapred.compress.map.output设置为true，就可以启用此功能。使用的压缩库库mapred.map.output.compression.codec指定.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，reducer通过HTTP方式得到输出文件的分区。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。&lt;/br&gt;&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。&lt;/br&gt;&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。&lt;/p&gt;
&lt;h2 id=&quot;二、什么是Shuffle&quot;&gt;&lt;a href=&quot;#二、什么是Shuffle&quot; class=&quot;headerlink&quot; title=&quot;二、什么是Shuffle?&quot;&gt;&lt;/a&gt;二、什么是Shuffle?&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/markdownImage/master/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/1.png&quot; alt=&quot;MapReducer执行原理&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="MapReducer" scheme="https://tokerr.github.io/tags/MapReducer/"/>
    
      <category term="Shuffle" scheme="https://tokerr.github.io/tags/Shuffle/"/>
    
  </entry>
  
  <entry>
    <title>Jquery防止Ajax重复提交解决方案</title>
    <link href="https://tokerr.github.io/2017/10/09/Jquery%E9%98%B2%E6%AD%A2Ajax%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://tokerr.github.io/2017/10/09/Jquery防止Ajax重复提交解决方案/</id>
    <published>2017-10-09T15:15:34.000Z</published>
    <updated>2019-05-01T13:51:07.474Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h3><p>不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。</p><h2 id="二、直接上代码"><a href="#二、直接上代码" class="headerlink" title="二、直接上代码"></a>二、直接上代码</h2><pre><code>/*** jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理*/$(function(){var pendingRequests = {};// 所有ajax请求的通用前置filter$.ajaxPrefilter(function( options, originalOptions, jqXHR ) {var key = generatePendingRequestKey(options);</code></pre><a id="more"></a>    <pre><code>//请求是否已经存在if(!pendingRequests[key]){storePendingRequest(key,jqXHR);}else{//如果ajax请求已经存在，下一次相同的请求则取消，防止重复请求jqXHR.abort();}//ajax请求完成时，从临时对象中清除请求对应的数据var complete = options.complete;options.complete = function(jqXHR, textStatus) {//延时1000毫秒删除请求信息，表示同Key值请求不能在此时间段内重复提交setTimeout(function(){delete pendingRequests[jqXHR.pendingRequestKey];},1000);if ($.isFunction(complete)) {complete.apply(this, arguments);}};//统一的错误处理var error = options.error;options.error = function(jqXHR, textStatus) {errorHandler(jqXHR, textStatus);if ($.isFunction(error)) {error.apply(this, arguments);}};});/*** 当ajax请求发生错误时，统一进行拦截处理的方法*/function errorHandler(jqXHR, textStatus){switch (jqXHR.status){case(500):internalError(jqXHR);break;case(403):accessDenied(jqXHR);break;case(408):timeoutError(jqXHR);break;case(404):pageNotFound(jqXHR);break;default://otherError(jqXHR, textStatus);}}function pageNotFound(jqXHR){Component.warningMessageBox({content:&quot;请求访问的地址或内容不存在！&quot;});}function accessDenied(jqXHR){Component.warningMessageBox({content:&quot;你无权进行此操作或页面访问！&quot;});}function internalError(jqXHR){Component.warningMessageBox({content:&quot;服务器存在错误，未能正确处理你的请求！&quot;});}function timeoutError(jqXHR){window.location.href=contextPath + &quot;/j_spring_security_logout&quot;;}function otherError(jqXHR, textStatus){Component.warningMessageBox({content:&quot;未知错误，错误代码：&quot; + textStatus});}/*** 将ajax请求存储到临时对象中，用于根据key判断请求是否已经存在*/function storePendingRequest(key, jqXHR){pendingRequests[key] = jqXHR;jqXHR.pendingRequestKey = key;}/*** 根据ajax请求参数构建一个临时存储key,此处简单的使用url作为key，* 不考虑为解决请求类型为get时相同路径引起的缓存问题，采用随机码构建URL的情况*/function generatePendingRequestKey(options){return options.url;}});</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h3&gt;&lt;p&gt;不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。&lt;/p&gt;
&lt;h2 id=&quot;二、直接上代码&quot;&gt;&lt;a href=&quot;#二、直接上代码&quot; class=&quot;headerlink&quot; title=&quot;二、直接上代码&quot;&gt;&lt;/a&gt;二、直接上代码&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;/**
* jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理
*/
$(function(){
var pendingRequests = {};
// 所有ajax请求的通用前置filter
$.ajaxPrefilter(function( options, originalOptions, jqXHR ) {
var key = generatePendingRequestKey(options);
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="jquery" scheme="https://tokerr.github.io/tags/jquery/"/>
    
      <category term="ajax" scheme="https://tokerr.github.io/tags/ajax/"/>
    
  </entry>
  
  <entry>
    <title>子查询的方式实现sql语句的先排序后分组</title>
    <link href="https://tokerr.github.io/2017/06/22/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/"/>
    <id>https://tokerr.github.io/2017/06/22/子查询的方式实现sql语句的先排序后分组/</id>
    <published>2017-06-22T13:18:36.000Z</published>
    <updated>2019-05-01T13:51:07.479Z</updated>
    
    <content type="html"><![CDATA[<h3 id="需求："><a href="#需求：" class="headerlink" title="需求："></a>需求：</h3><p>查询学生表当中每一门课程成绩最高的记录。</p><h3 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h3><p>先按分数对记录进行降序，然后按照课程进行分组即可实现。<br><a id="more"></a><br>Student表结构：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/1.png" alt=""></p><p>现在手动添加如下数据进去：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/2.png" alt=""></p><p>起初，按照原来的思路，我编写的sql语句如下图(第一句)，得到的结果却不是我们想要的，可以看到group by字句先于Order by执行了，效果如图(下一部分)：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/3.png" alt=""></p><p>因此，使用子查询的方式先对数据进行降序，对新的结果集给一个别名，然后再按课程进行分组，如下：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/4.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;需求：&quot;&gt;&lt;a href=&quot;#需求：&quot; class=&quot;headerlink&quot; title=&quot;需求：&quot;&gt;&lt;/a&gt;需求：&lt;/h3&gt;&lt;p&gt;查询学生表当中每一门课程成绩最高的记录。&lt;/p&gt;
&lt;h3 id=&quot;思路：&quot;&gt;&lt;a href=&quot;#思路：&quot; class=&quot;headerlink&quot; title=&quot;思路：&quot;&gt;&lt;/a&gt;思路：&lt;/h3&gt;&lt;p&gt;先按分数对记录进行降序，然后按照课程进行分组即可实现。&lt;br&gt;
    
    </summary>
    
    
      <category term="sql" scheme="https://tokerr.github.io/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>String类型两种创建对象的方式的内存分配</title>
    <link href="https://tokerr.github.io/2017/06/04/String%E7%B1%BB%E5%9E%8B%E4%B8%A4%E7%A7%8D%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E5%BC%8F%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"/>
    <id>https://tokerr.github.io/2017/06/04/String类型两种创建对象的方式的内存分配/</id>
    <published>2017-06-04T15:25:47.000Z</published>
    <updated>2019-05-01T13:51:07.476Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一张图就可以看明白"><a href="#一张图就可以看明白" class="headerlink" title="一张图就可以看明白"></a>一张图就可以看明白</h3><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/String%E7%B1%BB%E5%9E%8B%E4%B8%A4%E7%A7%8D%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%96%B9%E5%BC%8F%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/%E5%AD%97%E7%AC%A6%E4%B8%B2%20%E7%9A%84%E5%88%9B%E5%BB%BA%E6%96%B9%E5%BC%8F.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一张图就可以看明白&quot;&gt;&lt;a href=&quot;#一张图就可以看明白&quot; class=&quot;headerlink&quot; title=&quot;一张图就可以看明白&quot;&gt;&lt;/a&gt;一张图就可以看明白&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.co
      
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="String" scheme="https://tokerr.github.io/tags/String/"/>
    
  </entry>
  
  <entry>
    <title>Java运行时异常和非运行时异常</title>
    <link href="https://tokerr.github.io/2017/05/28/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8%E5%92%8C%E9%9D%9E%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8/"/>
    <id>https://tokerr.github.io/2017/05/28/Java运行时异常和非运行时异常/</id>
    <published>2017-05-28T02:21:04.000Z</published>
    <updated>2019-05-01T13:51:07.474Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Java异常机制"><a href="#1-Java异常机制" class="headerlink" title="1.Java异常机制"></a>1.Java异常机制</h1><p>Java把异常当做对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。Java中的异常分为两大类：错误Error和异常Exception，Java异常体系结构如下图所示：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8%E5%92%8C%E9%9D%9E%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8/Image.jpg" alt=""></p><h1 id="2-Throwable"><a href="#2-Throwable" class="headerlink" title="2.Throwable"></a>2.Throwable</h1><p>Throwable类是所有异常或错误的超类，它有两个子类：Error和Exception，分别表示错误和异常。其中异常Exception分为运行时异常(RuntimeException)和非运行时异常，也称之为不检查异常(Unchecked Exception)和检查异常(Checked Exception)。</p><h1 id="3-Error"><a href="#3-Error" class="headerlink" title="3.Error"></a>3.Error</h1><p>一般是指java虚拟机相关的问题，如系统崩溃、虚拟机出错误、动态链接失败等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常应用程序无法处理这些错误，因此应用程序不应该捕获Error对象，也无须在其throws子句中声明该方法抛出任何Error或其子类。<br><a id="more"></a></p><h1 id="4-可查异常和不可查异常"><a href="#4-可查异常和不可查异常" class="headerlink" title="4.可查异常和不可查异常"></a>4.可查异常和不可查异常</h1><p>通常，Java的异常(包括Exception和Error)分为可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）。<br>可查异常（编译器要求必须处置的异常）：正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。<br>除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。<br>不可查异常(编译器不要求强制处置的异常):包括运行时异常（RuntimeException与其子类）和错误（Error）。<br>如果使用throw在方法体中抛出可查异常，则需要在方法头部声明方法可能抛出的异常类型。程序会在throw语句后立即终止，它后面的语句执行不到，然后在包含它的所有try块中（可能在上层调用函数中）从里向外寻找含有与其匹配的catch子句的try块。</p><h1 id="5-运行时异常和非运行时异常"><a href="#5-运行时异常和非运行时异常" class="headerlink" title="5.运行时异常和非运行时异常"></a>5.运行时异常和非运行时异常</h1><p>(1)运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。<br>当出现RuntimeException的时候，我们可以不处理。当出现这样的异常时，总是由虚拟机接管。比如：我们从来没有人去处理过NullPointerException异常，它就是运行时异常，并且这种异常还是最常见的异常之一。<br>出现运行时异常后，如果没有捕获处理这个异常（即没有catch），系统会把异常一直往上层抛，一直到最上层，如果是多线程就由Thread.run()抛出，如果是单线程就被main()抛出。抛出之后，如果是线程，这个线程也就退出了。如果是主程序抛出的异常，那么这整个程序也就退出了。运行时异常是Exception的子类，也有一般异常的特点，是可以被catch块处理的。只不过往往我们不对他处理罢了。也就是说，你如果不对运行时异常进行处理，那么出现运行时异常之后，要么是线程中止，要么是主程序终止。<br>如果不想终止，则必须捕获所有的运行时异常，决不让这个处理线程退出。队列里面出现异常数据了，正常的处理应该是把异常数据舍弃，然后记录日志。不应该由于异常数据而影响下面对正常数据的处理。</p><p>(2)非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。如IOException、SQLException等以及用户自定义的Exception异常。对于这种异常，JAVA编译器强制要求我们必需对出现的这些异常进行catch并处理，否则程序就不能编译通过。所以，面对这种异常不管我们是否愿意，只能自己去写一大堆catch块去处理可能的异常。</p><h1 id="6-finally关键字"><a href="#6-finally关键字" class="headerlink" title="6.finally关键字"></a>6.finally关键字</h1><p>来看看下面这个test1()方法：</p><pre><code>public int test1() {          try {              return 1;          } finally {              return 2;          }      }</code></pre><p>方法test1将返回2；</p><p>怎么解释呢？再来看看下面这个test2()方法：</p><pre><code>public int test2() {          int i = 1;          try {              System.out.println(&quot;try语句块中&quot;);              return 1;          } finally {              System.out.println(&quot;finally语句块中&quot;);              return 2;          }      }  </code></pre><p>运行结果是：</p><pre><code>try语句块中finally语句块中2</code></pre><p>从运行结果中可以发现，try中的return语句调用的函数先于finally中调用的函数执行，也就是说return语句先执行，finally语句后执行，所以，返回的结果是2。return并不是让函数马上返回，而是return语句执行后，将把返回结果放置进函数栈中，此时函数并不是马上返回，它要执行finally语句后才真正开始返回。</p><h1 id="常见RuntimeException："><a href="#常见RuntimeException：" class="headerlink" title="常见RuntimeException："></a>常见RuntimeException：</h1><pre><code>ArrayStoreException                试图将错误类型的对象存储到一个对象数组时抛出的异常ClassCastException                试图将对象强制转换为不是实例的子类时，抛出该异常IllegalArgumentException         抛出的异常表明向方法传递了一个不合法或不正确的参数IndexOutOfBoundsException   指示某排序索引（例如对数组、字符串或向量的排序）超出范围时抛出NoSuchElementException       表明枚举中没有更多的元素NullPointerException                当应用程序试图在需要对象的地方使用 null 时，抛出该异常</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-Java异常机制&quot;&gt;&lt;a href=&quot;#1-Java异常机制&quot; class=&quot;headerlink&quot; title=&quot;1.Java异常机制&quot;&gt;&lt;/a&gt;1.Java异常机制&lt;/h1&gt;&lt;p&gt;Java把异常当做对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。Java中的异常分为两大类：错误Error和异常Exception，Java异常体系结构如下图所示：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/markdownImage/master/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8%E5%92%8C%E9%9D%9E%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BC%82%E5%B8%B8/Image.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;2-Throwable&quot;&gt;&lt;a href=&quot;#2-Throwable&quot; class=&quot;headerlink&quot; title=&quot;2.Throwable&quot;&gt;&lt;/a&gt;2.Throwable&lt;/h1&gt;&lt;p&gt;Throwable类是所有异常或错误的超类，它有两个子类：Error和Exception，分别表示错误和异常。其中异常Exception分为运行时异常(RuntimeException)和非运行时异常，也称之为不检查异常(Unchecked Exception)和检查异常(Checked Exception)。&lt;/p&gt;
&lt;h1 id=&quot;3-Error&quot;&gt;&lt;a href=&quot;#3-Error&quot; class=&quot;headerlink&quot; title=&quot;3.Error&quot;&gt;&lt;/a&gt;3.Error&lt;/h1&gt;&lt;p&gt;一般是指java虚拟机相关的问题，如系统崩溃、虚拟机出错误、动态链接失败等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常应用程序无法处理这些错误，因此应用程序不应该捕获Error对象，也无须在其throws子句中声明该方法抛出任何Error或其子类。&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="exception" scheme="https://tokerr.github.io/tags/exception/"/>
    
      <category term="异常" scheme="https://tokerr.github.io/tags/%E5%BC%82%E5%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>mybatis连接oracle执行sql语句出现ORA-00904: invalid identifier</title>
    <link href="https://tokerr.github.io/2017/05/07/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/"/>
    <id>https://tokerr.github.io/2017/05/07/mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier/</id>
    <published>2017-05-07T10:03:30.000Z</published>
    <updated>2019-05-01T13:51:07.477Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、总结"><a href="#一、总结" class="headerlink" title="一、总结"></a>一、总结</h1><p>使用mybatis连接oracle数据库进行查询，最好确保<strong>表命全大写</strong>，否者会出现ORA-00904: invalid identifier的问题</p><p>注：本人使用的mybatis版本是3.0.5</p><h1 id="二、问题描述："><a href="#二、问题描述：" class="headerlink" title="二、问题描述："></a>二、问题描述：</h1><p> 我使用ibator工具产生的代码，有一个Dao的测试类，但是一执行就出现了ORA-00904: invalid identifier，如图：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image1.png" alt=""><br> <a id="more"></a><br>原因分析，大部分情况下是由于引用了不存在的列名导致的。 解决的办法就是检查自己引用的列名称是否一致。对于某些工具生成的sql，可能导致列名称和期望不符的情况，比如，有些工具生成的列名称会带双引号，从而导致此错误。</p><p>经过查询和本人的实践验证，oracle执行查询时（这里以11g为例），对于特殊的字段命名有着非常严格的语法要求，如果是字段名称按照单词首字母大写的规范进行命名，在进行条件查询的时候必须，字段名称必须与原来命名一样并且要加上双引号，否则会包ORA-00904: invalid identifier。以下是本案例的测试截图：</p><p>表结构：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image2.png" alt=""></p><p>执行查询：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image3.png" alt=""></p><p>从执行的结果可以知道，最终oracle在执行sql语句的时候把条件查询的字段名转成了全大写，遇到表中没有找到相关的字段(区分大小写)，就出现了此错误。查询指定字段的值也是如此：</p><p>表结构：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image4.png" alt=""></p><p>执行查询：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image5.png" alt=""></p><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image6.png" alt=""></p><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image7.png" alt=""></p><h1 id="三、解决办法"><a href="#三、解决办法" class="headerlink" title="三、解决办法"></a>三、解决办法</h1><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p> 3.1oracle在执行sql语句进行查询的时候，默认的情况下(查询的时候不给字段加双引号)，会将字段名称转换成全大写之后再到表中进行匹配查询，比如：执行select <em> from dept where id=1，则实际执行的是:select </em> from DEPT where ID=1，这里表名和字段名全部都会转成全大写去匹配查询，一旦匹配不到(真正匹配字段名和名的时候区分大小写)，则会报错误。</p><p> 3.2如果设计表的时候不想表名和字段名都全大写，则在进行查询的时候需要在表名或者字段名称加上双引号(相当于告知oracle不要对sql语句中指定的表名或者字段名转成全大写)，并且区分大小写，这样执行查询才不会发生错误。</p><p>##解决方法##<br>因此解决的办法就是，在给字段名称进行命名的时候，建议全大写，对于表名也是全大写命名，这样不管是进行条件查询还是查询指定字段的名称的时候，都不需要严格区分大小写了并且还要加上双引号了，Oracle会自动帮你先转成全大写之后再进行匹配查询。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、总结&quot;&gt;&lt;a href=&quot;#一、总结&quot; class=&quot;headerlink&quot; title=&quot;一、总结&quot;&gt;&lt;/a&gt;一、总结&lt;/h1&gt;&lt;p&gt;使用mybatis连接oracle数据库进行查询，最好确保&lt;strong&gt;表命全大写&lt;/strong&gt;，否者会出现ORA-00904: invalid identifier的问题&lt;/p&gt;
&lt;p&gt;注：本人使用的mybatis版本是3.0.5&lt;/p&gt;
&lt;h1 id=&quot;二、问题描述：&quot;&gt;&lt;a href=&quot;#二、问题描述：&quot; class=&quot;headerlink&quot; title=&quot;二、问题描述：&quot;&gt;&lt;/a&gt;二、问题描述：&lt;/h1&gt;&lt;p&gt; 我使用ibator工具产生的代码，有一个Dao的测试类，但是一执行就出现了ORA-00904: invalid identifier，如图：&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/markdownImage/master/mybatis%E8%BF%9E%E6%8E%A5oracle%E6%89%A7%E8%A1%8Csql%E8%AF%AD%E5%8F%A5%E5%87%BA%E7%8E%B0ORA-00904-invalid-identifier/Image1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="mybatis" scheme="https://tokerr.github.io/tags/mybatis/"/>
    
      <category term="oracle" scheme="https://tokerr.github.io/tags/oracle/"/>
    
  </entry>
  
  <entry>
    <title>使用ibator无法根据oracle数据库中的表结构产生代码[解决方法]</title>
    <link href="https://tokerr.github.io/2017/05/06/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8ibator%E5%B7%A5%E5%85%B7%E8%BF%9E%E6%8E%A5oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E7%9A%84%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/"/>
    <id>https://tokerr.github.io/2017/05/06/关于使用ibator工具连接oracle数据库生成代码的使用问题/</id>
    <published>2017-05-06T11:11:35.000Z</published>
    <updated>2019-05-01T13:51:07.479Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、总结"><a href="#一、总结" class="headerlink" title="一、总结"></a>一、总结</h1><p><strong>使用ibator根据oracle中的表结构生成代码时，一定要确保每张表的表命全大写，否则生成失败</strong>     </p><h1 id="二、问题描述"><a href="#二、问题描述" class="headerlink" title="二、问题描述"></a>二、问题描述</h1><p>想说的已经在上面描述出来了。下面描述问题的由来已经解决的过程：</p><p>就是下面这个工具，我已经集成到了Myeclipse当中<br><a id="more"></a><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8ibator%E5%B7%A5%E5%85%B7%E8%BF%9E%E6%8E%A5oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E7%9A%84%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/Image1.png" alt=""></p><p>以前开始使用的都是mysql数据库，表的名称都是按照首字母大写的规范进行设计，这次的毕业设计项目使用到的是oracle，因为设计表的时候表明也是按照每个单词的首字母大写进行命名的，但是没想到，在使用ibator代码生成器生成pojo 的时候，居然失败的，而且这个问题一直困扰了我一个多月，并且百度谷歌搜索都无果，让我百思不得其解。直到今天在做毕业设计的时候，终于让我把这个问题解决了。</p><p>万幸在于，让我发现突破这个问题的关键只所在，在某一次使用这个工具对oracle中的某一张表进行操作的时候成功了(这是在本地真机上的oracle)。之前我把oracle服务器安装在电脑的虚拟机，装的是oracle10g，在使用ibator就出现了这个问题，一直怀疑是可能是因为远程的问题，或者oracle是10G不是oracle11g的版本问题，我就在真机上面装了个oracle11g的数据库，测试的时候自己阴差阳错，建表的sql语句是网上复制过来了，并且表明刚好是全大写，因此那一次就测试成功了。但今天在真机的数据库建表，表名按照单词的首字母大写命名，因此又出现了这个问题。但幸好，经过一番测试对比，终于发现原因之所在，可以说是ibator这个工具的bug吧。</p><p>另外，个人惰性思维一发作，真的是可以让人变傻。只通过自己的怀疑推测，而没有经过实践的检验，就下定结论，这是我在这个问题上思维懒惰的一个很好体现，自己下定论千万不要去推测去瞎猜，一定是要在经过实际的检验之后。另一方面是要多思考，出现这个问题的时候我就是怀疑，是因为远程的原因 或者是因为oracle版本的原因，思维懒惰的结果就是我把自己的猜测当成了自己的结论，并以此去指导自己的行为(觉得自己好悲催，问题很严重)，而从没有进一步想过，之前公司的项目也是远程的Mysql数据库使用ibator生成代码的，使用没有问题，这样就可以排除是因为远程的问题导致ibator不可以用了呀；还有怀疑是因为数据库版本的问题，竟然数据库已经成功安装，可以整成使用，跟版本有多大的联系吗？这点就不能排除了，呵呵。</p><p><strong>总之，在使用ibator获取oracle中的表结果生成代码时，一定要确保表名全大写；字段名称的命名的话，经过我的测验，字段名称全大写或者按照单词首字母大写的方式命名也是没有问题的，最终生成的pojo属性名都是全小写。</strong></p><p>三、关于ibator集成到myeclipse<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8ibator%E5%B7%A5%E5%85%B7%E8%BF%9E%E6%8E%A5oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E7%9A%84%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/Image2.png" alt=""><br>直接把截图上面的两个文件扔到myeclipse安装目录下的dropins文件夹就可以了，这里提供文件的连接，我都已经打包到一起了，解压即可。<a href="https://github.com/tokerr/markdownImage/raw/master/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8ibator%E5%B7%A5%E5%85%B7%E8%BF%9E%E6%8E%A5oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%9F%E6%88%90%E4%BB%A3%E7%A0%81%E7%9A%84%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98/ibator_3.0.6.full.zip" target="_blank" rel="external">点我下载</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、总结&quot;&gt;&lt;a href=&quot;#一、总结&quot; class=&quot;headerlink&quot; title=&quot;一、总结&quot;&gt;&lt;/a&gt;一、总结&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;使用ibator根据oracle中的表结构生成代码时，一定要确保每张表的表命全大写，否则生成失败&lt;/strong&gt;     &lt;/p&gt;
&lt;h1 id=&quot;二、问题描述&quot;&gt;&lt;a href=&quot;#二、问题描述&quot; class=&quot;headerlink&quot; title=&quot;二、问题描述&quot;&gt;&lt;/a&gt;二、问题描述&lt;/h1&gt;&lt;p&gt;想说的已经在上面描述出来了。下面描述问题的由来已经解决的过程：&lt;/p&gt;
&lt;p&gt;就是下面这个工具，我已经集成到了Myeclipse当中&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="mybatis" scheme="https://tokerr.github.io/tags/mybatis/"/>
    
      <category term="oracle" scheme="https://tokerr.github.io/tags/oracle/"/>
    
      <category term="ibator" scheme="https://tokerr.github.io/tags/ibator/"/>
    
  </entry>
  
  <entry>
    <title>ORA-12541:TNS:无监听程序</title>
    <link href="https://tokerr.github.io/2017/05/06/ORA-12541-TNS-%E6%97%A0%E7%9B%91%E5%90%AC%E7%A8%8B%E5%BA%8F/"/>
    <id>https://tokerr.github.io/2017/05/06/ORA-12541-TNS-无监听程序/</id>
    <published>2017-05-06T01:43:13.000Z</published>
    <updated>2019-05-01T13:51:07.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、问题描述"><a href="#一、问题描述" class="headerlink" title="一、问题描述"></a>一、问题描述</h2><p>这两天在做毕业设计，项目用到的是oracle数据库，由于之前用的都是mysql，oracle数据库的应用比较少。于是莫名奇妙的出现了个‘ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务’，也是折腾了两天，无果，今天接着是‘ORA-12541:TNS:无监听程序’，在windows系统的cmd上不使用实例名连接倒是可以登录，但是无法进行正常的查询操作。今天按照网上某篇博客的教程，居然把这个问题解决了，关键的一步是 启动tnslsnr，然后问题就解决了。</p><p>其实在今天电脑开始之后，我直接把360安全卫士关闭了，不排除oracle在开机 的时候某些服务被360拦截关闭的情况。</p><h2 id="二、附上cmd的操作日志"><a href="#二、附上cmd的操作日志" class="headerlink" title="二、附上cmd的操作日志"></a>二、附上cmd的操作日志</h2><pre><code>C:\Users\Administrator&gt;sqlplus / as sysdba</code></pre><a id="more"></a>    <pre><code>SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:23:15 2017Copyright (c) 1982, 2010, Oracle.  All rights reserved.连接到:Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL&gt; conn tokerr/tokerr已连接。SQL&gt;SQL&gt; select table_name from user_tables;TABLE_NAME------------------------------------------------------------TESTTABLE1TESTTABLE2TESTTABLE3TESTTABLE4TESTTABLE5SQL&gt; select * form TESTTABLE1;select * form TESTTABLE1         *第 1 行出现错误:ORA-00923: 未找到要求的 FROM 关键字SQL&gt; select * fROM TESTTABLE1;未选定行SQL&gt; select * fROM TESTTABLE2;未选定行SQL&gt; select * fROM TESTTABLE3;未选定行SQL&gt; exit从 Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing options 断开C:\Users\Administrator&gt;sqlplus tokerr/tokerr@orclSQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:27:17 2017Copyright (c) 1982, 2010, Oracle.  All rights reserved.ERROR:ORA-12541: TNS: 无监听程序请输入用户名:C:\Users\Administrator&gt;C:\Users\Administrator&gt;sqlplus / as sysdbaSQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:37:26 2017Copyright (c) 1982, 2010, Oracle.  All rights reserved.连接到:Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL&gt; startupORA-01081: 无法启动已在运行的 ORACLE - 请首先关闭它SQL&gt; 从 Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing options 断开C:\Users\Administrator&gt;lsnrctl statusLSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:39:09Copyright (c) 1991, 2010, Oracle.  All rights reserved.正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误  TNS-00511: 无监听程序   64-bit Windows Error: 2: No such file or directory正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521)))TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误  TNS-00511: 无监听程序   64-bit Windows Error: 61: Unknown errorC:\Users\Administrator&gt;lsnrctl startLSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:39:40Copyright (c) 1991, 2010, Oracle.  All rights reserved.启动tnslsnr: 请稍候...TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production系统参数文件为F:\Ora10InstantClient\listener.ora写入f:\oracledb\diag\tnslsnr\PC-20160512QTJL\listener\alert\log.xml的日志信息监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\.\pipe\EXTPROC1521ipc)))监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521)))正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))LISTENER 的 STATUS------------------------别名                      LISTENER版本                      TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production启动日期                  06-5月 -2017 09:39:46正常运行时间              0 天 0 小时 0 分 8 秒跟踪级别                  off安全性                    ON: Local OS AuthenticationSNMP                      OFF监听程序参数文件          F:\Ora10InstantClient\listener.ora监听程序日志文件          f:\oracledb\diag\tnslsnr\PC-20160512QTJL\listener\alert\log.xml监听端点概要...  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\.\pipe\EXTPROC1521ipc)))  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521)))服务摘要..服务 &quot;CLRExtProc&quot; 包含 1 个实例。  实例 &quot;CLRExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...服务 &quot;orcl&quot; 包含 1 个实例。  实例 &quot;orcl&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...命令执行成功C:\Users\Administrator&gt;lsnrctl statusLSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:41:30Copyright (c) 1991, 2010, Oracle.  All rights reserved.正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))LISTENER 的 STATUS------------------------别名                      LISTENER版本                      TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production启动日期                  06-5月 -2017 09:39:46正常运行时间              0 天 0 小时 1 分 48 秒跟踪级别                  off安全性                    ON: Local OS AuthenticationSNMP                      OFF监听程序参数文件          F:\Ora10InstantClient\listener.ora监听程序日志文件          f:\oracledb\diag\tnslsnr\PC-20160512QTJL\listener\alert\log.xml监听端点概要...  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\.\pipe\EXTPROC1521ipc)))  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521)))服务摘要..服务 &quot;CLRExtProc&quot; 包含 1 个实例。  实例 &quot;CLRExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...服务 &quot;orcl&quot; 包含 1 个实例。  实例 &quot;orcl&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...命令执行成功C:\Users\Administrator&gt;sqlplus tokerr/tokerr@orclSQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:41:36 2017Copyright (c) 1982, 2010, Oracle.  All rights reserved.连接到:Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL&gt; select * from TESTTABLES;select * from TESTTABLES              *第 1 行出现错误:ORA-00942: 表或视图不存在SQL&gt; select * from TESTTABLE1;未选定行SQL&gt;</code></pre><h2 id="三、正文"><a href="#三、正文" class="headerlink" title="三、正文"></a>三、正文</h2><p>在用PL/SQL Developer连接数据库时出现<br>“ORA-12541:TNS:无监听程序”错误。</p><h3 id="1、检查listener-log日志"><a href="#1、检查listener-log日志" class="headerlink" title="1、检查listener.log日志"></a>1、检查listener.log日志</h3><p>发现下面错误：</p><pre><code>TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:25:26Copyright (c) 1991, 2005, Oracle. All rights reserved.系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息写入D:/oracle/product/10.2.0/db_1/network/trace/listener.trc的跟踪信息跟踪级别当前为0以 pid=1704 开始监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc)))监听该对象时出错: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521)))TNS-12545: 因目标主机或对象不存在, 连接失败TNS-12560: TNS: 协议适配器错误TNS-00515: 因目标主机或对象不存在, 连接失败32-bit Windows Error: 49: Unknown error不再监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc)))</code></pre><h3 id="2、查看Oracle的listener是否启动"><a href="#2、查看Oracle的listener是否启动" class="headerlink" title="2、查看Oracle的listener是否启动"></a>2、查看Oracle的listener是否启动</h3><pre><code>C:/Documents and Settings/mengzhaoliang&gt;lsnrctl statusLSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:50:44Copyright (c) 1991, 2005, Oracle. All rights reserved.正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1)))TNS-12541: TNS: 无监听程序TNS-12560: TNS: 协议适配器错误TNS-00511: 无监听程序32-bit Windows Error: 2: No such file or directory正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521)))TNS-12535: TNS: 操作超时TNS-12560: TNS: 协议适配器错误TNS-00505: 操作超时32-bit Windows Error: 60: Unknown error</code></pre><p>原来没有启动listener，用“lsnrctl start”命令也不能启动。</p><pre><code>C:/Documents and Settings/mengzhaoliang&gt;lsnrctl startLSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:52:16Copyright (c) 1991, 2005, Oracle. All rights reserved.启动tnslsnr: 请稍候...TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc)))监听该对象时出错: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521)))TNS-12545: 因目标主机或对象不存在, 连接失败TNS-12560: TNS: 协议适配器错误TNS-00515: 因目标主机或对象不存在, 连接失败32-bit Windows Error: 49: Unknown error</code></pre><p>监听程序未能启动。请参阅上面的错误消息…</p><h3 id="3、查看listener-ora的内容："><a href="#3、查看listener-ora的内容：" class="headerlink" title="3、查看listener.ora的内容："></a>3、查看listener.ora的内容：</h3><pre><code># listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER =(SID_LIST =(SID_DESC =(SID_NAME = PLSExtProc)(ORACLE_HOME = D:/oracle/product/10.2.0/db_1)(PROGRAM = extproc)))LISTENER =(DESCRIPTION_LIST =(DESCRIPTION =(ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1))(ADDRESS = (PROTOCOL = TCP)(HOST = 0.5.0.5)(PORT = 1521))))</code></pre><p>原来本机的ip发生改变后，就出现了上述问题，改变数据库的监听ip地址:<br>把<code>(ADDRESS = (PROTOCOL = TCP)(HOST = 0.5.0.5)(PORT = 1521))</code><br>改成<code>(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))</code><br>127.0.0.1：也就是目前数据库正在用的ip地址。</p><h3 id="4、再次启动oracle的listener"><a href="#4、再次启动oracle的listener" class="headerlink" title="4、再次启动oracle的listener"></a>4、再次启动oracle的listener</h3><pre><code>C:/Documents and Settings/mengzhaoliang&gt;lsnrctl startLSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:54:40Copyright (c) 1991, 2005, Oracle. All rights reserved.启动tnslsnr: 请稍候...TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc)))监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521)))正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1)))LISTENER 的 STATUS------------------------别名                      LISTENER版本                      TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production启动日期                  20-9月 -2008 10:54:41正常运行时间              0 天 0 小时 0 分 1 秒跟踪级别                  off安全性                    ON: Local OS AuthenticationSNMP                      OFF监听程序参数文件          D:/oracle/product/10.2.0/db_1/network/admin/listener.ora监听程序日志文件          D:/oracle/product/10.2.0/db_1/network/log/listener.log监听端点概要...(DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc)))(DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521)))服务摘要..服务 &quot;PLSExtProc&quot; 包含 1 个例程。例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...</code></pre><p>命令执行成功</p><p>启动已经成功，</p><h3 id="5-再tnsnames-ora上添加上"><a href="#5-再tnsnames-ora上添加上" class="headerlink" title="5.再tnsnames.ora上添加上"></a>5.再tnsnames.ora上添加上</h3><pre><code>ORCL_127.0.0.1 =(DESCRIPTION =(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))(CONNECT_DATA =(SERVER = DEDICATED)(SERVICE_NAME = orcl)))</code></pre><p>6、再次用PL/SQL Developer再次连接数据库<br>出现下面错误：<br><strong>TNS-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务</strong><br>再次检查listener.log日志</p><pre><code>20-9月 -2008 11:01:54 * (CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=orcl)(CID=(PROGRAM=D:/plsql/plsqldev.exe)(HOST=RUIFEI-EF0ADC98)(USER=mengzhaoliang))) * (ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1267)) * establish * orcl * 12514TNS-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务查看listener：C:/Documents and Settings/mengzhaoliang&gt;lsnrctl servicesLSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:11:09Copyright (c) 1991, 2005, Oracle. All rights reserved.正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1)))服务摘要..服务 &quot;PLSExtProc&quot; 包含 1 个例程。例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...处理程序:&quot;DEDICATED&quot; 已建立:0 已被拒绝:0LOCAL SERVER</code></pre><p>命令执行成功</p><h3 id="7、用sqlplus也出现同样错误："><a href="#7、用sqlplus也出现同样错误：" class="headerlink" title="7、用sqlplus也出现同样错误："></a>7、用sqlplus也出现同样错误：</h3><pre><code>C:/Documents and Settings/mengzhaoliang&gt;sqlplusscott/mzl@ORCL_127.0.0.1SQL*Plus: Release 10.2.0.1.0 - Production on 星期六 9月 20 11:15:09 2008Copyright (c) 1982, 2005, Oracle. All rights reserved.ERROR:ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务</code></pre><h3 id="8、查看listenser状态："><a href="#8、查看listenser状态：" class="headerlink" title="8、查看listenser状态："></a>8、查看listenser状态：</h3><pre><code>C:/Documents and Settings/mengzhaoliang&gt;lsnrctl statusLSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:26:42Copyright (c) 1991, 2005, Oracle. All rights reserved.正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1)))LISTENER 的 STATUS------------------------别名                      LISTENER版本                      TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production启动日期                  20-9月 -2008 11:24:33正常运行时间              0 天 0 小时 2 分 8 秒跟踪级别                  off安全性                    ON: Local OS AuthenticationSNMP                      OFF监听程序参数文件          D:/oracle/product/10.2.0/db_1/network/admin/listener.ora监听程序日志文件          D:/oracle/product/10.2.0/db_1/network/log/listener.log监听端点概要...(DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc)))(DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521)))服务摘要..服务 &quot;PLSExtProc&quot; 包含 1 个例程。例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序...</code></pre><p>命令执行成功</p><pre><code>C:/Documents and Settings/mengzhaoliang&gt;tnsping orclTNS Ping Utility for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:27:43Copyright (c) 1997, 2005, Oracle. All rights reserved.已使用的参数文件:D:/oracle/product/10.2.0/db_1/network/admin/sqlnet.oraTNS-03505: 无法解析名称</code></pre><h3 id="9、查看sqlnet-ora内容："><a href="#9、查看sqlnet-ora内容：" class="headerlink" title="9、查看sqlnet.ora内容："></a>9、查看sqlnet.ora内容：</h3><pre><code># sqlnet.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/sqlnet.ora# Generated by Oracle configuration tools.# This file is actually generated by netca. But if customers choose to# install &quot;Software Only&quot;, this file wont exist and without the native# authentication, they will not be able to connect to the database on NT.SQLNET.AUTHENTICATION_SERVICES= (NTS)NAMES.DIRECTORY_PATH= (TNSNAMES, EZCONNECT)</code></pre><p>10.把listener.ora的内容：</p><pre><code># listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER =(SID_LIST =(SID_DESC =      (SID_NAME = PLSExtProc)(ORACLE_HOME = D:/oracle/product/10.2.0/db_1)      (PROGRAM = extproc)))LISTENER =(DESCRIPTION_LIST =(DESCRIPTION =(ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1))(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))))改成下面的内容：# listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER =(SID_LIST =(SID_DESC =      (SID_NAME = orcl)(ORACLE_HOME = D:/oracle/product/10.2.0/db_1)#      (PROGRAM = extproc)))LISTENER =(DESCRIPTION_LIST =(DESCRIPTION =(ADDRESS = (PROTOCOL = IPC)(KEY = orcl))(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))))</code></pre><h3 id="11、然后关闭、再启动listener"><a href="#11、然后关闭、再启动listener" class="headerlink" title="11、然后关闭、再启动listener"></a>11、然后关闭、再启动listener</h3><p>在cmd中执行“lsnrctl stop” 和“lsnrctl stop”命令，再次登陆正常！</p><pre><code>C:/Documents and Settings/mengzhaoliang&gt;sqlplus scott/mzl@orclSQL*Plus: Release 10.2.0.1.0 - Production on 星期六 9月 20 11:55:47 2008Copyright (c) 1982, 2005, Oracle. All rights reserved.连接到:Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - ProductionWith the Partitioning, OLAP and Data Mining optionsSQL&gt;</code></pre><p>再次用PL/SQL Peveloper登陆就没有问题了。</p><p>完毕!</p><p>我通过以上步骤我的问题还没解决，然后重启了一下<code>OracleOraDb10g_home1TNSListener</code>服务就行了</p><p><a href="http://blog.csdn.net/kobe_lzq/article/details/4846734" target="_blank" rel="external">原文链接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、问题描述&quot;&gt;&lt;a href=&quot;#一、问题描述&quot; class=&quot;headerlink&quot; title=&quot;一、问题描述&quot;&gt;&lt;/a&gt;一、问题描述&lt;/h2&gt;&lt;p&gt;这两天在做毕业设计，项目用到的是oracle数据库，由于之前用的都是mysql，oracle数据库的应用比较少。于是莫名奇妙的出现了个‘ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务’，也是折腾了两天，无果，今天接着是‘ORA-12541:TNS:无监听程序’，在windows系统的cmd上不使用实例名连接倒是可以登录，但是无法进行正常的查询操作。今天按照网上某篇博客的教程，居然把这个问题解决了，关键的一步是 启动tnslsnr，然后问题就解决了。&lt;/p&gt;
&lt;p&gt;其实在今天电脑开始之后，我直接把360安全卫士关闭了，不排除oracle在开机 的时候某些服务被360拦截关闭的情况。&lt;/p&gt;
&lt;h2 id=&quot;二、附上cmd的操作日志&quot;&gt;&lt;a href=&quot;#二、附上cmd的操作日志&quot; class=&quot;headerlink&quot; title=&quot;二、附上cmd的操作日志&quot;&gt;&lt;/a&gt;二、附上cmd的操作日志&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;C:\Users\Administrator&amp;gt;sqlplus / as sysdba
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="https://tokerr.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Oracle" scheme="https://tokerr.github.io/tags/Oracle/"/>
    
  </entry>
  
</feed>
