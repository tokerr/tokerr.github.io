{"meta":{"title":"农永滔的博客","subtitle":"nongyongtao","description":"农永滔的博客","author":"nongyongtao","url":"https://tokerr.github.io"},"pages":[],"posts":[{"title":"Java内存区域与内存溢出异常","slug":"Java内存区域与内存溢出异常","date":"2018-06-02T15:48:41.000Z","updated":"2019-05-01T13:51:07.474Z","comments":true,"path":"2018/06/02/Java内存区域与内存溢出异常/","link":"","permalink":"https://tokerr.github.io/2018/06/02/Java内存区域与内存溢出异常/","excerpt":"前言：Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。 Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。 无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。 通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。","text":"前言：Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。 Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。 无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。 通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和技术而简历和销毁的。Java虚拟所管理的内存区域将会包括一下几个运行时数据区域。 程序计数器介绍:程序计数器(Program counter register)是一块较小的内存控件，它的作用可以看做是当前线程所执行的字节码的行号指示器。 作用：在虚拟机的概念模型里，字节码的解析器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程回复等基础功能都需要依赖这个计数器来完成。 服务对象：由于Java虚拟机的多线程是通过线程的轮流切换并分配处理器执行时间的方式来时间的，在任何一个确定的时刻，一个处理器(对于多核处理器来说是一个内核)只会执行一条线程中的指令。因此，为了线程钱换后能回复到正确的执行为孩子，每条线程都需要有一个独立的程序计数器，各个线程之间的计数器互不影响，独立储存，我们称这块内存区域为”线程私有”的内存。 如果线程正在执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；此内存区域是唯一一个在Java虚拟规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈介绍：与程序计数器一样，Java虚拟机栈(JVM Stacks)也是线程自由的，他的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态连接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应这一个栈帧在虚拟机栈中从入栈和出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型(boolean,byte,char,short,int,float,long,double)、对象引用和returnAddress类型(指向了一条字节码指令的地址)。局部变量表所需要的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况:如果线程的栈深度大于虚拟机所允许的深的，将抛出StackOverflowError异常；如果虚拟机栈可以动态拓展，当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈本地方法栈(Native Method Stacks)与虚拟机栈所发挥的作用是非常的相似，其区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则是为虚拟机使用到的Navite方法服务。 简单地讲，一个Native Method就是一个java调用非java代码的接口，该方法的实现由非java语言实现。 java堆对于大多数的应用，Java堆(Java heap)是java虚拟机所管理的内存中最大的一块。java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例在这里分配内存。 java堆是垃圾收集器管理的主要区域，因此很多时候也被称为”GC堆”。 方法区方法区(Method Area)与java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。 PermGen（永久代）绝大部分 Java 程序员应该都见过 “java.lang.OutOfMemoryError: PermGen space “这个异常。这里的 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在 jsp 页面比较多的情况，容易出现永久代内存溢出。 在 JDK 1.8 中， HotSpot 已经没有 “PermGen space”这个区间了，取而代之是一个叫做 Metaspace（元空间） 的东西。","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://tokerr.github.io/tags/jvm/"},{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"}]},{"title":"hadoop2.9.0 编译源码安装","slug":"hadoop2-9-0-编译源码安装","date":"2017-12-17T11:10:01.000Z","updated":"2019-05-01T13:51:07.476Z","comments":true,"path":"2017/12/17/hadoop2-9-0-编译源码安装/","link":"","permalink":"https://tokerr.github.io/2017/12/17/hadoop2-9-0-编译源码安装/","excerpt":"1.编译基础环境Requirements: * Unix System (我这里使用的是centos 6.8) * JDK 1.8+ * Maven 3.0 or later * Findbugs 1.3.9 (if running findbugs) * ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错） * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac * Zlib devel (if compiling native code) * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance) * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs) * Internet connection for first build (to fetch all Maven and Hadoop dependencies) * python (for releasedocs) * bats (for shell code testing) * Node.js / bower / Ember-cli (for YARN UI v2 building)","text":"1.编译基础环境Requirements: * Unix System (我这里使用的是centos 6.8) * JDK 1.8+ * Maven 3.0 or later * Findbugs 1.3.9 (if running findbugs) * ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错） * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac * Zlib devel (if compiling native code) * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance) * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs) * Internet connection for first build (to fetch all Maven and Hadoop dependencies) * python (for releasedocs) * bats (for shell code testing) * Node.js / bower / Ember-cli (for YARN UI v2 building) 备注：由于这里的教程基本都是使用在线安装的方式，包括后面的使用maven对hadoop2.9的源码进行编译，需要下载依赖包，因此请确保服务器连接外网，如果你使用的是vmware虚拟机，可以参考我另一篇博客 vmware虚拟机host-only下配置与宿主机共享网络。 2.yum 源配置 首先安装wget （已安装则忽略） yum install -y wget 将CentOS的yum源更换为国内的阿里云源，我们使用默认的yum源，有时会连接到国外的镜像站导致yum下载比较慢。，所以将默认的yum源替换为阿里云的镜像站。 阿里云Linux安装镜像源地址：http://mirrors.aliyun.com/ 备份你的原镜像文件，以免出错后可以恢复。 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的CentOS-Base.repo 到/etc/yum.repos.d/ CentOS 5 使用下面的链接 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo CentOS 6 使用下面的链接 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo CentOS 7 使用下面的链接 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 运行yum makecache生成缓存 yum clean all yum makecache 3.yum 安装gcc对于配备了yum的Linux发行版而言，安装gcc编译器就变得so easy。我们只需要分别执行如下命令即可： yum -y install gcc gcc-c++ kernel-devel 4.安装CMake#wget https://cmake.org/files/v3.3/cmake-3.3.2.tar.gz #tar -zxvf cmake-2.8.10.2.tar.gz #cd cmake-2.8.10.2 #./bootstrap #gmake #gmake install 5.下载Hadoop源码包[root@hadoop001 sourcecode]# mkdir -p /opt/sourcecode [root@hadoop001 sourcecode]#wget http://apache.mirrors.tds.net/hadoop/common/stable/hadoop-2.9.0-src.tar.gz [root@hadoop001 sourcecode]#tar -xzvf hadoop-2.9.0-src.tar.gz [root@hadoop001 sourcecode]#cat ./hadoop-2.9.0-src/BUILDING.txt #从BUILDING文件中我们可以看到编译的要求 6.JDK安装这个安装起来相对简单，官网下载个tar包，解压配置环境变量就可以。可以自行百度和google ,可参考我如下系统环境变量配置文件： # cat /etc/profile JAVA_HOME=/usr/local/work/jdk1.8.0_144 MAVEN_HOME=/home/package/apache-maven-3.5.2 FINDBUGS_HOME=/home/package/findbugs-3.0.1 PROTOBUF_HOME=/usr/local/protobuf HADOOP_HOME=/home/hadoop/hadoop-2.9.0 CLASSPATH=.:$JAVA_HOME/lib/tools.jar PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$FINDBUGS_HOME/bin:$PROTOBUF_HOME/bin:$HADOOP_HOME/bin:$PATH export JAVA_HOME MAVEN_HOME FINDBUGS_HOME PROTOBUF_HOME HADOOP_HOME CLASSPATH PATH 7.Maven安装#wget 获取tar包 #解压 #配置环境变量 mvn --version #验证 8.protobuf安装protobuf要编译安装，需安装gcc、gcc-c++、 make 上传 protobuf-2.5.0.tar.gz tar -xzvf protobuf-2.5.0.tar.gz cd protobuf-2.5.0 yum install -y gcc gcc-c++ make ./configure --prefix=/usr/local/protobuf make &amp;&amp; make install #添加protobuf环境变量 source /etc/profile protoc --version 9.Findbugs安装下载tar包，解压，配置环境变量 10.安装snappy1.1.4,使Hadoop支持snappy压缩10.Snappy压缩库安装wget https://github.com/google/snappy/releases/download/1.1.4/snappy-1.1.4.tar.gz tar -zxvf snappy-1.1.4.tar.gz cd snappy-1.1.4 ./configure make &amp;&amp; make install ll -h /usr/local/lib |grep snappy 11.其他依赖安装yum install -y ant openssl openssl-devel svn ncurses-devel zlib-devel libtool svn yum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automake 12.编译进入Hadooop源码目录 cd hadoop-2.9.0-src mvn clean package -DskipTests -Pdist,native -Dtar -Dsnappy.lib=/usr/local/lib -Dbundle.snappy 13.生成tar包/home/hadoop/hadoop-2.9.0-src/hadoop-dist/target/hadoop-2.9.0.tar.gz 以下是我maven编译完成的信息，时间还是比较长的，跟网络也有关系： [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 02:44 h [INFO] Finished at: 2017-12-17T15:26:30+08:00 [INFO] Final Memory: 129M/237M [INFO] ------------------------------------------------------------------------ 注意事项： 由于Maven仓库在墙外，Maven在编译项目时下载包卡住情况，ctrl+c 中断，重新执行编译。 如果出现提示缺少了某个文件的情况，则要先清理maven(使用命令 mvn clean) 再重新编译。","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"}]},{"title":"虚拟机host-only下配置与宿主机共享网络","slug":"虚拟机host-only下配置与宿主机共享网络","date":"2017-12-17T10:52:41.000Z","updated":"2019-05-01T13:51:07.481Z","comments":true,"path":"2017/12/17/虚拟机host-only下配置与宿主机共享网络/","link":"","permalink":"https://tokerr.github.io/2017/12/17/虚拟机host-only下配置与宿主机共享网络/","excerpt":"准备 示例环境： 宿主机：windows7 虚拟机软件：vmware 12 pro 虚拟机：centos 6.8 备注：假设以上的环境已经全部安装完毕 1.在windows下打开网络适配器设置页面","text":"准备 示例环境： 宿主机：windows7 虚拟机软件：vmware 12 pro 虚拟机：centos 6.8 备注：假设以上的环境已经全部安装完毕 1.在windows下打开网络适配器设置页面点击进去，看到如下界面： 2.宿主机所连接的外网通过windows网络共享给VMnet1截图可以看到我宿主机所连接的网络是‘无线网络连接’，右键点击其属性，然后切换到共享网卡，勾选“允许其他网络用户通过此计算机的Internet连接来连接”，“请选择一个专用连接”下拉框选择“VMware Network Adapter VMnet1”，点击确定。 此时会提示VMware Network Adapter VMnet1的IP地址被修改为192.168.137.1，客户机网络配置要用到这个信息（本例为192.168.137.1，注意，这里经过试验，尽量不要修改这个ip地址，否则会出现配置不成功的现象）。 3.准备Linux环境3.1点击VMware快捷方式，右键打开文件所在位置 -&gt; 双击vmnetcfg.exe -&gt; VMnet1 host-only -&gt;修改subnet ip 设置网段：192.168.137.0 子网掩码：255.255.255.0 –&gt; 同时关闭DHCP服务-&gt; apply -&gt; ok在虚拟软件上 –My Computer -&gt; 选中虚拟机 -&gt; 右键 -&gt; settings -&gt; network adapter -&gt; host only -&gt; ok 3.3修改IP/配置DNS vim /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet UUID=6169d30a-2243-4a7d-9f03-455d9e0cefa6 ONBOOT=no NM_CONTROLLED=yes #BOOTPROTO=dhcp BOOTPROTO=static ##设置静态 IPADDR=192.168.137.101 ##配置ip NETMASK=255.255.255.0 ##配置子网 GATEWAY=192.168.137.2 ##配置网关 PREFIX=24 DNS1=8.8.8.8 ##配置dns DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no NAME=&quot;System eth0&quot; HWADDR=00:0C:29:44:CB:D8 LAST_CONNECT=1513431454 保存退出，重启网络服务： service network restart","categories":[],"tags":[{"name":"vmware","slug":"vmware","permalink":"https://tokerr.github.io/tags/vmware/"}]},{"title":"负载均衡session共享解决方法整理","slug":"负载均衡session共享解决方法整理","date":"2017-11-20T15:44:36.000Z","updated":"2019-05-01T13:51:07.482Z","comments":true,"path":"2017/11/20/负载均衡session共享解决方法整理/","link":"","permalink":"https://tokerr.github.io/2017/11/20/负载均衡session共享解决方法整理/","excerpt":"一、背景：最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！ 项目属于JavaWeb项目，部署在Tomcat环境下。 二、tomcat集群环境下session共享方法整理在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路： 一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；","text":"一、背景：最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！ 项目属于JavaWeb项目，部署在Tomcat环境下。 二、tomcat集群环境下session共享方法整理在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路： 一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；二是在集群中左右的节点进行Session数据的同步拷贝，所有节点的均保存了所有的Session数据。 2.1tomcat集群session同步方案有以下几种：1）使用tomcat自带的cluster方式，多个tomcat间自动实时复制session信息，配置起来很简单。使用组播的方式实现session的同步拷贝，但这个方案的效率比较低，在大并发下表现并不好。而且需要另外安装apache的HTTP Server，同样需要一台节点了协调session的拷贝，比较多余，使用的人少，网上的资料比较乱(建议去官网)。不推荐。 2）利用nginx的基于访问ip的hash路由策略，保证访问的ip始终被路由到同一个tomcat上，这个配置更简单。但如果应用是某一个局域网大量用户同时登录，这样负载均衡就没什么作用了。 3）利用nginx插件实现tomcat集群和session同步，nginx-upstream-jvm-route-0.1.tar.gz，是一个Nginx的扩展模块，用来实现基于Cookie的Session Sticky的功能。 4）利用memcached实现（MSM工具）。memcached存储session，并把多个tomcat的session集中管理，前端在利用nginx负载均衡和动静态资源分离，在兼顾系统水平扩展的同时又能保证较高的性能。 5）利用redis实现。使用redis不仅仅可以将缓存的session持久化，还因为它支持的单个对象比较大，而且数据类型丰富，不只是缓存 session，还可以做其他用途，可以一举几得。 6）利用filter+cookie方式实现。这种方法比较推荐，因为它的服务器使用范围比较多，不仅限于tomcat ，而且实现的原理比较简单容易控制。 最后三种方法是比较推荐，尝试过第一种方法，但是不推荐，原因已经写明；第四第五种方法，由于公司需要另外申请一台单独的session共享服务器，比较麻烦。最终还是选择了最后一种解决方案，思路简单，实现起来也不难。下面将介绍这种方案。 三、cookie+filter解决session共享问题下面是实现该方案涉及到的三个相关功能，重点在于过滤器的编写。 3.1 登录成功通知浏览器保存cookiepublic static void setCookie(HttpServletResponse response, HttpServletRequest request, String cookieName, String cookieValue) { /** * a.先判断是否存在cookie ，存在自己设置的cookie则重新设置过期的时间 b.不存在则创建自己cookie 通知客户端保存 * c.需要设置的属性如下： 设置value ,具体值视自己的业务而定，具体设置的之后可以通过构造方法设置name=value * ，注意使用算法加密 设置编码 设置过期时间 ，设置与session过期时间一致 设置domain 设置path */ // 声明 cookie Cookie autoCookie = null; // 获取所有的cookie Cookie cookies[] = request.getCookies(); HttpSession session = request.getSession(); // session.getMaxInactiveInterval();//session失效时间，值小于等于0代表永不超时 // 遍历cookie if (cookies != null &amp;&amp; cookies.length &gt; 0) { for (Cookie cookie : cookies) { // 判断是否存在自动登录记录 if (cookieName.equals(cookie.getName())) { autoCookie = cookie;// 赋值 break; } } } if (autoCookie == null) { // 不在创建 autoCookie = new Cookie(cookieName, cookieValue); } // 设置在执行秒数之后过期；负值意味着cookie不存储，浏览器退出则清除；值为零表示删除cookie autoCookie.setMaxAge(expiry);// 设置7天之内过期 // 设置编码 // 设置域名domain 默认情况下，Cookie只会返回给发送它们的服务器。 autoCookie.setDomain(request.getServerName()); // 设置path autoCookie.setPath(request.getContextPath()); // 浏览器的document对象中就看不到cookie autoCookie.setHttpOnly(true); response.addCookie(autoCookie);// 添加 } 3.2 登录退出通知浏览器清除cookiepublic static void cleanCookie(HttpServletRequest request, HttpServletResponse response, String cookieName) { Cookie cookies[] = request.getCookies(); if (cookies != null &amp;&amp; cookies.length &gt; 0) { for (Cookie cookie : cookies) { if (cookieName.equals(cookie.getName())) { cookie.setPath(request.getContextPath());// 浏览器回以同Name同Path同Domain覆盖原来的cookie cookie.setDomain(request.getServerName()); cookie.setMaxAge(0);// 通知浏览器删除 response.addCookie(cookie); } } } } } 3.3 编写自动登录过滤器 1）获取cookie判断用户是否已经登录 2）未登录则放行 3）已登录并且本地服务器没有相关session会话信息，则执行自动登录流程 4）自动登录完毕放行 @Override public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws IOException, ServletException { /** * a.到session获取认证信息 ，存在则通过认证，放行并终止程序 不存在执行下一步 b. * 不存在认证信息，获取cookie，遍历判断是否存在自己设置的cookie，不存在直接放行并终止程序 存在执行下一步 * c.执行自动登录流程，并查询用户必要的信息保存到session当中，执行完毕放行并终止程序 */ HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) resp; HttpSession session = request.getSession(); Object token = session.getAttribute(Constant.USER_CONTEXT_LOGGED); Cookie[] cookies = request.getCookies(); // 用户执行注销操作不进行自动登录 String uri = request.getRequestURI(); String logout = request.getParameter(&quot;logout&quot;); if (uri.contains(&quot;/projectContextPath/index.html&quot;) &amp;&amp; logout != null &amp;&amp; &quot;true&quot;.equals(logout)) { StringBuffer url = request.getRequestURL(); response.sendRedirect(url.toString()); return; } if (cookies != null &amp;&amp; cookies.length &gt; 0) {// 在session中没有获取到用户信息 Cookie autoCookie = null;// 已登录的cookie for (Cookie cookie : cookies) { // 未在本服务器登录，并且在客户端保存有响应的cookie，才会执行自动登录 if (Constant.COOKIE_NAME.equals(cookie.getName()) &amp;&amp; token == null) {// cookie存在 autoCookie = cookie; } } if (autoCookie != null ) {// 存在cookie // 开始自动登录，视具体业务根据cookie中的信息查询用户的信息并保存到session中完成自动登录 startAutoLogin(request, response, autoCookie); } } chain.doFilter(request, response);// 放行 } 另外， 安全性问题考虑，由于使用的是cookie保存了用户的信息，容易被黑客拦截篡改。通常cookie中会保存用户名、密码等敏感经过加密，很难反向破解，但也不是绝对的安全，黑客可以通过木马病毒盗取用户浏览器的cookie，直接骗取网站的信任。 最好是使用https。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"session","slug":"session","permalink":"https://tokerr.github.io/tags/session/"},{"name":"cookie","slug":"cookie","permalink":"https://tokerr.github.io/tags/cookie/"}]},{"title":"HBase简介（很好的梳理资料）","slug":"HBase简介（很好的梳理资料）","date":"2017-10-29T11:30:30.000Z","updated":"2019-05-01T13:51:07.472Z","comments":true,"path":"2017/10/29/HBase简介（很好的梳理资料）/","link":"","permalink":"https://tokerr.github.io/2017/10/29/HBase简介（很好的梳理资料）/","excerpt":"这篇博客梳理的太好了，附上大牛博主的博客地址。 一、 简介history started by chad walters and jim 2006.11 G release paper on BigTable 2007.2 inital HBase prototype created as Hadoop contrib 2007.10 First useable Hbase 2008.1 Hadoop become Apache top-level project and Hbase becomes subproject 2008.10 Hbase 0.18,0.19 released hbase是bigtable的开源山寨版本。是建立的hdfs之上，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统。","text":"这篇博客梳理的太好了，附上大牛博主的博客地址。 一、 简介history started by chad walters and jim 2006.11 G release paper on BigTable 2007.2 inital HBase prototype created as Hadoop contrib 2007.10 First useable Hbase 2008.1 Hadoop become Apache top-level project and Hbase becomes subproject 2008.10 Hbase 0.18,0.19 released hbase是bigtable的开源山寨版本。是建立的hdfs之上，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统。它介于nosql和RDBMS之间，仅能通过主键(row key)和主键的range来检索数据，仅支持单行事务(可通过hive支持来实现多表join等复杂操作)。主要用来存储非结构化和半结构化的松散数据。 与hadoop一样，Hbase目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。 HBase中的表一般有这样的特点： 大：一个表可以有上亿行，上百万列 面向列:面向列(族)的存储和权限控制，列(族)独立检索。 稀疏:对于为空(null)的列，并不占用存储空间，因此，表可以设计的非常稀疏。 下面一幅图是Hbase在Hadoop Ecosystem中的位置。 二、 逻辑视图HBase以表的形式存储数据。表有行和列组成。列划分为若干个列族(row family) Row Key与nosql数据库们一样,row key是用来检索记录的主键。访问hbase table中的行，只有三种方式： 通过单个row key访问 通过row key的range 全表扫描 Row key行键 (Row key)可以是任意字符串(最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在hbase内部，row key保存为字节数组。 存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)注意：字典序对int排序的结果是1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。要保持整形的自然序，行键必须用0作左填充。 行的一次读写是原子操作 (不论一次读写多少列)。这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。 列族hbase表中的每个列，都归属与某个列族。列族是表的chema的一部分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如courses:history ， courses:math 都属于 courses 这个列族。访问控制、磁盘和内存的使用统计都是在列族层面进行的。实际应用中，列族上的控制权限能 帮助我们管理不同类型的应用：我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据并创建继承的列族、一些应用则只允许浏览数据（甚至可能因 为隐私的原因不能浏览所有数据）。 时间戳HBase中通过row和columns确定的为一个存贮单元称为cell。每个 cell都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64位整型。时间戳可以由hbase(在数据写入时自动 )赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个 cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，hbase提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。 Cell由{row key, column( = + ), version} 唯一确定的单元。cell中的数据是没有类型的，全部是字节码形式存贮。 三、 物理存储1.已经提到过，Table中的所有行都按照row key的字典序排列。 2.Table 在行的方向上分割为多个Hregion。 3.region按大小分割的，每个表一开始只有一个region，随着数据不断插入表，region不断增大，当增大到一个阀值的时候，Hregion就会等分会两个新的Hregion。当table中的行不断增多，就会有越来越多的Hregion。 4.Hregion是Hbase中分布式存储和负载均衡的最小单元。最小单元就表示不同的Hregion可以分布在不同的HRegion server上。但一个Hregion是不会拆分到多个server上的。 5.HRegion虽然是分布式存储的最小单元，但并不是存储的最小单元。 事实上，HRegion由一个或者多个Store组成，每个store保存一个columns family。 每个Strore又由一个memStore和0至多个StoreFile组成。如图： StoreFile以HFile格式保存在HDFS上。 HFile的格式为： Trailer部分的格式: HFile分为六个部分： Data Block 段–保存表中的数据，这部分可以被压缩 Meta Block 段 (可选的)–保存用户自定义的kv对，可以被压缩。 File Info 段–Hfile的元信息，不被压缩，用户也可以在这一部分添加自己的元信息。 Data Block Index 段–Data Block的索引。每条索引的key是被索引的block的第一条记录的key。 Meta Block Index段 (可选的)–Meta Block的索引。 Trailer–这一段是定长的。保存了每一段的偏移量，读取一个HFile时，会首先 读取Trailer，Trailer保存了每个段的起始位置(段的Magic Number用来做安全check)，然后，DataBlock Index会被读取到内存中，这样，当检索某个key时，不需要扫描整个HFile，而只需从内存中找到key所在的block，通过一次磁盘io将整个 block读取到内存中，再找到需要的key。DataBlock Index采用LRU机制淘汰。 HFile的Data Block，Meta Block通常采用压缩方式存储，压缩之后可以大大减少网络IO和磁盘IO，随之而来的开销当然是需要花费cpu进行压缩和解压缩。目标Hfile的压缩支持两种方式：Gzip，Lzo。 HLog(WAL log) WAL 意为Write ahead log(http://en.wikipedia.org/wiki/Write-ahead_logging)，类似mysql中的binlog,用来 做灾难恢复只用，Hlog记录数据的所有变更,一旦数据修改，就可以从log中进行恢复。 每个Region Server维护一个Hlog,而不是每个Region一个。这样不同region(来自不同table)的日志会混在一起，这样做的目的是不断追加单个 文件相对于同时写多个文件而言，可以减少磁盘寻址次数，因此可以提高对table的写性能。带来的麻烦是，如果一台region server下线，为了恢复其上的region，需要将region server上的log进行拆分，然后分发到其它region server上进行恢复。 HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是”写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue，可参见上文描述。 四、 系统架构 Client 包含访问hbase的接口，client维护着一些cache来加快对hbase的访问，比如regione的位置信息。 Zookeeper 保证任何时候，集群中只有一个master 存贮所有Region的寻址入口。 实时监控Region Server的状态，将Region server的上线和下线信息实时通知给Master 存储Hbase的schema,包括有哪些table，每个table有哪些column family Master 为Region server分配region 负责region server的负载均衡 发现失效的region server并重新分配其上的region GFS上的垃圾文件回收 处理schema更新请求 Region Server Region server维护Master分配给它的region，处理对这些region的IO请求 Region server负责切分在运行过程中变得过大的region 可以看到，client访问hbase上数据的过程并不需要master参与（寻址访问zookeeper和region server，数据读写访问regione server），master仅仅维护者table和region的元数据信息，负载很低。 五、关键算法 / 流程region定位系统如何找到某个row key (或者某个 row key range)所在的region bigtable 使用三层类似B+树的结构来保存region位置。 第一层是保存zookeeper里面的文件，它持有root region的位置。 第二层root region是.META.表的第一个region其中保存了.META.z表其它region的位置。通过root region，我们就可以访问.META.表的数据。 .META.是第三层，它是一个特殊的表，保存了hbase中所有数据表的region 位置信息。 说明： 1.root region永远不会被split，保证了最需要三次跳转，就能定位到任意region 。 2.META.表每行保存一个region的位置信息，row key 采用表名+表的最后一样编码而成。 3.为了加快访问，.META.表的全部region都保存在内存中。 假设，.META.表的一行在内存中大约占用1KB。并且每个region限制为128MB。 那么上面的三层结构可以保存的region数目为： (128MB/1KB) * (128MB/1KB) = = 2(34)个region 4.client会将查询过的位置信息保存缓存起来，缓存不会主动失效，因此如果client上的缓存全部失效，则需要进行6次网络来回，才能定位到正确的region(其中三次用来发现缓存失效，另外三次用来获取位置信息)。 读写过程上文提到，hbase使用MemStore和StoreFile存储对表的更新。 数据在更新时首先写入Log(WAL log)和内存(MemStore)中，MemStore中的数据是排序的，当MemStore累计到一定阈值时，就会创建一个新的MemStore，并 且将老的MemStore添加到flush队列，由单独的线程flush到磁盘上，成为一个StoreFile。于此同时，系统会在zookeeper中 记录一个redo point，表示这个时刻之前的变更已经持久化了。(minor compact) 当系统出现意外时，可能导致内存(MemStore)中的数据丢失，此时使用Log(WAL log)来恢复checkpoint之后的数据。 前面提到过StoreFile是只读的，一旦创建后就不可以再修改。因此Hbase的更 新其实是不断追加的操作。当一个Store中的StoreFile达到一定的阈值后，就会进行一次合并(major compact),将对同一个key的修改合并到一起，形成一个大的StoreFile，当StoreFile的大小达到一定阈值后，又会对 StoreFile进行split，等分为两个StoreFile。 由于对表的更新是不断追加的，处理读请求时，需要访问Store中全部的 StoreFile和MemStore，将他们的按照row key进行合并，由于StoreFile和MemStore都是经过排序的，并且StoreFile带有内存中索引，合并的过程还是比较快。 写请求处理过程 client向region server提交写请求 region server找到目标region region检查数据是否与schema一致 如果客户端没有指定版本，则获取当前系统时间作为数据版本 将更新写入WAL log 将更新写入Memstore 判断Memstore的是否需要flush为Store文件。 region分配任何时刻，一个region只能分配给一个region server。master记录了当前有哪些可用的region server。以及当前哪些region分配给了哪些region server，哪些region还没有分配。当存在未分配的region，并且有一个region server上有可用空间时，master就给这个region server发送一个装载请求，把region分配给这个region server。region server得到请求后，就开始对此region提供服务。 region server上线master使用zookeeper来跟踪region server状态。当某个region server启动时，会首先在zookeeper上的server目录下建立代表自己的文件，并获得该文件的独占锁。由于master订阅了server 目录上的变更消息，当server目录下的文件出现新增或删除操作时，master可以得到来自zookeeper的实时通知。因此一旦region server上线，master能马上得到消息。 region server下线当region server下线时，它和zookeeper的会话断开，zookeeper而自动释放代表这台server的文件上的独占锁。而master不断轮询 server目录下文件的锁状态。如果master发现某个region server丢失了它自己的独占锁，(或者master连续几次和region server通信都无法成功),master就是尝试去获取代表这个region server的读写锁，一旦获取成功，就可以确定： region server和zookeeper之间的网络断开了。 region server挂了。 的其中一种情况发生了，无论哪种情况，region server都无法继续为它的region提供服务了，此时master会删除server目录下代表这台region server的文件，并将这台region server的region分配给其它还活着的同志。 如果网络短暂出现问题导致region server丢失了它的锁，那么region server重新连接到zookeeper之后，只要代表它的文件还在，它就会不断尝试获取这个文件上的锁，一旦获取到了，就可以继续提供服务。 master上线master启动进行以下步骤: 从zookeeper上获取唯一一个代码master的锁，用来阻止其它master成为master。 扫描zookeeper上的server目录，获得当前可用的region server列表。 和2中的每个region server通信，获得当前已分配的region和region server的对应关系。 扫描.META.region的集合，计算得到当前还未分配的region，将他们放入待分配region列表。 master下线由于master只维护表和region的元数据，而不参与表数据IO的过 程，master下线仅导致所有元数据的修改被冻结(无法创建删除表，无法修改表的schema，无法进行region的负载均衡，无法处理region 上下线，无法进行region的合并，唯一例外的是region的split可以正常进行，因为只有region server参与)，表的数据读写还可以正常进行。因此master下线短时间内对整个hbase集群没有影响。从上线过程可以看到，master保存的 信息全是可以冗余信息（都可以从系统其它地方收集到或者计算出来），因此，一般hbase集群中总是有一个master在提供服务，还有一个以上 的’master’在等待时机抢占它的位置。 六、访问接口HBase Shell Java clietn API HBase non-java access languages talking to the JVM Jython interface to HBase Groovy DSL for HBase Scala interface to HBase languages with a custom protocol REST gateway specification for HBase 充分利用HTTP协议：GET POST PUT DELETE § text/plain text/xml application/json application/x-protobuf Thrift gateway specification for HBase java cpp rb py perl php HBase Map Reduce Hive/Pig 七、结语：全文对 Hbase做了 简单的介绍，有错误之处，敬请指正。未来将结合 Hbase 在淘宝数据平台的应用场景，在更多细节上进行深入。 参考文档Bigtable: A Distributed Storage System for Structured Data HFile: A Block-Indexed File Format to Store Sorted Key-Value Pairs for a thorough introduction Hbase Architecture 101 Hbase source code","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://tokerr.github.io/tags/zookeeper/"},{"name":"hbase","slug":"hbase","permalink":"https://tokerr.github.io/tags/hbase/"}]},{"title":"sqoop学习笔记","slug":"sqoop学习笔记","date":"2017-10-25T13:28:29.000Z","updated":"2019-05-01T13:51:07.478Z","comments":true,"path":"2017/10/25/sqoop学习笔记/","link":"","permalink":"https://tokerr.github.io/2017/10/25/sqoop学习笔记/","excerpt":"说明：这里以hadoop2和mysql为例。 1.上传sqoop到Hadoop集群任意一个节点2.安装和配置2.1 配置sqoop-env.sh文件在sqoop中conf目录下新复制一个sqoop-env.sh文件：[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh修改配置sqoop-env.sh文件：","text":"说明：这里以hadoop2和mysql为例。 1.上传sqoop到Hadoop集群任意一个节点2.安装和配置2.1 配置sqoop-env.sh文件在sqoop中conf目录下新复制一个sqoop-env.sh文件：[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh修改配置sqoop-env.sh文件： export HADOOP_COMMON_HOME=/home/hadoop/hadoop/hadoop-2.3.0 #Set path to where hadoop-*-core.jar is available export HADOOP_MAPRED_HOME=/home/hadoop/hadoop/hadoop-2.3.0 #set the path to where bin/hbase is available #export HBASE_HOME= #Set the path to where bin/hive is available #export HIVE_HOME= #Set the path for where zookeper config dir is #export ZOOCFGDIR= 不配置该项会出现Please set $HADOOP_COMMON_HOME to the root的错误提示。 2.2 添加数据库驱动将数据库连接驱动拷贝到$SQOOP_HOME/lib里。注意，这里使用的是Mysql驱动版本不能过低，尽量使用最新的版本，否则可能会出现一下错误： ERROR manager.SqlManager: Error reading from database: java.sql.SQLException: Streaming result set 3.配置mysql远程登录3.1 改表：只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%” 登录数据库：mysql -u root -pvmware mysql&gt;use mysql; mysql&gt;update user set host = ‘%’ where user = ‘root’; mysql&gt;select host, user from user; mysql&gt;FLUSH RIVILEGES 3.2 授权：(1)例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。 第一步：root用户登录；mysql&gt;mysql -u root -p rootpassword; 第二步：赋予权限；mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘myuser’@’%’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; 第三步：mysql&gt;FLUSH PRIVILEGES; (2)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器，并使用mypassword作为密码 mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; mysql&gt;FLUSH PRIVILEGES; (3)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码 mysql&gt;GRANT ALL PRIVILEGES ON dk.* TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; mysql&gt;FLUSH PRIVILEGES; 说明：这里我使用了第（1）种方法。没有允许mysql远程登录，在使用sqoop导入数据的时候，会出现以下错误： message from server: &quot;Host is not allowed to connect to this MySQL server 4.使用&amp;练习第一类：数据库中的数据导入到HDFS上 sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --columns &apos;id, account, income, expenses&apos; 指定输出路径、指定数据分隔符 sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --target-dir &apos;/sqoop/td&apos; --fields-terminated-by &apos;\\t&apos; 指定Map数量 -m sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --target-dir &apos;/sqoop/td1&apos; --fields-terminated-by &apos;\\t&apos; -m 2 增加where条件, 注意：条件必须用引号引起来 sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --where &apos;id&gt;3&apos; --target-dir &apos;/sqoop/td2&apos; 增加query语句(使用 \\ 将语句换行) sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 \\ --query &apos;SELECT * FROM trade_detail where id &gt; 2 AND $CONDITIONS&apos; --split-by trade_detail.id --target-dir &apos;/sqoop/td3&apos; 注意： 如果使用–query这个命令的时候，需要注意的是where后面的参数，AND $CONDITIONS这个参数必须加上 而且存在单引号与双引号的区别，如果–query后面使用的是双引号，那么需要在$CONDITIONS前加上\\即\\$CONDITIONS 如果设置map数量为1个时即-m 1，不用加上–split-by ${tablename.column}，否则需要加上 第二类：将HDFS上的数据导出到数据库中(不要忘记指定分隔符) sqoop export --connect jdbc:mysql://192.168.8.120:3306/nongyt --username root --password 123 --export-dir &apos;/td3&apos; --table td_bak -m 1 --fields-terminated-by &apos;,&apos;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"sqoop","slug":"sqoop","permalink":"https://tokerr.github.io/tags/sqoop/"}]},{"title":"hadoop+zookeeper集群搭建","slug":"hadoop-zookeeper集群搭建","date":"2017-10-24T14:50:21.000Z","updated":"2019-05-01T13:51:07.476Z","comments":true,"path":"2017/10/24/hadoop-zookeeper集群搭建/","link":"","permalink":"https://tokerr.github.io/2017/10/24/hadoop-zookeeper集群搭建/","excerpt":"前期准备:hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA 1.修改Linux主机名2.修改IP3.修改主机名和IP的映射关系","text":"前期准备:hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA 1.修改Linux主机名2.修改IP3.修改主机名和IP的映射关系 注意： 如果你们公司是租用的服务器或是使用的云主机（如华为用主机、阿里云主机等） /etc/hosts里面要配置的是内网IP地址和主机名的映射关系4.关闭防火墙5.ssh免登陆 6.安装JDK，配置环境变量等 集群规划：主机名 IP 安装的软件 运行的进程 nongyt01 192.168.1.201 jdk、hadoop NameNode、DFSZKFailoverController(zkfc) nongyt02 192.168.1.202 jdk、hadoop NameNode、DFSZKFailoverController(zkfc) nongyt03 192.168.1.203 jdk、hadoop ResourceManager nongyt04 192.168.1.204 jdk、hadoop ResourceManager nongyt05 192.168.1.205 jdk、hadoop、zookeeper DataNode、NodeManager、JournalNode、QuorumPeerMain nongyt06 192.168.1.206 jdk、hadoop、zookeeper DataNode、NodeManager、JournalNode、QuorumPeerMain nongyt07 192.168.1.207 jdk、hadoop、zookeeper DataNode、NodeManager、JournalNode、QuorumPeerMain 说明：1.在hadoop2.0中通常由两个NameNode组成，一个处于active状态，另一个处于standby状态。Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步active namenode的状态，以便能够在它失败时快速进行切换。hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode这里还配置了一个zookeeper集群，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode为standby状态 2.hadoop-2.2.0中依然存在一个问题，就是ResourceManager只有一个，存在单点故障，hadoop-2.4.1解决了这个问题，有两个ResourceManager，一个是Active，一个是Standby，状态由zookeeper进行协调 安装步骤：1.安装配置zooekeeper集群（在nongyt05上）1.1解压 tar -zxvf zookeeper-3.4.5.tar.gz -C /nongyt/ 1.2修改配置 cd /nongyt/zookeeper-3.4.5/conf/ cp zoo_sample.cfg zoo.cfg vim zoo.cfg 修改：dataDir=/nongyt/zookeeper-3.4.5/tmp 在最后添加： server.1=nongyt05:2888:3888 server.2=nongyt06:2888:3888 server.3=nongyt07:2888:3888 保存退出 然后创建一个tmp文件夹 mkdir /nongyt/zookeeper-3.4.5/tmp 再创建一个空文件 touch /nongyt/zookeeper-3.4.5/tmp/myid 最后向该文件写入ID echo 1 &gt; /nongyt/zookeeper-3.4.5/tmp/myid 1.3将配置好的zookeeper拷贝到其他节点(首先分别在nongyt06、nongyt07根目录下创建一个nongyt目录：mkdir /nongyt) scp -r /nongyt/zookeeper-3.4.5/ nongyt06:/nongyt/ scp -r /nongyt/zookeeper-3.4.5/ nongyt07:/nongyt/ 注意：修改nongyt06、nongyt07对应/nongyt/zookeeper-3.4.5/tmp/myid内容 nongyt06： echo 2 &gt; /nongyt/zookeeper-3.4.5/tmp/myid nongyt07： echo 3 &gt; /nongyt/zookeeper-3.4.5/tmp/myid 2.安装配置hadoop集群（在nongyt01上操作） 2.1解压 tar -zxvf hadoop-2.4.1.tar.gz -C /nongyt/ 2.2配置HDFS（hadoop2.0所有的配置文件都在$HADOOP_HOME/etc/hadoop目录下） #将hadoop添加到环境变量中 vim /etc/profile export JAVA_HOME=/usr/java/jdk1.7.0_55 export HADOOP_HOME=/nongyt/hadoop-2.4.1 export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin #hadoop2.0的配置文件全部在$HADOOP_HOME/etc/hadoop下 cd /nongyt/hadoop-2.4.1/etc/hadoop 2.2.1修改hadoo-env.sh export JAVA_HOME=/usr/java/jdk1.7.0_55 2.2.2修改core-site.xml &lt;configuration&gt; &lt;!-- 指定hdfs的nameservice为ns1 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop临时目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/nongyt/hadoop-2.4.1/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper地址 --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.3修改hdfs-site.xml &lt;configuration&gt; &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt; &lt;value&gt;nongyt01:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt; &lt;value&gt;nongyt01:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt; &lt;value&gt;nongyt02:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt; &lt;value&gt;nongyt02:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://nongyt05:8485;nongyt06:8485;nongyt07:8485/ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/nongyt/hadoop-2.4.1/journal&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启NameNode失败自动切换 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置失败自动切换实现方式 --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt; sshfence shell(/bin/true) &lt;/value&gt; &lt;/property&gt; &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置sshfence隔离机制超时时间 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.4修改mapred-site.xml &lt;configuration&gt; &lt;!-- 指定mr框架为yarn方式 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.5修改yarn-site.xml &lt;configuration&gt; &lt;!-- 开启RM高可靠 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的cluster id --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 分别指定RM的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;nongyt03&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;nongyt04&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zk集群地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.6修改slaves(slaves是指定子节点的位置，因为要在nongyt01上启动HDFS、在nongyt03启动yarn，所以nongyt01上的slaves文件指定的是datanode的位置，nongyt03上的slaves文件指定的是nodemanager的位置) nongyt05 nongyt06 nongyt07 2.2.7配置免密码登陆 #首先要配置nongyt01到nongyt02、nongyt03、nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆 #在nongyt01上生产一对钥匙 ssh-keygen -t rsa #将公钥拷贝到其他节点，包括自己 ssh-coyp-id nongyt01 ssh-coyp-id nongyt02 ssh-coyp-id nongyt03 ssh-coyp-id nongyt04 ssh-coyp-id nongyt05 ssh-coyp-id nongyt06 ssh-coyp-id nongyt07 #配置nongyt03到nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆 #在nongyt03上生产一对钥匙 ssh-keygen -t rsa #将公钥拷贝到其他节点 ssh-coyp-id nongyt04 ssh-coyp-id nongyt05 ssh-coyp-id nongyt06 ssh-coyp-id nongyt07 #注意：两个namenode之间要配置ssh免密码登陆，别忘了配置nongyt02到nongyt01的免登陆 在nongyt02上生产一对钥匙 ssh-keygen -t rsa ssh-coyp-id -i nongyt01 2.4将配置好的hadoop拷贝到其他节点 scp -r /nongyt/ nongyt02:/ scp -r /nongyt/ nongyt03:/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt04:/nongyt/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt05:/nongyt/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt06:/nongyt/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt07:/nongyt/ ###注意：严格按照下面的步骤 2.5启动zookeeper集群（分别在nongyt05、nongyt06、tcast07上启动zk） cd /nongyt/zookeeper-3.4.5/bin/ ./zkServer.sh start #查看状态：一个leader，两个follower ./zkServer.sh status 2.6启动journalnode（分别在在nongyt05、nongyt06、tcast07上执行） cd /nongyt/hadoop-2.4.1 sbin/hadoop-daemon.sh start journalnode #运行jps命令检验，nongyt05、nongyt06、nongyt07上多了JournalNode进程 2.7格式化HDFS #在nongyt01上执行命令: hdfs namenode -format #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/nongyt/hadoop-2.4.1/tmp，然后将/nongyt/hadoop-2.4.1/tmp拷贝到nongyt02的/nongyt/hadoop-2.4.1/下。 scp -r tmp/ nongyt02:/nongyt/hadoop-2.4.1/ 2.8格式化ZK(在nongyt01上执行即可) hdfs zkfc -formatZK 2.9启动HDFS(在nongyt01上执行) sbin/start-dfs.sh 2.10启动YARN(#####注意#####：是在nongyt03上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动) sbin/start-yarn.sh 到此，hadoop-2.4.1配置完毕，可以统计浏览器访问: http://192.168.1.201:50070 NameNode &apos;nongyt01:9000&apos; (active) http://192.168.1.202:50070 NameNode &apos;nongyt02:9000&apos; (standby) 验证HDFS HA 首先向hdfs上传一个文件 hadoop fs -put /etc/profile /profile hadoop fs -ls / 然后再kill掉active的NameNode kill -9 &lt;pid of NN&gt; 通过浏览器访问：http://192.168.1.202:50070 NameNode &apos;nongyt02:9000&apos; (active) 这个时候nongyt02上的NameNode变成了active 在执行命令： hadoop fs -ls / -rw-r--r-- 3 root supergroup 1926 2014-02-06 15:36 /profile 刚才上传的文件依然存在！！！ 手动启动那个挂掉的NameNode sbin/hadoop-daemon.sh start namenode 通过浏览器访问：http://192.168.1.201:50070 NameNode &apos;nongyt01:9000&apos; (standby) 验证YARN： 运行一下hadoop提供的demo中的WordCount程序： hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /out OK，大功告成！！！ zookeeper配置文件详解zookeeper的默认配置文件为zookeeper/conf/zoo_sample.cfg，需要将其修改为zoo.cfg。其中各配置项的含义，解释如下： 1.tickTime：CS通信心跳时间Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。tickTime=2000 2.initLimit：LF初始通信时限集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。initLimit=5 3.syncLimit：LF同步通信时限集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。syncLimit=2 4.dataDir：数据文件目录Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。dataDir=/home/michael/opt/zookeeper/data 5.clientPort：客户端连接端口客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。clientPort=2181 6.服务器名称与地址： 集群信息（服务器编号，服务器地址，LF通信端口，选举端口） 这个配置项的书写格式比较特殊，规则如下： server.N=YYY:A:B server.1=nongyt05:2888:3888 server.2=nongyt06:2888:3888 server.3=nongyt07:2888:3888","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://tokerr.github.io/tags/zookeeper/"},{"name":"cluster","slug":"cluster","permalink":"https://tokerr.github.io/tags/cluster/"}]},{"title":"Linux下tomcat启动慢的问题","slug":"Linux下tomcat启动慢的问题","date":"2017-10-24T14:37:32.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/10/24/Linux下tomcat启动慢的问题/","link":"","permalink":"https://tokerr.github.io/2017/10/24/Linux下tomcat启动慢的问题/","excerpt":"有两种解决办法：1）在Tomcat环境中解决 可以通过配置JRE使用非阻塞的Entropy Source。在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。","text":"有两种解决办法：1）在Tomcat环境中解决 可以通过配置JRE使用非阻塞的Entropy Source。在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。2）在JVM环境中解决 打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容：securerandom.source=file:/dev/urandom替换成securerandom.source=file:/dev/./urandom 彻底解决“Linux下的所有应用程序产生随机数都会用到这个，所以不仅仅是Tomcat可能被 阻塞 。如果你搜索会发现Apache、Nginx、OpenSSL都被这个问题坑过.”由于《彻底找到Tomcat启动速度慢的元凶》这篇原文网上被引用过多，我也分不清那个是原文，所以此处就不贴原文地址了，大家可自行百度关键字：彻底找到Tomcat启动速度慢的元凶","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://tokerr.github.io/tags/tomcat/"}]},{"title":"HDFS架构及其执行原理","slug":"HDFS架构极其执行原理","date":"2017-10-18T09:18:35.000Z","updated":"2019-05-01T13:51:07.472Z","comments":true,"path":"2017/10/18/HDFS架构极其执行原理/","link":"","permalink":"https://tokerr.github.io/2017/10/18/HDFS架构极其执行原理/","excerpt":"一、前言：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。 1.1、名词复习 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统） 内部主从结构 •主节点，只有一个: namenode •从节点，有很多个: datanode namenode负责：","text":"一、前言：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。 1.1、名词复习 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统） 内部主从结构 •主节点，只有一个: namenode •从节点，有很多个: datanode namenode负责： 接收用户操作请求 维护文件系统的目录结构 管理文件与block之间关系，block与datanode之间关系 datanode负责： 存储文件 文件被分成block存储在磁盘上 为保证数据安全，文件会有多个副本 备注：还有另外一个SecondaryNameNode，作为NameNode的辅助组件，但是不能替代NameNode，下面会简单的介绍。 1.2、Hadoop1.0和hadop2.0的对比 二、分布式文件系统与HDFS 数据量越来越多，在一个操作系统管辖的范围存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，因此迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统 。 是一种允许文件通过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。 通透性。让实际上是通过网络来访问文件的动作，由程序与用户看来，就像是访问本地的磁盘一般。 容错。即使系统中有某些节点脱机，整体来说系统仍然可以持续运作而不会有数据损失。 分布式文件管理系统很多，hdfs只是其中一种。适用于一次写入多次查询的情况，不支持并发写情况，小文件不合适。 三、HDFS体系结构与基本概念3.1 HDFS架构包括NameNode，DataNode，Secondary NameNode 3.2 原理图 3.3 NameNode是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求。 文件包括(hdfs-site.xml的dfs.name.dir属性)： fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。 edits:操作日志文件。 fstime:保存最近一次checkpoint的时间 以上这些文件是保存在linux的文件系统中。 NameNode工作特点： Namenode始终在内存中保存metedata，用于处理“读请求” 到有“写请求”到来时，namenode会首先写editlog到磁盘，即向edits文件中写日志，成功返回后，才会修改内存，并且向客户端返回 Hadoop会维护一个fsimage文件，也就是namenode中metedata的镜像，但是fsimage不会随时与namenode内存中的metedata保持一致，而是每隔一段时间通过合并edits文件来更新内容。Secondary namenode就是用来合并fsimage和edits文件来更新NameNode的metedata的。 3.4 SecondaryNameNode HA的一个解决方案。但不支持热备。配置即可。 执行过程：从NameNode上下载元数据信息（fsimage,edits），然后把二者合并，生成新的fsimage，在本地保存，并将其推送到NameNode，替换旧的fsimage. 默认在安装在NameNode节点上，但这样…不安全！ SecondaryNameNode工作流程： secondary通知namenode切换edits文件 secondary从namenode获得fsimage和edits(通过http) secondary将fsimage载入内存，然后开始合并edits secondary将新的fsimage发回给namenode namenode用新的fsimage替换旧的fsimage 下图是NameNode和SecondaryNameNode工作相互协调的过程： 3.5 DataNode 提供真实文件数据的存储服务。 文件块（block）：最基本的存储单位。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB，以一个256MB文件，共有256/128=2个Block. 不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间 Replication。多复本。默认是三个。 四、HDFS的shell操作 调用文件系统(FS)Shell命令应使用bin/hadoop fs 的形式。 所有的FS shell命令使用URI路径作为参数。 URI格式是scheme://authority/。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。 例如：/parent/child可以表示成hdfs://namenode:namenodePort/parent/child，或者更简单的/parent/child（假设配置文件是namenode:namenodePort） 大多数FS Shell命令的行为和对应的Unix Shell命令类似。 HDFS fs命令 -help [cmd] //显示命令的帮助信息 -ls(r) &lt;path&gt; //显示当前目录下所有文件 -du(s) &lt;path&gt; //显示目录中所有文件大小 -count[-q] &lt;path&gt; //显示目录中文件数量 -mv &lt;src&gt; &lt;dst&gt; //移动多个文件到目标目录 -cp &lt;src&gt; &lt;dst&gt; //复制多个文件到目标目录 -rm(r) //删除文件(夹) -put &lt;localsrc&gt; &lt;dst&gt; //本地文件复制到hdfs -copyFromLocal //同put -moveFromLocal //从本地文件移动到hdfs -get [-ignoreCrc] &lt;src&gt; &lt;localdst&gt; //复制文件到本地，可以忽略crc校验 -getmerge &lt;src&gt; &lt;localdst&gt; //将源目录中的所有文件排序合并到一个文件中 -cat &lt;src&gt; //在终端显示文件内容 -text &lt;src&gt; //在终端显示文件内容 -copyToLocal [-ignoreCrc] &lt;src&gt; &lt;localdst&gt; //复制到本地 -moveToLocal &lt;src&gt; &lt;localdst&gt; -mkdir &lt;path&gt; //创建文件夹 -touchz &lt;path&gt; //创建一个空文件","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"HDFS","slug":"HDFS","permalink":"https://tokerr.github.io/tags/HDFS/"},{"name":"YARN","slug":"YARN","permalink":"https://tokerr.github.io/tags/YARN/"}]},{"title":"Shuffle工作机制","slug":"Shuffle工作机制","date":"2017-10-16T15:41:34.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/10/16/Shuffle工作机制/","link":"","permalink":"https://tokerr.github.io/2017/10/16/Shuffle工作机制/","excerpt":"一、前言&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。 二、什么是Shuffle?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。","text":"一、前言&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。 二、什么是Shuffle?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。 三、Shuffle工作机制：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从map端的输出开始。map函数开始产生输出时，不是简单地将它写到磁盘。这个过程更复杂，它利用缓冲的方式写到内存，井出于效率的考虑进行预排序。下图展示了这个过程每个map任务都有一个环形内存缓冲区，用于存储任务的输出。默认情况下，缓冲区的大为100MB，此值可以通过改变io.sort.mb属性来调整。一旦缓冲内容达到闹值(io.sort.spill.percent，默认为0.80，或80%)，一个后台线程便开始把内容写到(spill)磁盘中。在写磁盘过程中，map输出继续被写到缓冲区，但如果在此期间缓冲区被填楠，map会阻塞直到写磁盘过程完成。写磁盘将按轮询方式写到mapred.local.dir属性指定的作业特定子目录中的目录中。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在map输出写磁盘之前，线程首先根据数据最终要传送到的reducer把数据划分成相应的分区(partition)。在每个分区中，后台线程按键进行内排序，如果有一个combiner，它会在排序后的输出上运行。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦内存缓冲区达到溢出写的阀值，就会新建一个溢出写文件，因此在map任务写完其最后一个输出记录之后，会有几个溢出写文件。在任务完成之前，溢出写文件被合并成一个已分区且已排序的输出文件。配置属性io.sort.factor控制着一次最多能合并多少流，默认值是10.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果已经指定combiner，并且溢出写次数至少为3(min.num.spills.for.combine属性的取值)肘，则combiner就会在输出文件写到磁盘之前运行。combiner可以在输入上反复运行，如果combiner可拔插，添加Combiner绝不能改变最终的计算结果;不排除使用combiner作为在map端过滤数据的用途，比如空字符串或者其他无效的参数，这会影响reducer的计算结果。运行combiner的意义在于使map输出更紧凑，使得写到本地磁盘和传给reducer的数据更少。写盘时压缩map输出可以提高效率，因为这样会让写磁盘的速度更快，节约磁盘空间，并且减少传给reducer的数据量。默认情况下，输出是不压缩的，但只要将mapred.compress.map.output设置为true，就可以启用此功能。使用的压缩库库mapred.map.output.compression.codec指定.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，reducer通过HTTP方式得到输出文件的分区。","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"MapReducer","slug":"MapReducer","permalink":"https://tokerr.github.io/tags/MapReducer/"},{"name":"Shuffle","slug":"Shuffle","permalink":"https://tokerr.github.io/tags/Shuffle/"}]},{"title":"Jquery防止Ajax重复提交解决方案","slug":"Jquery防止Ajax重复提交解决方案","date":"2017-10-09T15:15:34.000Z","updated":"2019-05-01T13:51:07.474Z","comments":true,"path":"2017/10/09/Jquery防止Ajax重复提交解决方案/","link":"","permalink":"https://tokerr.github.io/2017/10/09/Jquery防止Ajax重复提交解决方案/","excerpt":"一、前言不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。 二、直接上代码/** * jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理 */ $(function(){ var pendingRequests = {}; // 所有ajax请求的通用前置filter $.ajaxPrefilter(function( options, originalOptions, jqXHR ) { var key = generatePendingRequestKey(options);","text":"一、前言不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。 二、直接上代码/** * jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理 */ $(function(){ var pendingRequests = {}; // 所有ajax请求的通用前置filter $.ajaxPrefilter(function( options, originalOptions, jqXHR ) { var key = generatePendingRequestKey(options); //请求是否已经存在 if(!pendingRequests[key]){ storePendingRequest(key,jqXHR); }else{ //如果ajax请求已经存在，下一次相同的请求则取消，防止重复请求 jqXHR.abort(); } //ajax请求完成时，从临时对象中清除请求对应的数据 var complete = options.complete; options.complete = function(jqXHR, textStatus) { //延时1000毫秒删除请求信息，表示同Key值请求不能在此时间段内重复提交 setTimeout(function(){ delete pendingRequests[jqXHR.pendingRequestKey]; },1000); if ($.isFunction(complete)) { complete.apply(this, arguments); } }; //统一的错误处理 var error = options.error; options.error = function(jqXHR, textStatus) { errorHandler(jqXHR, textStatus); if ($.isFunction(error)) { error.apply(this, arguments); } }; }); /** * 当ajax请求发生错误时，统一进行拦截处理的方法 */ function errorHandler(jqXHR, textStatus){ switch (jqXHR.status){ case(500): internalError(jqXHR); break; case(403): accessDenied(jqXHR); break; case(408): timeoutError(jqXHR); break; case(404): pageNotFound(jqXHR); break; default: //otherError(jqXHR, textStatus); } } function pageNotFound(jqXHR){ Component.warningMessageBox({ content:&quot;请求访问的地址或内容不存在！&quot; }); } function accessDenied(jqXHR){ Component.warningMessageBox({ content:&quot;你无权进行此操作或页面访问！&quot; }); } function internalError(jqXHR){ Component.warningMessageBox({ content:&quot;服务器存在错误，未能正确处理你的请求！&quot; }); } function timeoutError(jqXHR){ window.location.href=contextPath + &quot;/j_spring_security_logout&quot;; } function otherError(jqXHR, textStatus){ Component.warningMessageBox({ content:&quot;未知错误，错误代码：&quot; + textStatus }); } /** * 将ajax请求存储到临时对象中，用于根据key判断请求是否已经存在 */ function storePendingRequest(key, jqXHR){ pendingRequests[key] = jqXHR; jqXHR.pendingRequestKey = key; } /** * 根据ajax请求参数构建一个临时存储key,此处简单的使用url作为key， * 不考虑为解决请求类型为get时相同路径引起的缓存问题，采用随机码构建URL的情况 */ function generatePendingRequestKey(options){ return options.url; } });","categories":[],"tags":[{"name":"jquery","slug":"jquery","permalink":"https://tokerr.github.io/tags/jquery/"},{"name":"ajax","slug":"ajax","permalink":"https://tokerr.github.io/tags/ajax/"}]},{"title":"Spring Boot – JSP View Example","slug":"Spring-Boot-–-JSP-View-Example","date":"2017-08-16T14:51:30.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/08/16/Spring-Boot-–-JSP-View-Example/","link":"","permalink":"https://tokerr.github.io/2017/08/16/Spring-Boot-–-JSP-View-Example/","excerpt":"Learn to create and configure spring boot application which uses JSP template files to render view layer. It uses embedded Tomcat server to run the application.Sourcecode StructureThe files in this application are placed as given structure in image. Maven dependencies – pom.xmlThis application uses given below dependencies.","text":"Learn to create and configure spring boot application which uses JSP template files to render view layer. It uses embedded Tomcat server to run the application.Sourcecode StructureThe files in this application are placed as given structure in image. Maven dependencies – pom.xmlThis application uses given below dependencies. 4.0.0 com.howtodoinjava spring-boot-demo war 0.0.1-SNAPSHOT spring-boot-demo Maven Webapp http://maven.apache.org org.springframework.boot spring-boot-starter-parent 1.5.1.RELEASE 1.8 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-tomcat provided javax.servlet jstl org.apache.tomcat.embed tomcat-embed-jasper provided Spring Boot Application InitializerThe first step in producing a deployable war file is to provide a SpringBootServletInitializer subclass and override its configure() method. This makes use of Spring Framework’s Servlet 3.0 support and allows you to configure your application when it’s launched by the servlet container. package com.howtodoinjava.app.controller; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.builder.SpringApplicationBuilder; import org.springframework.boot.web.support.SpringBootServletInitializer; @SpringBootApplication public class SpringBootWebApplication extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { return application.sources(SpringBootWebApplication.class); } public static void main(String[] args) throws Exception { SpringApplication.run(SpringBootWebApplication.class, args); } } Spring ControllerController classes can have methods mapped to specific URLs in the application. In given application, it has two views i.e. “/” and “/next”. package com.howtodoinjava.app.controller; import java.util.Map; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; @Controller public class IndexController { @RequestMapping(&quot;/&quot;) public String home(Map&lt;String, Object&gt; model) { model.put(&quot;message&quot;, &quot;HowToDoInJava Reader !!&quot;); return &quot;index&quot;; } @RequestMapping(&quot;/next&quot;) public String next(Map&lt;String, Object&gt; model) { model.put(&quot;message&quot;, &quot;You are in new page !!&quot;); return &quot;next&quot;; } } Configure JSP View ResolverTo resolve JSP files location, you can have two approaches. 1) Add entries in application.propertiesspring.mvc.view.prefix=/WEB-INF/view/ spring.mvc.view.suffix=.jsp //For detailed logging during development logging.level.org.springframework=TRACE logging.level.com=TRACE 2) Configure InternalResourceViewResolverpackage com.howtodoinjava.app.controller; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.EnableWebMvc; import org.springframework.web.servlet.config.annotation.ViewResolverRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter; import org.springframework.web.servlet.view.InternalResourceViewResolver; import org.springframework.web.servlet.view.JstlView; @Configuration @EnableWebMvc @ComponentScan public class MvcConfiguration extends WebMvcConfigurerAdapter { @Override public void configureViewResolvers(ViewResolverRegistry registry) { InternalResourceViewResolver resolver = new InternalResourceViewResolver(); resolver.setPrefix(&quot;/WEB-INF/view/&quot;); resolver.setSuffix(&quot;.jsp&quot;); resolver.setViewClass(JstlView.class); registry.viewResolver(resolver); } } JSP Filesindex.jsp&lt;!DOCTYPE html&gt; &lt;%@ taglib prefix=&quot;spring&quot; uri=&quot;http://www.springframework.org/tags&quot;%&gt; &lt;html lang=&quot;en&quot;&gt; &lt;body&gt; &lt;div&gt; &lt;div&gt; &lt;h1&gt;Spring Boot JSP Example&lt;/h1&gt; &lt;h2&gt;Hello ${message}&lt;/h2&gt; Click on this &lt;strong&gt;&lt;a href=&quot;next&quot;&gt;link&lt;/a&gt;&lt;/strong&gt; to visit another page. &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; next.jsp&lt;!DOCTYPE html&gt; &lt;%@ taglib prefix=&quot;spring&quot; uri=&quot;http://www.springframework.org/tags&quot;%&gt; &lt;html lang=&quot;en&quot;&gt; &lt;body&gt; &lt;div&gt; &lt;div&gt; &lt;h1&gt;Another page&lt;/h1&gt; &lt;h2&gt;Hello ${message}&lt;/h2&gt; Click on this &lt;strong&gt;&lt;a href=&quot;/&quot;&gt;link&lt;/a&gt;&lt;/strong&gt; to visit previous page. &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; Run the applicationAfter whole code is written and placed inside folders, run the application by executing main() method in SpringBootWebApplication class. Now hit the URL: http://localhost:8080/ Click next link Spring Boot JSP example Source CodeDownload the sourcecode of this application with below ink.Download Source Code","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"springboot","slug":"springboot","permalink":"https://tokerr.github.io/tags/springboot/"},{"name":"jsp","slug":"jsp","permalink":"https://tokerr.github.io/tags/jsp/"}]},{"title":"对赋值语句中short类型转换的理解[转]","slug":"对赋值语句中short类型转换的理解","date":"2017-07-05T04:38:02.000Z","updated":"2019-05-01T13:51:07.480Z","comments":true,"path":"2017/07/05/对赋值语句中short类型转换的理解/","link":"","permalink":"https://tokerr.github.io/2017/07/05/对赋值语句中short类型转换的理解/","excerpt":"一、问题的提出有这么几个赋值语句： 1. short b = 1; 2. short b = 1; ++b; 3. short b = 1; b+=1; 4. short b = 1; b = b + 1; 前三段代码没问题，最后一段代码编译器会报错：cannot convert from int to short","text":"一、问题的提出有这么几个赋值语句： 1. short b = 1; 2. short b = 1; ++b; 3. short b = 1; b+=1; 4. short b = 1; b = b + 1; 前三段代码没问题，最后一段代码编译器会报错：cannot convert from int to short 二、问题的分析与解答我之前学过C，C标准规定，整数常量的类型是能容纳该整数的最小类型。所以在C中，b=b+1是不会报错的。Java不一样，Java语言规范明确说：整数常量如果末尾带L是long类型，不带L则是int类型(An integer literal is of type long if it is suffixed with an ASCII letter L or l (ell); otherwise it is of type int )。所以1是int类型，b+1的结果是int类型，而b是short类型，int赋值给short又没有经过强转就会报错。按这个思路，++和+＝为啥不报错？有人说++和+＝会自动强转。好，我先接受这个说法。那么b＝1为什么也不报错？ 带着困惑，我又去查了Java语言规范。Java把short、byte提升到int这种情况称为widening conversion，把int转为short或byte这种情况称为narrowing conversion。在赋值时，Java要求赋值=右边的类型必须被转为＝左边的类型。Java会自动执行5种转换，其中有widening conversion而没有narrowing conversion。所以， 上面第4段代码中b=b+1的右边是int，Java不会自动转为short，于是造成＝左右类型不一致，报错。 好，问题来了：short b=1 、++b 和 b+=1也有int转short的情况，为什么不报错？答案只能是：它们属于特殊情况。 对于short b = 1 Java语言规范说：如果＝的右边是常量表达式，而且类型是byte、short、char或int，那么Java在必要时会自动执行narrowing conversion，只要这个常量表达式的值在＝左边,并且变量的取值范围之内(if the expression is a constant expression of type byte, short, char, or int: A narrowing primitive conversion may be used if the type of the variable is byte, short, or char, and the value of the constant expression is representable in the type of the variable) 哦，原来如此！short b = 1; 1是常量表达式，类型是int，且在short的取值范围之内，所以Java自动强转，不会报错。但如果你写short b=200000，200000虽然是常量，但超过short取值范围，照样报错。 对于++， Java语言规范说：如有必要，++计算之后的结果会先执行narrowing conversion，再存入变量中（If necessary, the sum is narrowed by a narrowing primitive conversion and/or subjected to boxing conversion (§5.1.7) to the type of the variable before it is stored）。也就是说，虽然b是short类型，但Java在++运算上的自动强转保证了++b不会报错同样，对于+=Java也会自动强转。对于b+＝1，Java会转成b = (short)(b+1) 因为之前受C语言的影响，这两天看到相关帖子，搞得我云里雾里。查了Java语言规范，总算是搞清楚了，发出来和大家分享一下。 原文连接","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"}]},{"title":"子查询的方式实现sql语句的先排序后分组","slug":"子查询的方式实现sql语句的先排序后分组","date":"2017-06-22T13:18:36.000Z","updated":"2019-05-01T13:51:07.479Z","comments":true,"path":"2017/06/22/子查询的方式实现sql语句的先排序后分组/","link":"","permalink":"https://tokerr.github.io/2017/06/22/子查询的方式实现sql语句的先排序后分组/","excerpt":"需求：查询学生表当中每一门课程成绩最高的记录。 思路：先按分数对记录进行降序，然后按照课程进行分组即可实现。","text":"需求：查询学生表当中每一门课程成绩最高的记录。 思路：先按分数对记录进行降序，然后按照课程进行分组即可实现。Student表结构： 现在手动添加如下数据进去： 起初，按照原来的思路，我编写的sql语句如下图(第一句)，得到的结果却不是我们想要的，可以看到group by字句先于Order by执行了，效果如图(下一部分)： 因此，使用子查询的方式先对数据进行降序，对新的结果集给一个别名，然后再按课程进行分组，如下：","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://tokerr.github.io/tags/sql/"}]},{"title":"JVM加载class文件的原理机制[转]","slug":"JVM加载class文件的原理机制-转","date":"2017-06-07T13:56:54.000Z","updated":"2019-05-01T13:51:07.473Z","comments":true,"path":"2017/06/07/JVM加载class文件的原理机制-转/","link":"","permalink":"https://tokerr.github.io/2017/06/07/JVM加载class文件的原理机制-转/","excerpt":"JVM加载class文件的原理机制 一、摘要当执行 java *.class 的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。 二、JVM 简介是我们Javase 的最基本功底了，刚开始学Java 的时候，一般都是从“Hello World ”开始的，然后会写个复杂点class ，然后再找一些开源框架，比如Spring ，Hibernate 等等，再然后就开发企业级的应用，比如网站、企业内部应用、实时交易系统等等，直到某一天突然发现做的系统咋就这么慢呢，而且时不时还来个内存溢出什么的，今天是交易系统报了StackOverflowError ，明天是网站系统报了个OutOfMemoryError ，这种错误又很难重现，只有分析Javacore 和dump 文件，运气好点还能分析出个结果，运行遭的点，就直接去庙里烧香吧！每天接客户的电话都是战战兢兢的，生怕再出什么幺蛾子了。我想Java 做的久一点的都有这样的经历，那这些问题的最终根结是在哪呢？—— JVM 。 JVM 全称是Java Virtual Machine ，Java 虚拟机，也就是在计算机上再虚拟一个计算机，这和我们使用 VMWare不一样，那个虚拟的东西你是可以看到的，这个JVM 你是看不到的，它存在内存中。我们知道计算机的基本构成是：运算器、控制器、存储器、输入和输出设备，那这个JVM 也是有这成套的元素，运算器是当然是交给硬件CPU 还处理了，只是为了适应“一次编译，随处运行”的情况，需要做一个翻译动作，于是就用了JVM 自己的命令集，这与汇编的命令集有点类似，每一种汇编命令集针对一个系列的CPU ，比如8086 系列的汇编也是可以用在8088 上的，但是就不能跑在8051 上，而JVM 的命令集则是可以到处运行的，因为JVM 做了翻译，根据不同的CPU ，翻译成不同的机器语言。 JVM 中我们最需要深入理解的就是它的存储部分，存储？硬盘？NO ，NO ， JVM 是一个内存中的虚拟机，那它的存储就是内存了，我们写的所有类、常量、变量、方法都在内存中，这决定着我们程序运行的是否健壮、是否高效，接下来的部分就是重点介绍之一。","text":"JVM加载class文件的原理机制 一、摘要当执行 java *.class 的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。 二、JVM 简介是我们Javase 的最基本功底了，刚开始学Java 的时候，一般都是从“Hello World ”开始的，然后会写个复杂点class ，然后再找一些开源框架，比如Spring ，Hibernate 等等，再然后就开发企业级的应用，比如网站、企业内部应用、实时交易系统等等，直到某一天突然发现做的系统咋就这么慢呢，而且时不时还来个内存溢出什么的，今天是交易系统报了StackOverflowError ，明天是网站系统报了个OutOfMemoryError ，这种错误又很难重现，只有分析Javacore 和dump 文件，运气好点还能分析出个结果，运行遭的点，就直接去庙里烧香吧！每天接客户的电话都是战战兢兢的，生怕再出什么幺蛾子了。我想Java 做的久一点的都有这样的经历，那这些问题的最终根结是在哪呢？—— JVM 。 JVM 全称是Java Virtual Machine ，Java 虚拟机，也就是在计算机上再虚拟一个计算机，这和我们使用 VMWare不一样，那个虚拟的东西你是可以看到的，这个JVM 你是看不到的，它存在内存中。我们知道计算机的基本构成是：运算器、控制器、存储器、输入和输出设备，那这个JVM 也是有这成套的元素，运算器是当然是交给硬件CPU 还处理了，只是为了适应“一次编译，随处运行”的情况，需要做一个翻译动作，于是就用了JVM 自己的命令集，这与汇编的命令集有点类似，每一种汇编命令集针对一个系列的CPU ，比如8086 系列的汇编也是可以用在8088 上的，但是就不能跑在8051 上，而JVM 的命令集则是可以到处运行的，因为JVM 做了翻译，根据不同的CPU ，翻译成不同的机器语言。 JVM 中我们最需要深入理解的就是它的存储部分，存储？硬盘？NO ，NO ， JVM 是一个内存中的虚拟机，那它的存储就是内存了，我们写的所有类、常量、变量、方法都在内存中，这决定着我们程序运行的是否健壮、是否高效，接下来的部分就是重点介绍之一。 三、JVM 的组成部分我们先把JVM 这个虚拟机画出来，如下图所示： 从这个图中可以看到，JVM 是运行在操作系统之上的，它与硬件没有直接的交互。我们再来看下JVM 有哪些组成部分，如下图所示： 该图参考了网上广为流传的JVM 构成图，大家看这个图，整个JVM 分为四部分： Class Loader 类加载器类加载器的作用是加载类文件到内存，比如编写一个HelloWord.java 程序，然后通过javac 编译成class 文件，那怎么才能加载到内存中被执行呢？Class Loader 承担的就是这个责任，那不可能随便建立一个.class 文件就能被加载的，Class Loader 加载的class 文件是有格式要求，在《JVM Specification 》中式这样定义Class 文件的结构： ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count]; } 需要详细了解的话，可以仔细阅读《JVM Specification 》的第四章“The class File Format ”，这里不再详细说明。友情提示：Class Loader 只管加载，只要符合文件结构就加载，至于说能不能运行，则不是它负责的，那是由Execution Engine 负责的。 Execution Engine 执行引擎执行引擎也叫做解释器(Interpreter) ，负责解释命令，提交操作系统执行。 Native Interface 本地接口本地接口的作用是融合不同的编程语言为Java 所用，它的初衷是融合C/C++ 程序，Java 诞生的时候是C/C++ 横行的时候，要想立足，必须有一个聪明的、睿智的调用C/C++ 程序，于是就在内存中专门开辟了一块区域处理标记为native 的代码，它的具体做法是Native Method Stack 中登记native 方法，在Execution Engine 执行时加载native libraies 。目前该方法使用的是越来越少了，除非是与硬件有关的应用，比如通过Java 程序驱动打印机，或者Java 系统管理生产设备，在企业级应用中已经比较少见，因为现在的异构领域间的通信很发达，比如可以使用Socket 通信，也可以使用Web Service 等等，不多做介绍。 Runtime data area 运行数据区运行数据区是整个JVM 的重点。我们所有写的程序都被加载到这里，之后才开始运行，Java 生态系统如此的繁荣，得益于该区域的优良自治，下一章节详细介绍之。 &emsp;&emsp;整个JVM 框架由加载器加载文件，然后执行器在内存中处理数据，需要与异构系统交互是可以通过本地接口进行，瞧，一个完整的系统诞生了！ 三、JVM加载class文件的原理机制 Java中的所有类，必须被装载到jvm中才能运行，这个装载工作是由jvm中的类装载器完成的,类装载器所做的工作实质是把类文件从硬盘读取到内存中 java中的类大致分为三种： 1.系统类 2.扩展类 3.由程序员自定义的类 类装载方式，有两种 1.隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中 2.显式装载， 通过class.forname()等方法，显式加载需要的类隐式加载与显式加载的区别，两者本质是一样? 类加载的动态性体现 &emsp;&emsp;一个应用程序总是由n多个类组成，Java程序启动时，并不是一次把所有的类全部加载后再运行，它总是先把保证程序运行的基础类一次性加载到jvm中，其它类等到jvm用到的时候再加载，这样的好处是节省了内存的开销，因为java最早就是为嵌入式系统而设计的，内存宝贵，这是一种可以理解的机制，而用到时再加载这也是java动态性的一种体现 java类装载器 Java中的类装载器实质上也是类，功能是把类载入jvm中，值得注意的是jvm的类装载器并不是一个，而是三个，层次结构如下： Bootstrap Loader - 负责加载系统类 &emsp;&emsp;&emsp;&emsp;| &emsp;&emsp;- - ExtClassLoader - 负责加载扩展类 &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; | &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;- - AppClassLoader - 负责加载应用类 &emsp;&emsp;为什么要有三个类加载器，一方面是分工，各自负责各自的区块，另一方面为了实现委托模型，下面会谈到该模型 类加载器之间是如何协调工作的&emsp;&emsp;前面说了，java中有三个类加载器，问题就来了，碰到一个类需要加载时，它们之间是如何协调工作的，即java是如何区分一个类该由哪个类加载器来完成呢。&emsp;&emsp;在这里java采用了委托模型机制，这个机制简单来讲，就是“类装载器有载入类的需求时，会先请示其Parent使用其搜索路径帮忙载入，如果Parent 找不到,那么才由自己依照自己的搜索路径搜索类”，注意喔，这句话具有递归性 Java代码 1. /** 2. * @author Jamson Huang 3. * 4. */ 5. public class TestClass { 6. 7. /** 8. * @param args 9. */ 10. public static void main(String[] args) throws Exception{ 11. //调用class加载器 12. ClassLoader cl = TestClass.class .getClassLoader(); 13. System.out.println(cl); 14. //调用上一层Class加载器 15. ClassLoader clParent = cl.getParent(); 16. System.out.println(clParent); 17. //调用根部Class加载器 18. ClassLoader clRoot = clParent.getParent(); 19. System.out.println(clRoot); 20. 21. } 22. 23. } Result代码 1. Run， Console中出现的log信息如下： 2. sun.misc.Launcher$AppClassLoader@7259da 3. sun.misc.Launcher$ExtClassLoader@16930e2 4. null &emsp;&emsp;可以看出TestClass是由AppClassLoader加载器加载的AppClassLoader的Parent 加载器是ExtClassLoader但是ExtClassLoader的Parent为 null 是怎么回事呵，朋友们留意的话，前面有提到Bootstrap Loader是用C++语言写的,依java的观点来看，逻辑上并不存在Bootstrap Loader的类实体，所以在java程序代码里试图打印出其内容时，我们就会看到输出为null 【注：以下内容大部分引用java深度历险】 &emsp;&emsp;弄明白了上面的示例，接下来直接进入类装载的委托模型实例，写两个文件，如下：Java代码 1. /** 2. * @author Jamson Huang 3. * 4. */ 5. public class Test1 { 6. 7. /** 8. * @param args 9. */ 10. public static void main(String[] args) throws Exception { 11. System.out.println(Test1.class .getClassLoader()); 12. 13. Test2 test2 = new Test2(); 14. 15. test2.print(); 16. } 17. 18. } 19. /** 20. * @author Jamson Huang 21. * 22. */ 23. public class Test2 { 24. public void print(){ 25. System.out.println(Test2.class ); 26. System.out.println(this .getClass()); 27. System.out.println(Test2.class .getClassLoader()); 28. } 29. } Result代码 1. Run,Console出现log如下： 2. sun.misc.Launcher$AppClassLoader@7259da 3. class com.java.test.Test2 4. class com.java.test.Test2 5. sun.misc.Launcher$AppClassLoader@7259da 7.预先加载与依需求加载 &emsp;&emsp;Java 运行环境为了优化系统，提高程序的执行速度，在 JRE 运行的开始会将 Java 运行所需要的基本类采用预先加载（ pre-loading ）的方法全部加载要内存当中，因为这些单元在 Java 程序运行的过程当中经常要使用的，主要包括 JRE 的 rt.jar 文件里面所有的 .class 文件。 &emsp;&emsp;当 java.exe 虚拟机开始运行以后，它会找到安装在机器上的 JRE 环境，然后把控制权交给 JRE ， JRE 的类加载器会将 lib 目录下的 rt.jar 基础类别文件库加载进内存，这些文件是 Java 程序执行所必须的，所以系统在开始就将这些文件加载，避免以后的多次 IO 操作，从而提高程序执行效率。 图（ 2 ）我们可以看到多个基础类被加载,java.lang.Object,java.io.Serializable 等等。&emsp;&emsp;相对于预先加载，我们在程序中需要使用自己定义的类的时候就要使用依需求加载方法（ load-on-demand ），就是在 Java 程序需要用到的时候再加载，以减少内存的消耗，因为 Java 语言的设计初衷就是面向嵌入式领域的。 8.自定义类加载机制 &emsp;&emsp;之前我们都是调用系统的类加载器来实现加载的，其实我们是可以自己定义类加载器的。利用 Java 提供的 java.net.URLClassLoader 类就可以实现。下面我们看一段范例： Java代码 1. try { 2. URL url = new URL( &quot;file:/d:/test/lib/&quot; ); 3. URLClassLoader urlCL = new URLClassLoader( new URL[]{url}); 4. Class c = urlCL.loadClass(&quot;TestClassA&quot; ); 5. TestClassA object = (TestClassA)c.newInstance(); 6. object.method(); 7. }catch (Exception e){ 8. e.printStackTrace(); 9. } &emsp;&emsp;我们通过自定义的类加载器实现了 TestClassA 类的加载并调用 method （）方法。分析一下这个程序：首先定义 URL 指定类加载器从何处加载类， URL 可以指向网际网络上的任何位置，也可以指向我们计算机里的文件系统 ( 包含 JAR 文件 ) 。上述范例当中我们从 file:/d:/test/lib/ 处寻找类；然后定义 URLClassLoader 来加载所需的类，最后即可使用该实例了。 9.类加载器的阶层体系 讨论了这么多以后，接下来我们仔细研究一下 Java 的类加载器的工作原理： 当执行 java *.class 的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。 下面的图形可以表示三者之间的关系： BootstrapLoader &lt;—(Extends)—-AppClassLoader &lt;—(Extends)—-ExtClassLoader 这三个加载器就构成我们的 Java 类加载体系。他们分别从以下的路径寻找程序所需要的类： BootstrapLoader ： sun.boot.class.path ExtClassLoader: java.ext.dirs AppClassLoader: java.class.path 这三个系统参量可以通过 System.getProperty() 函数得到具体对应的路径。大家可以自己编程实现查看具体的路径。 原文连接","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://tokerr.github.io/tags/jvm/"},{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"javase","slug":"javase","permalink":"https://tokerr.github.io/tags/javase/"},{"name":"java虚拟机","slug":"java虚拟机","permalink":"https://tokerr.github.io/tags/java虚拟机/"}]},{"title":"实现Set或者List集合的升(降)排序（实现Comparator接口的方式）","slug":"实现Set或者List集合的升-降-排序（实现Comparable接口的方式）","date":"2017-06-06T15:01:38.000Z","updated":"2019-05-01T13:51:07.480Z","comments":true,"path":"2017/06/06/实现Set或者List集合的升-降-排序（实现Comparable接口的方式）/","link":"","permalink":"https://tokerr.github.io/2017/06/06/实现Set或者List集合的升-降-排序（实现Comparable接口的方式）/","excerpt":"一、知识储备实现集合排序的两种方式：实现集合的排序有两种方式，下面以TreeSet集合为例: 方式一：元素自身具备比较性元素自身具备比较性，需要元素实现Comparable接口，重写compareTo方法，也就是让元素自身具备比较性，这种方式叫做元素的自然排序也叫做默认排序。 方式二：容器具备比较性当元素自身不具备比较性，或者自身具备的比较性不是所需要的。那么此时可以让容器自身具备。需要定义一个类实现接口Comparator，重写compare方法，并将该接口的子类实例对象作为参数传递给TreeMap集合的构造方法。注意：在重写compareTo或者compare方法时，必须要明确比较的主要条件相等时要比较次要条件。（假设姓名和年龄一直的人为相同的人，如果想要对人按照年龄的大小来排序，如果年龄相同的人，需要如何处理？不能直接return 0，因为可能姓名不同（年龄相同姓名不同的人是不同的人）。此时就需要进行次要条件判断（需要判断姓名），只有姓名和年龄同时相等的才可以返回0.）通过return 0来判断唯一性。","text":"一、知识储备实现集合排序的两种方式：实现集合的排序有两种方式，下面以TreeSet集合为例: 方式一：元素自身具备比较性元素自身具备比较性，需要元素实现Comparable接口，重写compareTo方法，也就是让元素自身具备比较性，这种方式叫做元素的自然排序也叫做默认排序。 方式二：容器具备比较性当元素自身不具备比较性，或者自身具备的比较性不是所需要的。那么此时可以让容器自身具备。需要定义一个类实现接口Comparator，重写compare方法，并将该接口的子类实例对象作为参数传递给TreeMap集合的构造方法。注意：在重写compareTo或者compare方法时，必须要明确比较的主要条件相等时要比较次要条件。（假设姓名和年龄一直的人为相同的人，如果想要对人按照年龄的大小来排序，如果年龄相同的人，需要如何处理？不能直接return 0，因为可能姓名不同（年龄相同姓名不同的人是不同的人）。此时就需要进行次要条件判断（需要判断姓名），只有姓名和年龄同时相等的才可以返回0.）通过return 0来判断唯一性。 TreeSet集合 TreeSet内部是红-黑树的数据结构，默认对元素进行自然排序（String）。如果在比较的时候两个对象返回值为0，那么元素重复。 红黑树是一种特定类型的二叉树。 红黑树算法的规则: 左小右大。既然TreeSet可以自然排序,那么TreeSet必定是有排序规则的。让存入的元素自定义比较规则。 二、案例演示package com.nyt.change; import java.util.ArrayList; import java.util.Collections; import java.util.Comparator; import java.util.List; import java.util.TreeSet; import org.junit.Test; public class Test3 { @Test public void sortByArrayList() { User u1 = new User(1, 20); User u2 = new User(3, 22); User u3 = new User(4, 26); User u4 = new User(2, 24); User u5 = new User(1, 24); User u6 = new User(2, 24); List&lt;User&gt; list=new ArrayList&lt;User&gt;(); list.add(u1); list.add(u2); list.add(u3); list.add(u4); list.add(u5); list.add(u6); System.out.println(&quot;======排序之前=======&quot;); for (User u : list) { System.out.println(u); } //按照id升序，按照age降序(次要条件) Collections.sort(list,new myComparator()); System.out.println(&quot;======排序之后=======&quot;); for (User u : list) { System.out.println(u); } } /**sortByArrayList()运行结果 * ======排序之前======= User [id=1, age=20] User [id=3, age=22] User [id=4, age=26] User [id=2, age=24] User [id=1, age=24] User [id=2, age=24] ======排序之后======= User [id=1, age=24] User [id=1, age=20] User [id=2, age=24] User [id=2, age=24] User [id=3, age=22] User [id=4, age=26] * */ /** * 使用TreeSet集合排序 * @author tok * */ @Test public void sortByTreeSet(){ TreeSet&lt;User&gt; set=new TreeSet&lt;User&gt;(new myComparator()); // Set&lt;User&gt; set=new TreeSet&lt;User&gt;(new myComparator()); set.add(new User(1, 20)); set.add(new User(3, 22)); set.add(new User(4, 26)); set.add(new User(2, 24)); set.add(new User(2, 24)); set.add(new User(1, 24)); for (User user : set) { System.out.println(user); } } /**sortByTreeSet()运行结果 * User [id=1, age=24] User [id=1, age=20] User [id=2, age=24] User [id=3, age=22] User [id=4, age=26] * @author Administrator * */ class myComparator implements Comparator{ @Override public int compare(Object o1, Object o2) { if (!(o1 instanceof User) || !(o2 instanceof User)) return 0; User u1=(User)o1; User u2=(User)o2; /** * 口诀:正正得正，正负得负，PS:自己体会 * 按照id升序排序 */ if(u1.getId()&lt;u2.getId())//注意两者的大小 return -1;//会按照id进行降序 if(u1.getId()&gt;u2.getId())//注意两者的大小 return 1;//会按照id进行降序 /** * 按照age降序,次要条件 */ if((u1.getId()==u2.getId())){ if(u1.getAge()&gt;u2.getAge()) return -1; if(u1.getAge()&lt;u2.getAge()) return 1; } /** * 两个对象相等 */ // if(u1.getId()==u2.getId() &amp;&amp; u1.getAge()==u2.getAge()) // return 0; //否则认为两个对象相等,如果是Set集合将会被过滤掉 return 0; } } } 三、疑惑解答问题:为什么使用TreeSet存入字符串,字符串默认输出是按升序排列的? 答:1.因为字符串实现了一个接口,叫做Comparable 接口.字符串重写了该接口的compareTo 方法,所以String对象具备了比较性.那么同样道理,我的自定义元素(例如Person类,Book类)想要存入TreeSet集合,就需要实现该接口,也就是要让自定义对象具备比较性. 2.存入TreeSet集合中的元素要具备比较性.比较性要实现Comparable接口，重写该接口的compareTo方法TreeSet属于Set集合，该集合的元素是不能重复的，TreeSet如何保证元素的唯一性通过compareTo或者compare方法中的来保证元素的唯一性。 3.添加的元素必须要实现Comparable接口。当compareTo()函数返回值为0时，说明两个对象相等，此时该对象不会添加进来。 4.当Comparable比较方式，及Comparator比较方式同时存在，以Comparator比较方式为主。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"集合","slug":"集合","permalink":"https://tokerr.github.io/tags/集合/"},{"name":"Collection","slug":"Collection","permalink":"https://tokerr.github.io/tags/Collection/"},{"name":"升序，降序","slug":"升序，降序","permalink":"https://tokerr.github.io/tags/升序，降序/"},{"name":"Set","slug":"Set","permalink":"https://tokerr.github.io/tags/Set/"},{"name":"List","slug":"List","permalink":"https://tokerr.github.io/tags/List/"}]},{"title":"String类型两种创建对象的方式的内存分配","slug":"String类型两种创建对象的方式的内存分配","date":"2017-06-04T15:25:47.000Z","updated":"2019-05-01T13:51:07.476Z","comments":true,"path":"2017/06/04/String类型两种创建对象的方式的内存分配/","link":"","permalink":"https://tokerr.github.io/2017/06/04/String类型两种创建对象的方式的内存分配/","excerpt":"","text":"一张图就可以看明白","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"String","slug":"String","permalink":"https://tokerr.github.io/tags/String/"}]},{"title":"以下代码创建了几个对象[转]","slug":"以下代码创建了几个对象","date":"2017-06-04T15:09:26.000Z","updated":"2019-05-01T13:51:07.478Z","comments":true,"path":"2017/06/04/以下代码创建了几个对象/","link":"","permalink":"https://tokerr.github.io/2017/06/04/以下代码创建了几个对象/","excerpt":"问题：以下代码创建了几个对象 String a,b,c; a = &quot;a&quot;; b = &quot;b&quot;; a = a+b; StringBuffer d = new StringBuffer(&quot;abc&quot;); d = d.append(&quot;567&quot;); 先说一下我的答案: 我感觉是 3 个.首先, 明确一下 创建对象 的具体含义. 按我的理解, 如果字符串是 字符常量, 那么这个字符串对象是在编译时候确定好的, 它是存放在常量池中的, 因此就不算是创建了一个字符串对象, 而如果有 String b = new String(&quot;abc&quot;)之类的操作, 那么可以认为是创建了字符串对象, 并与变量 b 关联.根据上面的定义, 那么有: “a”, “b”, “abc”, “567” 都是常量, 放在常量池中的, 因此就不算是创建对象了.那么来看一下代码:源码:","text":"问题：以下代码创建了几个对象 String a,b,c; a = &quot;a&quot;; b = &quot;b&quot;; a = a+b; StringBuffer d = new StringBuffer(&quot;abc&quot;); d = d.append(&quot;567&quot;); 先说一下我的答案: 我感觉是 3 个.首先, 明确一下 创建对象 的具体含义. 按我的理解, 如果字符串是 字符常量, 那么这个字符串对象是在编译时候确定好的, 它是存放在常量池中的, 因此就不算是创建了一个字符串对象, 而如果有 String b = new String(&quot;abc&quot;)之类的操作, 那么可以认为是创建了字符串对象, 并与变量 b 关联.根据上面的定义, 那么有: “a”, “b”, “abc”, “567” 都是常量, 放在常量池中的, 因此就不算是创建对象了.那么来看一下代码:源码: 1: String a,b,c; 2: a = “a”; 3: b = “b”; 4: a = a+b; 5: StringBuffer d = new StringBuffer(“abc”); 6: d = d.append(“567”);为了方便起见, 我手动给每一行编号了.再来看一下对应的字节码: Code: stack=3, locals=5, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: new #4 // class java/lang/StringBuilder 9: dup 10: invokespecial #5 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 13: aload_1 14: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 17: aload_2 18: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 21: invokevirtual #7 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 24: astore_1 25: new #8 // class java/lang/StringBuffer 28: dup 29: ldc #9 // String abc 31: invokespecial #10 // Method java/lang/StringBuffer.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V 34: astore 4 36: aload 4 38: ldc #11 // String 567 40: invokevirtual #12 // Method java/lang/StringBuffer.append:(Ljava/lang/String;)Ljava/lang/StringBuffer; 43: astore 4 45: return 由字节码可以看出, 源码的第四行 a = a+b翻译为如下代码: StringBuilder builder = new StringBuilder(); builder.append(a); builder.append(b); a = builder.toString(); 那么这里就新建了一个对象 new StringBuilder(), 接着调用 builder.toString() 方法, 它源码如下: @Overridepublic String toString() { // Create a copy, don&apos;t share the array return new String(value, 0, count); } 于是 builder.toString() 方法创建了一个 String 对象, 因此目前我们已经创建了 两个对象 了.接着第五行 StringBuffer d = new StringBuffer(&quot;abc&quot;) 毫无疑问是 创建了对象 StringBuffer, 于是我们就有 三个对象 了. 有一点需要注意的是 StringBuffer d 从始至终都没有调用 toString 方法, 因此就不会有多余的 String 创建出来.总结: * &quot;a&quot;: 字符串常量, 不算创建对象 * &quot;b&quot;: 字符串常量, 不算创建对象 * builder 对象: 在执行 a = a+b 时创建. * &quot;ab&quot;: 由 StringBuilder.toString() 创建. * &quot;abc&quot;: 字符串常量, 不算创建对象 * &quot;567&quot;: 字符串常量, 不算创建对象 * d: 通过 new StringBuffer(&quot;abc&quot;) 创建. 因此最终有三个对象创建了. 原文连接","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"String","slug":"String","permalink":"https://tokerr.github.io/tags/String/"}]},{"title":"Java运行时异常和非运行时异常","slug":"Java运行时异常和非运行时异常","date":"2017-05-28T02:21:04.000Z","updated":"2019-05-01T13:51:07.474Z","comments":true,"path":"2017/05/28/Java运行时异常和非运行时异常/","link":"","permalink":"https://tokerr.github.io/2017/05/28/Java运行时异常和非运行时异常/","excerpt":"1.Java异常机制Java把异常当做对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。Java中的异常分为两大类：错误Error和异常Exception，Java异常体系结构如下图所示： 2.ThrowableThrowable类是所有异常或错误的超类，它有两个子类：Error和Exception，分别表示错误和异常。其中异常Exception分为运行时异常(RuntimeException)和非运行时异常，也称之为不检查异常(Unchecked Exception)和检查异常(Checked Exception)。 3.Error一般是指java虚拟机相关的问题，如系统崩溃、虚拟机出错误、动态链接失败等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常应用程序无法处理这些错误，因此应用程序不应该捕获Error对象，也无须在其throws子句中声明该方法抛出任何Error或其子类。","text":"1.Java异常机制Java把异常当做对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。Java中的异常分为两大类：错误Error和异常Exception，Java异常体系结构如下图所示： 2.ThrowableThrowable类是所有异常或错误的超类，它有两个子类：Error和Exception，分别表示错误和异常。其中异常Exception分为运行时异常(RuntimeException)和非运行时异常，也称之为不检查异常(Unchecked Exception)和检查异常(Checked Exception)。 3.Error一般是指java虚拟机相关的问题，如系统崩溃、虚拟机出错误、动态链接失败等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常应用程序无法处理这些错误，因此应用程序不应该捕获Error对象，也无须在其throws子句中声明该方法抛出任何Error或其子类。 4.可查异常和不可查异常通常，Java的异常(包括Exception和Error)分为可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）。可查异常（编译器要求必须处置的异常）：正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。不可查异常(编译器不要求强制处置的异常):包括运行时异常（RuntimeException与其子类）和错误（Error）。如果使用throw在方法体中抛出可查异常，则需要在方法头部声明方法可能抛出的异常类型。程序会在throw语句后立即终止，它后面的语句执行不到，然后在包含它的所有try块中（可能在上层调用函数中）从里向外寻找含有与其匹配的catch子句的try块。 5.运行时异常和非运行时异常(1)运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。当出现RuntimeException的时候，我们可以不处理。当出现这样的异常时，总是由虚拟机接管。比如：我们从来没有人去处理过NullPointerException异常，它就是运行时异常，并且这种异常还是最常见的异常之一。出现运行时异常后，如果没有捕获处理这个异常（即没有catch），系统会把异常一直往上层抛，一直到最上层，如果是多线程就由Thread.run()抛出，如果是单线程就被main()抛出。抛出之后，如果是线程，这个线程也就退出了。如果是主程序抛出的异常，那么这整个程序也就退出了。运行时异常是Exception的子类，也有一般异常的特点，是可以被catch块处理的。只不过往往我们不对他处理罢了。也就是说，你如果不对运行时异常进行处理，那么出现运行时异常之后，要么是线程中止，要么是主程序终止。如果不想终止，则必须捕获所有的运行时异常，决不让这个处理线程退出。队列里面出现异常数据了，正常的处理应该是把异常数据舍弃，然后记录日志。不应该由于异常数据而影响下面对正常数据的处理。 (2)非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。如IOException、SQLException等以及用户自定义的Exception异常。对于这种异常，JAVA编译器强制要求我们必需对出现的这些异常进行catch并处理，否则程序就不能编译通过。所以，面对这种异常不管我们是否愿意，只能自己去写一大堆catch块去处理可能的异常。 6.finally关键字来看看下面这个test1()方法： public int test1() { try { return 1; } finally { return 2; } } 方法test1将返回2； 怎么解释呢？再来看看下面这个test2()方法： public int test2() { int i = 1; try { System.out.println(&quot;try语句块中&quot;); return 1; } finally { System.out.println(&quot;finally语句块中&quot;); return 2; } } 运行结果是： try语句块中 finally语句块中 2 从运行结果中可以发现，try中的return语句调用的函数先于finally中调用的函数执行，也就是说return语句先执行，finally语句后执行，所以，返回的结果是2。return并不是让函数马上返回，而是return语句执行后，将把返回结果放置进函数栈中，此时函数并不是马上返回，它要执行finally语句后才真正开始返回。 常见RuntimeException：ArrayStoreException 试图将错误类型的对象存储到一个对象数组时抛出的异常 ClassCastException 试图将对象强制转换为不是实例的子类时，抛出该异常 IllegalArgumentException 抛出的异常表明向方法传递了一个不合法或不正确的参数 IndexOutOfBoundsException 指示某排序索引（例如对数组、字符串或向量的排序）超出范围时抛出 NoSuchElementException 表明枚举中没有更多的元素 NullPointerException 当应用程序试图在需要对象的地方使用 null 时，抛出该异常","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"exception","slug":"exception","permalink":"https://tokerr.github.io/tags/exception/"},{"name":"异常","slug":"异常","permalink":"https://tokerr.github.io/tags/异常/"}]},{"title":"mybatis连接oracle执行sql语句出现ORA-00904: invalid identifier","slug":"mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier","date":"2017-05-07T10:03:30.000Z","updated":"2019-05-01T13:51:07.477Z","comments":true,"path":"2017/05/07/mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier/","link":"","permalink":"https://tokerr.github.io/2017/05/07/mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier/","excerpt":"一、总结使用mybatis连接oracle数据库进行查询，最好确保表命全大写，否者会出现ORA-00904: invalid identifier的问题 注：本人使用的mybatis版本是3.0.5 二、问题描述： 我使用ibator工具产生的代码，有一个Dao的测试类，但是一执行就出现了ORA-00904: invalid identifier，如图：","text":"一、总结使用mybatis连接oracle数据库进行查询，最好确保表命全大写，否者会出现ORA-00904: invalid identifier的问题 注：本人使用的mybatis版本是3.0.5 二、问题描述： 我使用ibator工具产生的代码，有一个Dao的测试类，但是一执行就出现了ORA-00904: invalid identifier，如图： 原因分析，大部分情况下是由于引用了不存在的列名导致的。 解决的办法就是检查自己引用的列名称是否一致。对于某些工具生成的sql，可能导致列名称和期望不符的情况，比如，有些工具生成的列名称会带双引号，从而导致此错误。 经过查询和本人的实践验证，oracle执行查询时（这里以11g为例），对于特殊的字段命名有着非常严格的语法要求，如果是字段名称按照单词首字母大写的规范进行命名，在进行条件查询的时候必须，字段名称必须与原来命名一样并且要加上双引号，否则会包ORA-00904: invalid identifier。以下是本案例的测试截图： 表结构： 执行查询： 从执行的结果可以知道，最终oracle在执行sql语句的时候把条件查询的字段名转成了全大写，遇到表中没有找到相关的字段(区分大小写)，就出现了此错误。查询指定字段的值也是如此： 表结构： 执行查询： 三、解决办法总结： 3.1oracle在执行sql语句进行查询的时候，默认的情况下(查询的时候不给字段加双引号)，会将字段名称转换成全大写之后再到表中进行匹配查询，比如：执行select from dept where id=1，则实际执行的是:select from DEPT where ID=1，这里表名和字段名全部都会转成全大写去匹配查询，一旦匹配不到(真正匹配字段名和名的时候区分大小写)，则会报错误。 3.2如果设计表的时候不想表名和字段名都全大写，则在进行查询的时候需要在表名或者字段名称加上双引号(相当于告知oracle不要对sql语句中指定的表名或者字段名转成全大写)，并且区分大小写，这样执行查询才不会发生错误。 ##解决方法##因此解决的办法就是，在给字段名称进行命名的时候，建议全大写，对于表名也是全大写命名，这样不管是进行条件查询还是查询指定字段的名称的时候，都不需要严格区分大小写了并且还要加上双引号了，Oracle会自动帮你先转成全大写之后再进行匹配查询。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://tokerr.github.io/tags/mybatis/"},{"name":"oracle","slug":"oracle","permalink":"https://tokerr.github.io/tags/oracle/"}]},{"title":"使用ibator无法根据oracle数据库中的表结构产生代码[解决方法]","slug":"关于使用ibator工具连接oracle数据库生成代码的使用问题","date":"2017-05-06T11:11:35.000Z","updated":"2019-05-01T13:51:07.479Z","comments":true,"path":"2017/05/06/关于使用ibator工具连接oracle数据库生成代码的使用问题/","link":"","permalink":"https://tokerr.github.io/2017/05/06/关于使用ibator工具连接oracle数据库生成代码的使用问题/","excerpt":"一、总结使用ibator根据oracle中的表结构生成代码时，一定要确保每张表的表命全大写，否则生成失败 二、问题描述想说的已经在上面描述出来了。下面描述问题的由来已经解决的过程： 就是下面这个工具，我已经集成到了Myeclipse当中","text":"一、总结使用ibator根据oracle中的表结构生成代码时，一定要确保每张表的表命全大写，否则生成失败 二、问题描述想说的已经在上面描述出来了。下面描述问题的由来已经解决的过程： 就是下面这个工具，我已经集成到了Myeclipse当中 以前开始使用的都是mysql数据库，表的名称都是按照首字母大写的规范进行设计，这次的毕业设计项目使用到的是oracle，因为设计表的时候表明也是按照每个单词的首字母大写进行命名的，但是没想到，在使用ibator代码生成器生成pojo 的时候，居然失败的，而且这个问题一直困扰了我一个多月，并且百度谷歌搜索都无果，让我百思不得其解。直到今天在做毕业设计的时候，终于让我把这个问题解决了。 万幸在于，让我发现突破这个问题的关键只所在，在某一次使用这个工具对oracle中的某一张表进行操作的时候成功了(这是在本地真机上的oracle)。之前我把oracle服务器安装在电脑的虚拟机，装的是oracle10g，在使用ibator就出现了这个问题，一直怀疑是可能是因为远程的问题，或者oracle是10G不是oracle11g的版本问题，我就在真机上面装了个oracle11g的数据库，测试的时候自己阴差阳错，建表的sql语句是网上复制过来了，并且表明刚好是全大写，因此那一次就测试成功了。但今天在真机的数据库建表，表名按照单词的首字母大写命名，因此又出现了这个问题。但幸好，经过一番测试对比，终于发现原因之所在，可以说是ibator这个工具的bug吧。 另外，个人惰性思维一发作，真的是可以让人变傻。只通过自己的怀疑推测，而没有经过实践的检验，就下定结论，这是我在这个问题上思维懒惰的一个很好体现，自己下定论千万不要去推测去瞎猜，一定是要在经过实际的检验之后。另一方面是要多思考，出现这个问题的时候我就是怀疑，是因为远程的原因 或者是因为oracle版本的原因，思维懒惰的结果就是我把自己的猜测当成了自己的结论，并以此去指导自己的行为(觉得自己好悲催，问题很严重)，而从没有进一步想过，之前公司的项目也是远程的Mysql数据库使用ibator生成代码的，使用没有问题，这样就可以排除是因为远程的问题导致ibator不可以用了呀；还有怀疑是因为数据库版本的问题，竟然数据库已经成功安装，可以整成使用，跟版本有多大的联系吗？这点就不能排除了，呵呵。 总之，在使用ibator获取oracle中的表结果生成代码时，一定要确保表名全大写；字段名称的命名的话，经过我的测验，字段名称全大写或者按照单词首字母大写的方式命名也是没有问题的，最终生成的pojo属性名都是全小写。 三、关于ibator集成到myeclipse直接把截图上面的两个文件扔到myeclipse安装目录下的dropins文件夹就可以了，这里提供文件的连接，我都已经打包到一起了，解压即可。点我下载","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://tokerr.github.io/tags/mybatis/"},{"name":"oracle","slug":"oracle","permalink":"https://tokerr.github.io/tags/oracle/"},{"name":"ibator","slug":"ibator","permalink":"https://tokerr.github.io/tags/ibator/"}]},{"title":"ORA-12541:TNS:无监听程序","slug":"ORA-12541-TNS-无监听程序","date":"2017-05-06T01:43:13.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/05/06/ORA-12541-TNS-无监听程序/","link":"","permalink":"https://tokerr.github.io/2017/05/06/ORA-12541-TNS-无监听程序/","excerpt":"一、问题描述这两天在做毕业设计，项目用到的是oracle数据库，由于之前用的都是mysql，oracle数据库的应用比较少。于是莫名奇妙的出现了个‘ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务’，也是折腾了两天，无果，今天接着是‘ORA-12541:TNS:无监听程序’，在windows系统的cmd上不使用实例名连接倒是可以登录，但是无法进行正常的查询操作。今天按照网上某篇博客的教程，居然把这个问题解决了，关键的一步是 启动tnslsnr，然后问题就解决了。 其实在今天电脑开始之后，我直接把360安全卫士关闭了，不排除oracle在开机 的时候某些服务被360拦截关闭的情况。 二、附上cmd的操作日志C:\\Users\\Administrator&gt;sqlplus / as sysdba","text":"一、问题描述这两天在做毕业设计，项目用到的是oracle数据库，由于之前用的都是mysql，oracle数据库的应用比较少。于是莫名奇妙的出现了个‘ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务’，也是折腾了两天，无果，今天接着是‘ORA-12541:TNS:无监听程序’，在windows系统的cmd上不使用实例名连接倒是可以登录，但是无法进行正常的查询操作。今天按照网上某篇博客的教程，居然把这个问题解决了，关键的一步是 启动tnslsnr，然后问题就解决了。 其实在今天电脑开始之后，我直接把360安全卫士关闭了，不排除oracle在开机 的时候某些服务被360拦截关闭的情况。 二、附上cmd的操作日志C:\\Users\\Administrator&gt;sqlplus / as sysdba SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:23:15 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; conn tokerr/tokerr 已连接。 SQL&gt; SQL&gt; select table_name from user_tables; TABLE_NAME ------------------------------------------------------------ TESTTABLE1 TESTTABLE2 TESTTABLE3 TESTTABLE4 TESTTABLE5 SQL&gt; select * form TESTTABLE1; select * form TESTTABLE1 * 第 1 行出现错误: ORA-00923: 未找到要求的 FROM 关键字 SQL&gt; select * fROM TESTTABLE1; 未选定行 SQL&gt; select * fROM TESTTABLE2; 未选定行 SQL&gt; select * fROM TESTTABLE3; 未选定行 SQL&gt; exit 从 Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开 C:\\Users\\Administrator&gt;sqlplus tokerr/tokerr@orcl SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:27:17 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. ERROR: ORA-12541: TNS: 无监听程序 请输入用户名: C:\\Users\\Administrator&gt; C:\\Users\\Administrator&gt;sqlplus / as sysdba SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:37:26 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; startup ORA-01081: 无法启动已在运行的 ORACLE - 请首先关闭它 SQL&gt; 从 Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开 C:\\Users\\Administrator&gt;lsnrctl status LSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:39:09 Copyright (c) 1991, 2010, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误 TNS-00511: 无监听程序 64-bit Windows Error: 2: No such file or directory 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))) TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误 TNS-00511: 无监听程序 64-bit Windows Error: 61: Unknown error C:\\Users\\Administrator&gt;lsnrctl start LSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:39:40 Copyright (c) 1991, 2010, Oracle. All rights reserved. 启动tnslsnr: 请稍候... TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production 系统参数文件为F:\\Ora10InstantClient\\listener.ora 写入f:\\oracledb\\diag\\tnslsnr\\PC-20160512QTJL\\listener\\alert\\log.xml的日志信息 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\\\.\\pipe\\EXTPROC1521ipc))) 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production 启动日期 06-5月 -2017 09:39:46 正常运行时间 0 天 0 小时 0 分 8 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 F:\\Ora10InstantClient\\listener.ora 监听程序日志文件 f:\\oracledb\\diag\\tnslsnr\\PC-20160512QTJL\\listener\\alert\\log.xml 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\\\.\\pipe\\EXTPROC1521ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;CLRExtProc&quot; 包含 1 个实例。 实例 &quot;CLRExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 服务 &quot;orcl&quot; 包含 1 个实例。 实例 &quot;orcl&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 C:\\Users\\Administrator&gt;lsnrctl status LSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:41:30 Copyright (c) 1991, 2010, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production 启动日期 06-5月 -2017 09:39:46 正常运行时间 0 天 0 小时 1 分 48 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 F:\\Ora10InstantClient\\listener.ora 监听程序日志文件 f:\\oracledb\\diag\\tnslsnr\\PC-20160512QTJL\\listener\\alert\\log.xml 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\\\.\\pipe\\EXTPROC1521ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;CLRExtProc&quot; 包含 1 个实例。 实例 &quot;CLRExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 服务 &quot;orcl&quot; 包含 1 个实例。 实例 &quot;orcl&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 C:\\Users\\Administrator&gt;sqlplus tokerr/tokerr@orcl SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:41:36 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; select * from TESTTABLES; select * from TESTTABLES * 第 1 行出现错误: ORA-00942: 表或视图不存在 SQL&gt; select * from TESTTABLE1; 未选定行 SQL&gt; 三、正文在用PL/SQL Developer连接数据库时出现“ORA-12541:TNS:无监听程序”错误。 1、检查listener.log日志发现下面错误： TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:25:26 Copyright (c) 1991, 2005, Oracle. All rights reserved. 系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora 写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息 写入D:/oracle/product/10.2.0/db_1/network/trace/listener.trc的跟踪信息 跟踪级别当前为0 以 pid=1704 开始 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 监听该对象时出错: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521))) TNS-12545: 因目标主机或对象不存在, 连接失败 TNS-12560: TNS: 协议适配器错误 TNS-00515: 因目标主机或对象不存在, 连接失败 32-bit Windows Error: 49: Unknown error 不再监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 2、查看Oracle的listener是否启动C:/Documents and Settings/mengzhaoliang&gt;lsnrctl status LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:5 0:44 Copyright (c) 1991, 2005, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误 TNS-00511: 无监听程序 32-bit Windows Error: 2: No such file or directory 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521))) TNS-12535: TNS: 操作超时 TNS-12560: TNS: 协议适配器错误 TNS-00505: 操作超时 32-bit Windows Error: 60: Unknown error 原来没有启动listener，用“lsnrctl start”命令也不能启动。 C:/Documents and Settings/mengzhaoliang&gt;lsnrctl start LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:5 2:16 Copyright (c) 1991, 2005, Oracle. All rights reserved. 启动tnslsnr: 请稍候... TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production 系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora 写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 监听该对象时出错: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521)) ) TNS-12545: 因目标主机或对象不存在, 连接失败 TNS-12560: TNS: 协议适配器错误 TNS-00515: 因目标主机或对象不存在, 连接失败 32-bit Windows Error: 49: Unknown error 监听程序未能启动。请参阅上面的错误消息… 3、查看listener.ora的内容：# listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PLSExtProc) (ORACLE_HOME = D:/oracle/product/10.2.0/db_1) (PROGRAM = extproc) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1)) (ADDRESS = (PROTOCOL = TCP)(HOST = 0.5.0.5)(PORT = 1521)) ) ) 原来本机的ip发生改变后，就出现了上述问题，改变数据库的监听ip地址:把(ADDRESS = (PROTOCOL = TCP)(HOST = 0.5.0.5)(PORT = 1521))改成(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))127.0.0.1：也就是目前数据库正在用的ip地址。 4、再次启动oracle的listenerC:/Documents and Settings/mengzhaoliang&gt;lsnrctl start LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:5 4:40 Copyright (c) 1991, 2005, Oracle. All rights reserved. 启动tnslsnr: 请稍候... TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production 系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora 写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Produ ction 启动日期 20-9月 -2008 10:54:41 正常运行时间 0 天 0 小时 0 分 1 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 D:/oracle/product/10.2.0/db_1/network/admin/listener.o ra 监听程序日志文件 D:/oracle/product/10.2.0/db_1/network/log/listener.log 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;PLSExtProc&quot; 包含 1 个例程。 例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 启动已经成功， 5.再tnsnames.ora上添加上ORCL_127.0.0.1 = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) ) ) 6、再次用PL/SQL Developer再次连接数据库出现下面错误：TNS-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务再次检查listener.log日志 20-9月 -2008 11:01:54 * (CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=orcl)(CID= (PROGRAM=D:/plsql/plsqldev.exe)(HOST=RUIFEI-EF0ADC98)(USER=mengzhaoliang))) * (ADDRESS= (PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1267)) * establish * orcl * 12514 TNS-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务 查看listener： C:/Documents and Settings/mengzhaoliang&gt;lsnrctl services LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:1 1:09 Copyright (c) 1991, 2005, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) 服务摘要.. 服务 &quot;PLSExtProc&quot; 包含 1 个例程。 例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 处理程序: &quot;DEDICATED&quot; 已建立:0 已被拒绝:0 LOCAL SERVER 命令执行成功 7、用sqlplus也出现同样错误：C:/Documents and Settings/mengzhaoliang&gt;sqlplusscott/mzl@ORCL_127.0.0.1 SQL*Plus: Release 10.2.0.1.0 - Production on 星期六 9月 20 11:15:09 2008 Copyright (c) 1982, 2005, Oracle. All rights reserved. ERROR: ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务 8、查看listenser状态：C:/Documents and Settings/mengzhaoliang&gt;lsnrctl status LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:2 6:42 Copyright (c) 1991, 2005, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Produ ction 启动日期 20-9月 -2008 11:24:33 正常运行时间 0 天 0 小时 2 分 8 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 D:/oracle/product/10.2.0/db_1/network/admin/listener.o ra 监听程序日志文件 D:/oracle/product/10.2.0/db_1/network/log/listener.log 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;PLSExtProc&quot; 包含 1 个例程。 例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 C:/Documents and Settings/mengzhaoliang&gt;tnsping orcl TNS Ping Utility for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 - 2008 11:27:43 Copyright (c) 1997, 2005, Oracle. All rights reserved. 已使用的参数文件: D:/oracle/product/10.2.0/db_1/network/admin/sqlnet.ora TNS-03505: 无法解析名称 9、查看sqlnet.ora内容：# sqlnet.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/sqlnet.ora # Generated by Oracle configuration tools. # This file is actually generated by netca. But if customers choose to # install &quot;Software Only&quot;, this file wont exist and without the native # authentication, they will not be able to connect to the database on NT. SQLNET.AUTHENTICATION_SERVICES= (NTS) NAMES.DIRECTORY_PATH= (TNSNAMES, EZCONNECT) 10.把listener.ora的内容： # listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PLSExtProc) (ORACLE_HOME = D:/oracle/product/10.2.0/db_1) (PROGRAM = extproc) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1)) (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) ) ) 改成下面的内容： # listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = orcl) (ORACLE_HOME = D:/oracle/product/10.2.0/db_1) # (PROGRAM = extproc) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = orcl)) (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) ) ) 11、然后关闭、再启动listener在cmd中执行“lsnrctl stop” 和“lsnrctl stop”命令，再次登陆正常！ C:/Documents and Settings/mengzhaoliang&gt;sqlplus scott/mzl@orcl SQL*Plus: Release 10.2.0.1.0 - Production on 星期六 9月 20 11:55:47 2008 Copyright (c) 1982, 2005, Oracle. All rights reserved. 连接到: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - Production With the Partitioning, OLAP and Data Mining options SQL&gt; 再次用PL/SQL Peveloper登陆就没有问题了。 完毕! 我通过以上步骤我的问题还没解决，然后重启了一下OracleOraDb10g_home1TNSListener服务就行了 原文链接","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://tokerr.github.io/tags/数据库/"},{"name":"Oracle","slug":"Oracle","permalink":"https://tokerr.github.io/tags/Oracle/"}]},{"title":"序列化和反序列化的简单理解","slug":"序列化和反序列化的简单理解","date":"2017-05-05T14:26:32.000Z","updated":"2019-05-01T13:51:07.480Z","comments":true,"path":"2017/05/05/序列化和反序列化的简单理解/","link":"","permalink":"https://tokerr.github.io/2017/05/05/序列化和反序列化的简单理解/","excerpt":"一、序列化和反序列化的概念 把对象转换为字节序列的过程称为对象的序列化。 把字节序列恢复为对象的过程称为对象的反序列化。 对象的序列化主要有两种用途： 1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 2） 在网络上传送对象的字节序列。","text":"一、序列化和反序列化的概念 把对象转换为字节序列的过程称为对象的序列化。 把字节序列恢复为对象的过程称为对象的反序列化。 对象的序列化主要有两种用途： 1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 2） 在网络上传送对象的字节序列。 在很多应用中，需要对某些对象进行序列化，让它们离开内存空间，入住物理硬盘，以便长期保存。比如最常见的是Web服务器中的Session对象，当有 10万用户并发访问，就有可能出现10万个Session对象，内存可能吃不消，于是Web容器就会把一些seesion先序列化到硬盘中，等要用了，再把保存在硬盘中的对象还原到内存中。 当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。 二、JDK类库中的序列化API java.io.ObjectOutputStream代表对象输出流，它的writeObject(Object obj)方法可对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中。 java.io.ObjectInputStream代表对象输入流，它的readObject()方法从一个源输入流中读取字节序列，再把它们反序列化为一个对象，并将其返回。 只有实现了Serializable和Externalizable接口的类的对象才能被序列化。Externalizable接口继承自 Serializable接口，实现Externalizable接口的类完全由自身来控制序列化的行为，而仅实现Serializable接口的类可以 采用默认的序列化方式 。 对象序列化包括如下步骤： 1） 创建一个对象输出流，它可以包装一个其他类型的目标输出流，如文件输出流； 2） 通过对象输出流的writeObject()方法写对象。 对象反序列化的步骤如下： 1） 创建一个对象输入流，它可以包装一个其他类型的源输入流，如文件输入流； 2） 通过对象输入流的readObject()方法读取对象。 对象序列化和反序列范例： 定义一个Person类，实现Serializable接口 1 import java.io.Serializable; 2 3 /** 4 * &lt;p&gt;ClassName: Person&lt;p&gt; 5 * &lt;p&gt;Description:测试对象序列化和反序列化&lt;p&gt; 6 * @author xudp 7 * @version 1.0 V 8 * @createTime 2014-6-9 下午02:33:25 9 */ 10 public class Person implements Serializable { 11 12 /** 13 * 序列化ID 14 */ 15 private static final long serialVersionUID = -5809782578272943999L; 16 private int age; 17 private String name; 18 private String sex; 19 20 public int getAge() { 21 return age; 22 } 23 24 public String getName() { 25 return name; 26 } 27 28 public String getSex() { 29 return sex; 30 } 31 32 public void setAge(int age) { 33 this.age = age; 34 } 35 36 public void setName(String name) { 37 this.name = name; 38 } 39 40 public void setSex(String sex) { 41 this.sex = sex; 42 } 43 } 序列化和反序列化Person类对象 1 import java.io.File; 2 import java.io.FileInputStream; 3 import java.io.FileNotFoundException; 4 import java.io.FileOutputStream; 5 import java.io.IOException; 6 import java.io.ObjectInputStream; 7 import java.io.ObjectOutputStream; 8 import java.text.MessageFormat; 9 10 /** 11 * &lt;p&gt;ClassName: TestObjSerializeAndDeserialize&lt;p&gt; 12 * &lt;p&gt;Description: 测试对象的序列化和反序列&lt;p&gt; 13 * @author xudp 14 * @version 1.0 V 15 * @createTime 2014-6-9 下午03:17:25 16 */ 17 public class TestObjSerializeAndDeserialize { 18 19 public static void main(String[] args) throws Exception { 20 SerializePerson();//序列化Person对象 21 Person p = DeserializePerson();//反序列Perons对象 22 System.out.println(MessageFormat.format(&quot;name={0},age={1},sex={2}&quot;, 23 p.getName(), p.getAge(), p.getSex())); 24 } 25 26 /** 27 * MethodName: SerializePerson 28 * Description: 序列化Person对象 29 * @author xudp 30 * @throws FileNotFoundException 31 * @throws IOException 32 */ 33 private static void SerializePerson() throws FileNotFoundException, 34 IOException { 35 Person person = new Person(); 36 person.setName(&quot;gacl&quot;); 37 person.setAge(25); 38 person.setSex(&quot;男&quot;); 39 // ObjectOutputStream 对象输出流，将Person对象存储到E盘的Person.txt文件中，完成对Person对象的序列化操作 40 ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream( 41 new File(&quot;E:/Person.txt&quot;))); 42 oo.writeObject(person); 43 System.out.println(&quot;Person对象序列化成功！&quot;); 44 oo.close(); 45 } 46 47 /** 48 * MethodName: DeserializePerson 49 * Description: 反序列Perons对象 50 * @author xudp 51 * @return 52 * @throws Exception 53 * @throws IOException 54 */ 55 private static Person DeserializePerson() throws Exception, IOException { 56 ObjectInputStream ois = new ObjectInputStream(new FileInputStream( 57 new File(&quot;E:/Person.txt&quot;))); 58 Person person = (Person) ois.readObject(); 59 System.out.println(&quot;Person对象反序列化成功！&quot;); 60 return person; 61 } 62 63 } 代码运行结果如下：序列化Person成功后在E盘生成了一个Person.txt文件，而反序列化Person是读取E盘的Person.txt后生成了一个Person对象 三、serialVersionUID的作用 s​e​r​i​a​l​V​e​r​s​i​o​n​U​I​D​:​ ​字​面​意​思​上​是​序​列​化​的​版​本​号​，凡是实现Serializable接口的类都有一个表示序列化版本标识符的静态变量 private static final long serialVersionUID serialVersionUID有两种生成方式： 采用这种方式生成的serialVersionUID是1L，例如： 1 private static final long serialVersionUID = 1L; 采用这种方式生成的serialVersionUID是根据类名，接口名，方法和属性等来生成的，例如： 1 private static final long serialVersionUID = 4603642343377807741L; 扯了那么多，那么serialVersionUID(序列化版本号)到底有什么用呢，我们用如下的例子来说明一下serialVersionUID的作用，看下面的代码： 1 import java.io.File; 2 import java.io.FileInputStream; 3 import java.io.FileNotFoundException; 4 import java.io.FileOutputStream; 5 import java.io.IOException; 6 import java.io.ObjectInputStream; 7 import java.io.ObjectOutputStream; 8 import java.io.Serializable; 9 10 public class TestSerialversionUID { 11 12 public static void main(String[] args) throws Exception { 13 SerializeCustomer();// 序列化Customer对象 14 Customer customer = DeserializeCustomer();// 反序列Customer对象 15 System.out.println(customer); 16 } 17 18 /** 19 * MethodName: SerializeCustomer 20 * Description: 序列化Customer对象 21 * @author xudp 22 * @throws FileNotFoundException 23 * @throws IOException 24 */ 25 private static void SerializeCustomer() throws FileNotFoundException, 26 IOException { 27 Customer customer = new Customer(&quot;gacl&quot;,25); 28 // ObjectOutputStream 对象输出流 29 ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream( 30 new File(&quot;E:/Customer.txt&quot;))); 31 oo.writeObject(customer); 32 System.out.println(&quot;Customer对象序列化成功！&quot;); 33 oo.close(); 34 } 35 36 /** 37 * MethodName: DeserializeCustomer 38 * Description: 反序列Customer对象 39 * @author xudp 40 * @return 41 * @throws Exception 42 * @throws IOException 43 */ 44 private static Customer DeserializeCustomer() throws Exception, IOException { 45 ObjectInputStream ois = new ObjectInputStream(new FileInputStream( 46 new File(&quot;E:/Customer.txt&quot;))); 47 Customer customer = (Customer) ois.readObject(); 48 System.out.println(&quot;Customer对象反序列化成功！&quot;); 49 return customer; 50 } 51 } 52 53 /** 54 * &lt;p&gt;ClassName: Customer&lt;p&gt; 55 * &lt;p&gt;Description: Customer实现了Serializable接口，可以被序列化&lt;p&gt; 56 * @author xudp 57 * @version 1.0 V 58 * @createTime 2014-6-9 下午04:20:17 59 */ 60 class Customer implements Serializable { 61 //Customer类中没有定义serialVersionUID 62 private String name; 63 private int age; 64 65 public Customer(String name, int age) { 66 this.name = name; 67 this.age = age; 68 } 69 70 /* 71 * @MethodName toString 72 * @Description 重写Object类的toString()方法 73 * @author xudp 74 * @return string 75 * @see java.lang.Object#toString() 76 */ 77 @Override 78 public String toString() { 79 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 80 } 81 } 运行结果： 序列化和反序列化都成功了。 下面我们修改一下Customer类，添加多一个sex属性，如下： 1 class Customer implements Serializable { 2 //Customer类中没有定义serialVersionUID 3 private String name; 4 private int age; 5 6 //新添加的sex属性 7 private String sex; 8 9 public Customer(String name, int age) { 10 this.name = name; 11 this.age = age; 12 } 13 14 public Customer(String name, int age,String sex) { 15 this.name = name; 16 this.age = age; 17 this.sex = sex; 18 } 19 20 /* 21 * @MethodName toString 22 * @Description 重写Object类的toString()方法 23 * @author xudp 24 * @return string 25 * @see java.lang.Object#toString() 26 */ 27 @Override 28 public String toString() { 29 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 30 } 31 } 然后执行反序列操作，此时就会抛出如下的异常信息： 1 Exception in thread &quot;main&quot; java.io.InvalidClassException: Customer; 2 local class incompatible: 3 stream classdesc serialVersionUID = -88175599799432325, 4 local class serialVersionUID = -5182532647273106745 意思就是说，文件流中的class和classpath中的class，也就是修改过后的class，不兼容了，处于安全机制考虑，程序抛出了错误，并且拒绝载入。那么如果我们真的有需求要在序列化后添加一个字段或者方法呢？应该怎么办？那就是自己去指定serialVersionUID。在TestSerialversionUID例子中，没有指定Customer类的serialVersionUID的，那么java编译器会自动给这个class进行一个摘要算法，类似于指纹算法，只要这个文件 多一个空格，得到的UID就会截然不同的，可以保证在这么多类中，这个编号是唯一的。所以，添加了一个字段后，由于没有显指定 serialVersionUID，编译器又为我们生成了一个UID，当然和前面保存在文件中的那个不会一样了，于是就出现了2个序列化版本号不一致的错误。因此，只要我们自己指定了serialVersionUID，就可以在序列化后，去添加一个字段，或者方法，而不会影响到后期的还原，还原后的对象照样可以使用，而且还多了方法或者属性可以用。 下面继续修改Customer类，给Customer指定一个serialVersionUID，修改后的代码如下： 1 class Customer implements Serializable { 2 /** 3 * Customer类中定义的serialVersionUID(序列化版本号) 4 */ 5 private static final long serialVersionUID = -5182532647273106745L; 6 private String name; 7 private int age; 8 9 //新添加的sex属性 10 //private String sex; 11 12 public Customer(String name, int age) { 13 this.name = name; 14 this.age = age; 15 } 16 17 /*public Customer(String name, int age,String sex) { 18 this.name = name; 19 this.age = age; 20 this.sex = sex; 21 }*/ 22 23 /* 24 * @MethodName toString 25 * @Description 重写Object类的toString()方法 26 * @author xudp 27 * @return string 28 * @see java.lang.Object#toString() 29 */ 30 @Override 31 public String toString() { 32 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 33 } 34 } 重新执行序列化操作，将Customer对象序列化到本地硬盘的Customer.txt文件存储，然后修改Customer类，添加sex属性，修改后的Customer类代码如下： 1 class Customer implements Serializable { 2 /** 3 * Customer类中定义的serialVersionUID(序列化版本号) 4 */ 5 private static final long serialVersionUID = -5182532647273106745L; 6 private String name; 7 private int age; 8 9 //新添加的sex属性 10 private String sex; 11 12 public Customer(String name, int age) { 13 this.name = name; 14 this.age = age; 15 } 16 17 public Customer(String name, int age,String sex) { 18 this.name = name; 19 this.age = age; 20 this.sex = sex; 21 } 22 23 /* 24 * @MethodName toString 25 * @Description 重写Object类的toString()方法 26 * @author xudp 27 * @return string 28 * @see java.lang.Object#toString() 29 */ 30 @Override 31 public String toString() { 32 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 33 } 34 } 执行反序列操作，这次就可以反序列成功了，如下所示： 四、serialVersionUID的取值 serialVersionUID的取值是Java运行时环境根据类的内部细节自动生成的。如果对类的源代码作了修改，再重新编译，新生成的类文件的serialVersionUID的取值有可能也会发生变化。 类的serialVersionUID的默认值完全依赖于Java编译器的实现，对于同一个类，用不同的Java编译器编译，有可能会导致不同的 serialVersionUID，也有可能相同。为了提高serialVersionUID的独立性和确定性，强烈建议在一个可序列化类中显示的定义serialVersionUID，为它赋予明确的值。 显式地定义serialVersionUID有两种用途： 1、 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 2、 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。 原文连接","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"}]},{"title":"validation实现后台校验;","slug":"hibernate-validation实现后台校验","date":"2017-05-02T15:05:20.000Z","updated":"2019-05-01T13:51:07.477Z","comments":true,"path":"2017/05/02/hibernate-validation实现后台校验/","link":"","permalink":"https://tokerr.github.io/2017/05/02/hibernate-validation实现后台校验/","excerpt":"1 validation校验对前端的校验大多数通过js在页面校验，这种方法比较简单，如果对安全性考虑，还要在后台校验。 springmvc使用JSR-303（javaEE6规范的一部分）校验规范，springmvc使用的是Hibernate Validator（和Hibernate的ORM） 1.1 加入Hibernate Validator的jar","text":"1 validation校验对前端的校验大多数通过js在页面校验，这种方法比较简单，如果对安全性考虑，还要在后台校验。 springmvc使用JSR-303（javaEE6规范的一部分）校验规范，springmvc使用的是Hibernate Validator（和Hibernate的ORM） 1.1 加入Hibernate Validator的jar 1.2 在处理器适配器中配置校验器 1.3 创建CustomValidationMessages在classpath下创建CustomValidationMessages.properties 1.4 校验规则需求：商品信息提交时校验 ，商品生产日期不能为空，商品名称长度在1到30字符之间 1.5 捕获错误需要修改controller方法，在要校验的pojo前边加上@Validated， 错误信息输出： 1.6 在页面上展示错误 1.7 分组校验需求：针对不同的controller方法通过分组校验达到个性化校验的目的，修改商品修改功能，只校验生产日期不能为空。 第一步：创建分组接口 第二步：定义校验规则属于哪个分组 第三步：在controller方法定义使用校验的分组 1.8 hibernate-validator的配置以及使用此处只列出Hibernate Validator提供的大部分验证约束注解，请参考hibernate validator官方文档了解其他验证约束注解和进行自定义的验证约束注解定义。 springmvc参数自动转换:1.String to Date2.String to Integer or int3.String to Byte or int4.String to Long or loong Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.lang.Byte&apos; for property &apos;duration&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;128&quot; from type &apos;java.lang.String&apos; to type &apos;java.lang.Byte&apos;; nested exception is java.lang.NumberFormatException: Value out of range. Value:&quot;128&quot; Radix:10 Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.util.Date&apos; for property &apos;starttime&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;2017-01-23 16:25:45&quot; from type &apos;java.lang.String&apos; to type &apos;java.util.Date&apos;; nested exception is java.lang.IllegalStateException: JodaTime library not available - @DateTimeFormat not supported http://127.0.0.1:8888/mokao-back/empfollowups/addEmpfollowups?empId=12988&amp;starttime=2015-06-04%2009:06:29&amp;duration=128&amp;salesid=325 Validator校验器使用正常[ { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;duration&quot;, &quot;codes&quot;: [ &quot;empfollowups.duration&quot;, &quot;duration&quot; ], &quot;defaultMessage&quot;: &quot;duration&quot; } ], &quot;bindingFailure&quot;: true, &quot;code&quot;: &quot;typeMismatch&quot;, &quot;codes&quot;: [ &quot;typeMismatch.empfollowups.duration&quot;, &quot;typeMismatch.duration&quot;, &quot;typeMismatch.java.lang.Byte&quot;, &quot;typeMismatch&quot; ], &quot;defaultMessage&quot;: &quot;Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.lang.Byte&apos; for property &apos;duration&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;128&quot; from type &apos;java.lang.String&apos; to type &apos;java.lang.Byte&apos;; nested exception is java.lang.NumberFormatException: Value out of range. Value:&quot;128&quot; Radix:10&quot;, &quot;field&quot;: &quot;duration&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: &quot;128&quot; }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;starttime&quot;, &quot;codes&quot;: [ &quot;empfollowups.starttime&quot;, &quot;starttime&quot; ], &quot;defaultMessage&quot;: &quot;starttime&quot; } ], &quot;bindingFailure&quot;: true, &quot;code&quot;: &quot;typeMismatch&quot;, &quot;codes&quot;: [ &quot;typeMismatch.empfollowups.starttime&quot;, &quot;typeMismatch.starttime&quot;, &quot;typeMismatch.java.util.Date&quot;, &quot;typeMismatch&quot; ], &quot;defaultMessage&quot;: &quot;Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.util.Date&apos; for property &apos;starttime&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;2015-06-04 09:06:29&quot; from type &apos;java.lang.String&apos; to type &apos;java.util.Date&apos;; nested exception is java.lang.IllegalStateException: JodaTime library not available - @DateTimeFormat not supported&quot;, &quot;field&quot;: &quot;starttime&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: &quot;2015-06-04 09:06:29&quot; }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;goal&quot;, &quot;codes&quot;: [ &quot;empfollowups.goal&quot;, &quot;goal&quot; ], &quot;defaultMessage&quot;: &quot;goal&quot; } ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;NotNull&quot;, &quot;codes&quot;: [ &quot;NotNull.empfollowups.goal&quot;, &quot;NotNull.goal&quot;, &quot;NotNull.java.lang.String&quot;, &quot;NotNull&quot; ], &quot;defaultMessage&quot;: &quot;回访目的不能为空!&quot;, &quot;field&quot;: &quot;goal&quot;, &quot;objectName&quot;: &quot;empfollowups&quot; }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;salesid&quot;, &quot;codes&quot;: [ &quot;empfollowups.salesid&quot;, &quot;salesid&quot; ], &quot;defaultMessage&quot;: &quot;salesid&quot; }, 127, 0 ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;Range&quot;, &quot;codes&quot;: [ &quot;Range.empfollowups.salesid&quot;, &quot;Range.salesid&quot;, &quot;Range.java.lang.Integer&quot;, &quot;Range&quot; ], &quot;defaultMessage&quot;: &quot;回访时间范围请保持在0-127分钟之内!&quot;, &quot;field&quot;: &quot;salesid&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: 325 } ] OK【对于以上 String to Byte 类型错误的原因是：传过去的参数超出-127~127的范围，因此出现数字格式化异常，若是绑定的参数在正常范围内即-127~127之内则能正常绑定】NO【已经解决，@DateTimeFormat not support 对于日期格式的字符串配置的springmvc的转换去没有转换成功 异常原因：缺少jar包 导入如下jar包即可使用注解的方式将pojo中string类型字符串转换成日期对象:joda-time库】 二、以下是springmvc中validator的配置： 2.1先引入相关jar包:已附录在首行，3个相关jar包，若是需要使用注解对pojo中的Date类型进行转换，需要将joda-time也一并引入 2.2 配置： 控制器 2.3相关文件：源码文件，这里就不帖出来了 2.4 pojo属性类型转换除了@DateTimeFormat 注解用于转换日期之外，还有可用于数字类型的属性转换的注解:@NumberFormat@DateTimeFormat(pattern=”yyyy-MM-dd”) 可将形如1980-0-01的字符串转换到Date类@NumberFormat(pattern=”#,###.##”) 可将形如4,500.00的字符串转换成long类型 2.5 List allErrors = bindingResult.getAllErrors(); allErrors 实例展示(这里转换成了json字符串) http://127.0.0.1:8888/mokao-back/empfollowups/addEmpfollowups?empId=12988&amp;starttime=2015-06-04%2009:06:29&amp;duration=118&amp;salesid=325 [ { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;salesid&quot;, &quot;codes&quot;: [ &quot;empfollowups.salesid&quot;, &quot;salesid&quot; ], &quot;defaultMessage&quot;: &quot;salesid&quot; }, 127, 0 ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;Range&quot;, &quot;codes&quot;: [ &quot;Range.empfollowups.salesid&quot;, &quot;Range.salesid&quot;, &quot;Range.java.lang.Integer&quot;, &quot;Range&quot; ], &quot;defaultMessage&quot;: &quot;销售的id值请保持在0~127范围之内!&quot;, &quot;field&quot;: &quot;salesid&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: 325 }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;goal&quot;, &quot;codes&quot;: [ &quot;empfollowups.goal&quot;, &quot;goal&quot; ], &quot;defaultMessage&quot;: &quot;goal&quot; } ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;NotNull&quot;, &quot;codes&quot;: [ &quot;NotNull.empfollowups.goal&quot;, &quot;NotNull.goal&quot;, &quot;NotNull.java.lang.String&quot;, &quot;NotNull&quot; ], &quot;defaultMessage&quot;: &quot;回访目的不能为空!&quot;, &quot;field&quot;: &quot;goal&quot;, &quot;objectName&quot;: &quot;empfollowups&quot; } ] org.codehaus.jackson.map.JsonMappingException: No serializer found for class org.springframework.validation.DefaultMessageCodesResolver and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationConfig.Feature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: org.springframework.validation.BeanPropertyBindingResult[&quot;messageCodesResolver&quot;]) at org.codehaus.jackson.map.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:52) at org.codehaus.jackson.map.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:25) at org.codehaus.jackson.map.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:446) at org.codehaus.jackson.map.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:150) at org.codehaus.jackson.map.ser.BeanSerializer.serialize(BeanSerializer.java:112) at org.codehaus.jackson.map.ser.StdSerializerProvider._serializeValue(StdSerializerProvider.java:610) at org.codehaus.jackson.map.ser.StdSerializerProvider.serializeValue(StdSerializerProvider.java:256) at org.codehaus.jackson.map.ObjectMapper._configAndWriteValue(ObjectMapper.java:2575) at org.codehaus.jackson.map.ObjectMapper.writeValueAsString(ObjectMapper.java:2097) at com.skf.mokao.controller.empfollowups.EmpfollowupsController.addEmpfollowups(EmpfollowupsController.java:125) at com.skf.mokao.controller.empfollowups.EmpfollowupsController$$FastClassByCGLIB$$2006e11c.invoke(&lt;generated&gt;) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191) at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:688) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:42) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:80) at com.skf.mokao.aspect.Aspect5_LoginCheck.around(Aspect5_LoginCheck.java:146) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:65) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:89) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:621) at com.skf.mokao.controller.empfollowups.EmpfollowupsController$$EnhancerByCGLIB$$8b5e69da.addEmpfollowups(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.web.bind.annotation.support.HandlerMethodInvoker.invokeHandlerMethod(HandlerMethodInvoker.java:176) at org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter.invokeHandlerMethod(AnnotationMethodHandlerAdapter.java:426) at org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter.handle(AnnotationMethodHandlerAdapter.java:414) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:790) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:719) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:644) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:549) at javax.servlet.http.HttpServlet.service(HttpServlet.java:624) at javax.servlet.http.HttpServlet.service(HttpServlet.java:731) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at com.skf.mokao.filter.UserLoginFilter.doFilter(UserLoginFilter.java:63) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:380) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:237) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:167) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at com.skf.mokao.filter.RequestParametersFilter.doFilter(RequestParametersFilter.java:138) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:505) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:956) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:442) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1083) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:640) at org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.doRun(AprEndpoint.java:2517) at org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.run(AprEndpoint.java:2506) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745)","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"validation","slug":"validation","permalink":"https://tokerr.github.io/tags/validation/"},{"name":"spring","slug":"spring","permalink":"https://tokerr.github.io/tags/spring/"},{"name":"springmvc","slug":"springmvc","permalink":"https://tokerr.github.io/tags/springmvc/"},{"name":"hibernate-validation","slug":"hibernate-validation","permalink":"https://tokerr.github.io/tags/hibernate-validation/"}]},{"title":"在不同环境下使用Gson出现的Date格式化问题","slug":"在不同环境下使用Gson出现的Date格式化问题","date":"2017-04-27T15:03:17.000Z","updated":"2019-05-01T13:51:07.479Z","comments":true,"path":"2017/04/27/在不同环境下使用Gson出现的Date格式化问题/","link":"","permalink":"https://tokerr.github.io/2017/04/27/在不同环境下使用Gson出现的Date格式化问题/","excerpt":"在Java中处理JSON格式的数据时，Google Gson是个不错的选择，用起来挺方便的，也有一定灵活性。我现在工作中在参与的两个项目里都有用它。不过它在处理Date格式时有个小陷阱，在不同环境中部署时可能会遇到问题。 Gson默认处理Date对象的序列化/反序列化是通过一个SimpleDateFormat对象来实现的，通过下面的代码去获取实例：DateFormat.getDateTimeInstance() 在不同的locale环境中，这样获取到的SimpleDateFormat的模式字符串会不一样。例如说，在我的开发机是Windows XP SP3，zh_CN.GBK，模式字符串是：“yyyy-M-d H:mm:ss”","text":"在Java中处理JSON格式的数据时，Google Gson是个不错的选择，用起来挺方便的，也有一定灵活性。我现在工作中在参与的两个项目里都有用它。不过它在处理Date格式时有个小陷阱，在不同环境中部署时可能会遇到问题。 Gson默认处理Date对象的序列化/反序列化是通过一个SimpleDateFormat对象来实现的，通过下面的代码去获取实例：DateFormat.getDateTimeInstance() 在不同的locale环境中，这样获取到的SimpleDateFormat的模式字符串会不一样。例如说，在我的开发机是Windows XP SP3，zh_CN.GBK，模式字符串是：“yyyy-M-d H:mm:ss”而在我们的一台测试服务器上，RHEL 5.4，en_US.UTF-8，模式字符串则是：“MMM d, yyyy h:mm:ss a” 这就使得同样的Date对象通过Gson来序列化为JSON后内容不同。例如说要序列化的日期是2010-08-19 16:13:57，那么在我的开发机上得到的是：“2010-8-19 16:13:57” 而在那台测试服务器上则是：“Aug 19, 2010 4:13:57 PM” 这就……郁闷了。在一边序列化的内容在另一边会反序列化失败。 为了避免使用Gson时遇到locale影响Date格式的问题，使用GsonBuilder来创建Gson对象，在创建过程中调用GsonBuilder.setDateFormat(String)指定一个固定的格式即可。例如：Gson gson = new GsonBuilder() .setDateFormat(“yyyy-MM-dd HH:mm:ss”) .create(); 原文链接","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"google","slug":"google","permalink":"https://tokerr.github.io/tags/google/"},{"name":"json","slug":"json","permalink":"https://tokerr.github.io/tags/json/"},{"name":"gson","slug":"gson","permalink":"https://tokerr.github.io/tags/gson/"},{"name":"linux","slug":"linux","permalink":"https://tokerr.github.io/tags/linux/"},{"name":"windows","slug":"windows","permalink":"https://tokerr.github.io/tags/windows/"}]},{"title":"sql语句使用临时数据，模拟构建一张临时表(用于一次性查询的)","slug":"sql语句使用临时数据，模拟构建一张临时表-用于一次性查询的","date":"2017-04-26T13:31:02.000Z","updated":"2019-05-01T13:51:07.478Z","comments":true,"path":"2017/04/26/sql语句使用临时数据，模拟构建一张临时表-用于一次性查询的/","link":"","permalink":"https://tokerr.github.io/2017/04/26/sql语句使用临时数据，模拟构建一张临时表-用于一次性查询的/","excerpt":"一、问题描述：项目使用到了sendcloud的邮件服务，邮件的发送接口前期已经写好了，前几天突然需要看到取消接收我们公司发出去的邮件列表，由于又是后台的功能，所以交到了我们的手上，逻辑也简单，就是第一次去调用服务商的接口，至于如何调用，方法也不少，这里也不赘述，进入主题： 因为sendcloud服务商烦我返回的数据，除了一个邮箱的列表之外，没有必要的邮箱对应公司的名称(产品这边提的需求)，这点不难理解，详细的数据都在我们的数据库里面，因此在调用sendcloud的接口获取到邮箱列表之后还需要到我们的数据库中查询出对应的公司名称。 于是我就思考，每个邮箱单独去做一次查询，使用程序填装的方式，将企业名称一一对应封装，但是如果邮箱列表很多的情况下，就会影响数据库的性能，这是很不可取的，因此想着能不能通过sql的连接查询方式，把数据一次性的查询出来，只需要访问一次数据库即可：这样就需要将邮件列表在sql查询中组装成一张临时的表，然后再使用连接的方式查询企业的表从而获取到企业的详细信息，这样即使没有查到对应的企业，但是有限依然能正常显示。","text":"一、问题描述：项目使用到了sendcloud的邮件服务，邮件的发送接口前期已经写好了，前几天突然需要看到取消接收我们公司发出去的邮件列表，由于又是后台的功能，所以交到了我们的手上，逻辑也简单，就是第一次去调用服务商的接口，至于如何调用，方法也不少，这里也不赘述，进入主题： 因为sendcloud服务商烦我返回的数据，除了一个邮箱的列表之外，没有必要的邮箱对应公司的名称(产品这边提的需求)，这点不难理解，详细的数据都在我们的数据库里面，因此在调用sendcloud的接口获取到邮箱列表之后还需要到我们的数据库中查询出对应的公司名称。 于是我就思考，每个邮箱单独去做一次查询，使用程序填装的方式，将企业名称一一对应封装，但是如果邮箱列表很多的情况下，就会影响数据库的性能，这是很不可取的，因此想着能不能通过sql的连接查询方式，把数据一次性的查询出来，只需要访问一次数据库即可：这样就需要将邮件列表在sql查询中组装成一张临时的表，然后再使用连接的方式查询企业的表从而获取到企业的详细信息，这样即使没有查到对应的企业，但是有限依然能正常显示。 二、基本的操作直接上图，简洁明了，想我不愿意看那么长描述性问题的人，问题写了那么多，觉得有点废话。 select (&apos;111&apos;) AS num1,(5555) AS num2 UNION ALL select (&apos;111&apos;) AS num1,(null) AS num2 注意：上面使用到了union all的合并查询，剩下的自己去领悟 三、实际的应用：结合mybatis3.1sql语句的编写 sql语句：表结构就不贴出来了 SELECT temp.email, temp.num2, emp.id, emp. NAME FROM ( SELECT (&apos;2955*****@qq.com&apos;) AS email,(5555) AS num2 UNION ALL SELECT (&apos;hr@******.com&apos;) AS email,(5555) AS num2 UNION ALL SELECT (&apos;advertiser@****.com&apos;) AS email,(NULL) AS num2 UNION ALL SELECT (&apos;advertis@*****.com&apos;) AS email,(5555) AS num2 ) AS temp LEFT JOIN employers AS emp ON temp.email = emp.email WHERE emp.flag != &apos;D&apos; OR emp.flag IS NULL 3.2mapper.xml和dao接口3.2.1 dao接口： public List&lt;Employers&gt; queryUnsubscribeByPage_(@Param(&quot;emails&quot;) List&lt;SCEmailUnsubscribe.Data&gt; emails,@Param(&quot;condition&quot;)SCEmailUnsubscribe.Data condition,@Param(&quot;startNum&quot;)Integer startNum,@Param(&quot;pageSize&quot;)Integer pageSize); 3.2.2 mapper.xml &lt;sql id=&quot;Condition_And_Clause_&quot;&gt; &lt;if test=&quot;condition!=null&quot;&gt; &lt;if test=&quot;condition.empname!=null&quot;&gt; AND `Name` LIKE #{condition.empname,jdbcType=VARCHAR} &lt;/if&gt; &lt;if test=&quot;condition.email!=null&quot;&gt; AND `Email` LIKE #{condition.email,jdbcType=VARCHAR} &lt;/if&gt; &lt;/if&gt; &lt;/sql&gt; &lt;select id=&quot;queryUnsubscribeByPage_&quot; resultType=&quot;com.skf.mokao.pojo.Employers&quot;&gt; SELECT temp.email AS email, STR_TO_DATE(temp.unsubscribeTime,&apos;%Y-%m-%d %H:%i:%s&apos;) AS unsubscribeTime, emp.id AS id, emp.name AS name FROM ( &lt;if test=&quot;emails!=null&quot;&gt; &lt;foreach collection=&quot;emails&quot; open=&quot;SELECT &quot; close=&quot;&quot; item=&quot;item&quot; separator=&quot; UNION ALL SELECT &quot;&gt; (#{item.email}) AS email,(#{item.unsubscribeTime,jdbcType=TIMESTAMP}) AS unsubscribeTime &lt;/foreach&gt; &lt;/if&gt; ) AS temp LEFT JOIN employers AS emp ON temp.email = emp.email WHERE emp.flag != &apos;D&apos; OR emp.flag IS NULL &lt;include refid=&quot;Condition_And_Clause_&quot;/&gt; ORDER BY temp.unsubscribeTime DESC LIMIT #{startNum,jdbcType=INTEGER},#{pageSize,jdbcType=INTEGER} &lt;/select&gt; &lt;select id=&quot;queryUnsubscribeCount_&quot; resultType=&quot;java.lang.Integer&quot; &gt; SELECT COUNT(temp.email) FROM ( &lt;if test=&quot;emails!=null&quot;&gt; &lt;foreach collection=&quot;emails&quot; open=&quot;SELECT &quot; close=&quot;&quot; item=&quot;item&quot; separator=&quot; UNION ALL SELECT &quot;&gt; (#{item.email}) AS email,(#{item.unsubscribeTime,jdbcType=TIMESTAMP}) AS unsubscribeTime &lt;/foreach&gt; &lt;/if&gt; ) AS temp LEFT JOIN employers AS emp ON temp.email = emp.email WHERE emp.flag != &apos;D&apos; OR emp.flag IS NULL &lt;include refid=&quot;Condition_And_Clause_&quot;/&gt; &lt;/select&gt;","categories":[],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://tokerr.github.io/tags/mybatis/"},{"name":"mysql","slug":"mysql","permalink":"https://tokerr.github.io/tags/mysql/"},{"name":"临时表","slug":"临时表","permalink":"https://tokerr.github.io/tags/临时表/"}]},{"title":"java.util.Date转java.sql.Date丢失时间问题","slug":"java-util-Date转java-sql-Date丢失时间问题","date":"2017-04-25T14:15:59.000Z","updated":"2019-05-01T13:51:07.477Z","comments":true,"path":"2017/04/25/java-util-Date转java-sql-Date丢失时间问题/","link":"","permalink":"https://tokerr.github.io/2017/04/25/java-util-Date转java-sql-Date丢失时间问题/","excerpt":"一.引发我写这篇博客的原因（问题描述）：由于项目使用的是springmvc+mybatis，前期的开发使用到了ibator这个dao层代码生成工具(ps:后来因为老板的原因，禁用了这个工具，但是以前的老代码还有在使用这个工具生成的代码)，其中提供的Example极大的方便开发是进行数据的各种查询的工作，但是使用过程出现了一些问题。在对日期时间类型的字段进行筛选的时候不能精确到时分秒，原因是Example里面默认的是将util的Date 转成 sql的Date，以至丢失时间 查询不能精确到时分秒","text":"一.引发我写这篇博客的原因（问题描述）：由于项目使用的是springmvc+mybatis，前期的开发使用到了ibator这个dao层代码生成工具(ps:后来因为老板的原因，禁用了这个工具，但是以前的老代码还有在使用这个工具生成的代码)，其中提供的Example极大的方便开发是进行数据的各种查询的工作，但是使用过程出现了一些问题。在对日期时间类型的字段进行筛选的时候不能精确到时分秒，原因是Example里面默认的是将util的Date 转成 sql的Date，以至丢失时间 查询不能精确到时分秒 二、问题原因以及解决方法：java.sql.Date 只存储日期数据不存储时间数据 // 会丢失时间数据 preparedStatement.setDate(1, new java.sql.Date(date.getTime())); //可以这样来处理 preparedStatement.setTimestamp(1, new java.sql.Timestamp(new java.util.Date().getTime())); //想要得到完整的数据，包括日期和时间，可以这样 java.util.Date d = resultSet.getTimestamp(1); //这样处理更合适一些，可以避免一些潜在Timestamp 问题 java.util.Date d = new java.util.Date(resultSet.getTimestamp(1).getTime()); 这样的话：往数据库存储的时候可以接收 java.util.Date类型 再用getTime()方法得到代表那个Date对象的long值，再以这个long值 构造一个Timestamp对象 存进数据库中。从存数据库里取的时候，可以先得到Timestamp用他的getTime()方法得到long值，再以这个long值构造一个 java.util.Date对象，这样就可以对这个Date对象操作了。例如 new SimpleTimeFormat(&quot;yyyyy-MM-dd HH:mm:ss&quot;).format()等等","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"日期转换","slug":"日期转换","permalink":"https://tokerr.github.io/tags/日期转换/"}]},{"title":"提高mysql千万级大数据SQL查询优化30条经验（Mysql索引优化注意）","slug":"提高mysql千万级大数据SQL查询优化30条经验（Mysql索引优化注意）","date":"2017-04-25T13:54:40.000Z","updated":"2019-05-01T13:51:07.481Z","comments":true,"path":"2017/04/25/提高mysql千万级大数据SQL查询优化30条经验（Mysql索引优化注意）/","link":"","permalink":"https://tokerr.github.io/2017/04/25/提高mysql千万级大数据SQL查询优化30条经验（Mysql索引优化注意）/","excerpt":"转自：http://blog.163.com/zhangjie_0303/blog/static/9908270620146951355834/ 近期由于项目的需求，需要在项目的后台进行数据统计，由于涉及的表比较多，于是考虑到查询的速度的问题，以前也没怎么注意，这里记下一篇转载的博客。尽量多看官方文档！1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num=0 3.应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则引擎将放弃使用索引而进行全表扫描。","text":"转自：http://blog.163.com/zhangjie_0303/blog/static/9908270620146951355834/ 近期由于项目的需求，需要在项目的后台进行数据统计，由于涉及的表比较多，于是考虑到查询的速度的问题，以前也没怎么注意，这里记下一篇转载的博客。尽量多看官方文档！1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num=0 3.应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则引擎将放弃使用索引而进行全表扫描。 4.应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num=10 or num=20可以这样查询：select id from t where num=10 union all select id from t where num=20 5.in 和 not in 也要慎用，否则会导致全表扫描，如：select id from t where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了：select id from t where num between 1 and 3 6.下面的查询也将导致全表扫描：select id from t where name like ‘李%’若要提高效率，可以考虑全文检索。 如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：select id from t where num=@num可以改为强制查询使用索引：select id from t with(index(索引名)) where num=@num 8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num/2=100应改为:select id from t where num=100*2 9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where substring(name,1,3)=’abc’ ，name以abc开头的id 应改为: select id from t where name like ‘abc%’ 10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 11.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 12.不要写一些没有意义的查询，如需要生成一个空表结构：select col1,col2 into #t from t where 1=0 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(…) 13.很多时候用 exists 代替 in 是一个好的选择：select num from a where num in(select num from b) 用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 14.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 索引并不是越多越好，索引固然可 以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。 应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 17.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 18.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 19.任何地方都不要使用 select from t ，用具体的字段列表代替“”，不要返回用不到的任何字段。 20.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 21.避免频繁创建和删除临时表，以减少系统表资源的消耗。 22.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 25.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 26.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 与临时表一样，游标并不是不可使 用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送DONE_IN_PROC 消息。 29.尽量避免大事务操作，提高系统并发能力。 30.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://tokerr.github.io/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://tokerr.github.io/tags/数据库/"},{"name":"mysql索引优化","slug":"mysql索引优化","permalink":"https://tokerr.github.io/tags/mysql索引优化/"}]},{"title":"简单易懂的更换hexo主题的教程","slug":"简单易懂的更换hexo主题的教程","date":"2017-04-05T14:47:29.000Z","updated":"2019-05-01T13:51:07.481Z","comments":true,"path":"2017/04/05/简单易懂的更换hexo主题的教程/","link":"","permalink":"https://tokerr.github.io/2017/04/05/简单易懂的更换hexo主题的教程/","excerpt":"以Smackdown为例：http://blog.smackdown.gebilaowu.cn/一、预览的页面 二、到github中找到hexo主题的demo一般的都会附带上github的demo地址，顺便附录上hexo官方的主题列表页面，大家可以在里面挑一款自己喜欢的(https://hexo.io/themes/)，这个官网的主题连接在_config.yml配置文件的themes属性配置的上面有。","text":"以Smackdown为例：http://blog.smackdown.gebilaowu.cn/一、预览的页面 二、到github中找到hexo主题的demo一般的都会附带上github的demo地址，顺便附录上hexo官方的主题列表页面，大家可以在里面挑一款自己喜欢的(https://hexo.io/themes/)，这个官网的主题连接在_config.yml配置文件的themes属性配置的上面有。图示的仓库地址：https://github.com/smackgg/hexo-theme-smackdown 三、将主题的demo克隆到本地一定要确保克隆到自己bolg下面的themes下面(置于克隆到其他的文件夹我没有试过) 四、更新操作： 五、修改配置文件，打开_config.yml文件： 六、启动本地预览效果： 七、部署到github服务器： 八、注意事项：8.1 由于windows的cmd一般是gbk方式编码，因此使用windows自带的cmd初始化blog之后，需要把_config.yml配置文件改成utf-8的编码格式，不然部署到服务器上浏览器打开会出现中文乱码。 8.2 我搭建hexo博客，部署deploy的时候出现了error deployer not found:github 的错误，附上当前解决这个问题的连接：http://www.jianshu.com/p/5e0ca2b14815","categories":[],"tags":[{"name":"hexo 主题 更换","slug":"hexo-主题-更换","permalink":"https://tokerr.github.io/tags/hexo-主题-更换/"}]}]}