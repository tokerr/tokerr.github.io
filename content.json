{"meta":{"title":"是滔不是涛","subtitle":"nongyongtao","description":"农永滔的博客","author":"nongyongtao","url":"https://tokerr.github.io"},"pages":[],"posts":[{"title":"单例模式还可以用枚举来实现吗？","slug":"单例模式（singleton）","date":"2020-04-19T06:03:00.000Z","updated":"2020-04-19T06:50:18.542Z","comments":true,"path":"2020/04/19/单例模式（singleton）/","link":"","permalink":"https://tokerr.github.io/2020/04/19/单例模式（singleton）/","excerpt":"单例模式（singleton）一、什么是单例模式？ 确保内存当中一个类的实例对象只要一个 二、两种单例模式 饿汉式 步骤 在单例类中定义与自己类型相同的常量，并初始化 private static final SingletonClass INSTANCE= new SingletonClass(); 私有化单例类的构造方法 定义一个publish的getInstance方法，返回实例化的常量 特点 在类初始化阶段就完成了单例对象的初始化 不存在多线程安全问题","text":"单例模式（singleton）一、什么是单例模式？ 确保内存当中一个类的实例对象只要一个 二、两种单例模式 饿汉式 步骤 在单例类中定义与自己类型相同的常量，并初始化 private static final SingletonClass INSTANCE= new SingletonClass(); 私有化单例类的构造方法 定义一个publish的getInstance方法，返回实例化的常量 特点 在类初始化阶段就完成了单例对象的初始化 不存在多线程安全问题 懒汉式 特点 在第一次调用getInstance方法的时候才会初始化单例对象，这也是与‘饿汉式’的区别。 实现步骤 单例类中定义一个与自己类型相同的静态变量，不初始化 private static SIngletonClass INSTANCE; 同样需要私有化单例类的构造方法 实现getInstance方法 实现方式一 123456public static SIngletonClass getInstance()&#123;if(INSTANCE == null)&#123; INSTANCE=new SingletonClass();&#125;return INSTANCE;&#125; 存在的问题 存在多线程安全的问题，可能两个线程分别得到不同的实例 实现方式二：synchronized 在方式一的基础上，给getInstance方法加synchronized关键字 存在的问题 解决了方式一的多线程安全问题，但是会大大降低运行效率 实现方式三 1234567891011public static SIngletonClass getInstance()&#123;if( INSTANCE == null)&#123; synchronized(SIngletonClass.class)&#123; INSTANCE=new SIngletonClass();&#125;&#125;return INSTANCE;&#125; 缺陷：同样有多线程安全问题 实现方式四：双重判断加锁 在方式三的基础上，在synchronized加锁之后，再次对INSTANCE做一次空判断，如果也为空，再初始化单例对象。 需要使用volatile关键字修饰变量，防止JIT对指令进行重排序 private static volatile SingletonClass INSTANCE; 多线程安全的问题得以解决 实现方式五：使用内部类的方式实现懒汉式 指导思想： JVM“只对每个类加载一次”的原则，保证了多线程安全 JVM加载外部类时不会加载内部类，这样可以实现懒加载 代码实现 12345678910111213public class SingletonClass&#123;private SingletonClass()&#123;&#125;;public static class InnerClass&#123;public static final SingletonClass INSTANCE=new SingletonClass();&#125; public static SingletonClass getInstance()&#123;return InnerClass.INSTANCE;&#125;&#125; 实现方式六：使用枚举类的方式实现懒汉式 好处： 不仅可以解决多线程安全问题，还可以防止反序列化。想其他几种单例的实现方式，都是可以通过反射的方式再次创建实例的。（枚举类没有构造方法） 是最简单和安全的实现方式 123456public enum SingletonClass&#123;INSTANCE; public void method1()&#123;&#125;&#125; 三、总结这里列出了7种单例的实现方式，并不是说一定要用哪一种，而是应该结合项目的情况，选择一种合适的实现方式。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://tokerr.github.io/tags/设计模式/"},{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://tokerr.github.io/tags/DesignPattern/"}]},{"title":"代理模式（Proxy）","slug":"代理模式（Proxy）","date":"2020-04-12T08:44:00.000Z","updated":"2020-04-19T07:07:18.235Z","comments":true,"path":"2020/04/12/代理模式（Proxy）/","link":"","permalink":"https://tokerr.github.io/2020/04/12/代理模式（Proxy）/","excerpt":"代理模式（Proxy）一、说明 本文当中出现的代码均为伪代码，可参考文章末尾列出的项目代码地址。 假设我们的jar包使用maven进行管理。 二、模式定义 对访问（或请求）实现拦截和权限的控制，以决定是否需要执行用户的请求。常见的代理体现有Spring AOP、javax.servlet.Filter，与装饰模式很像 三、静态代理 使用继承的方式实现代理 使用组合的方式实现代理","text":"代理模式（Proxy）一、说明 本文当中出现的代码均为伪代码，可参考文章末尾列出的项目代码地址。 假设我们的jar包使用maven进行管理。 二、模式定义 对访问（或请求）实现拦截和权限的控制，以决定是否需要执行用户的请求。常见的代理体现有Spring AOP、javax.servlet.Filter，与装饰模式很像 三、静态代理 使用继承的方式实现代理 使用组合的方式实现代理 缺点 需要为不同的代理逻辑编写新的代理类 角色 代理 被代理对象 类图 代理和被代理对象都实现了同一个接口 四、动态代理 4.1JDK动态代理（接口代理） 局限 被代理类必须要实现至少一个接口 通过反编译查看生成的代理类，其实实现了指定的接口 使用步骤 1.先定义一个接口 123interface Moveable&#123; void move(); &#125; ​ 2.定义InvacationHandler 1234567891011121314public MyInvocationhandler implement InvocationHandler&#123;Moveable object;public MyInvocationhandler(Moveable object)&#123; this.object=object;&#125; @Overridepublic Object invoke(Object proxy, Method method , Object[] args)&#123;System.out.println(\"执行之前！\");return method.invoke(object,args);&#125;&#125; ​ 3.通过JDK API生成接口的代理对象 1Proxy.newProxyInstance(MoveableSub.class.getClassLoader(), new Class[]&#123;Moveable.class&#125;,new MyInvocationHandler(new MoveableSub())) ​ 4.可以通过设置，将生成的字节码文件（代理类）保存到本地 1System.setProperty(\"sun.misc.ProxyGenerator.saveGeneratedFiles\",\"true\") 原理 a&gt; 使用的是一个小而快的字节码工具ASM，生成代理类。因此，Java的动态语言特性其实就是ASM。 b&gt; ASM可以直接修改class二进制字节码。 4.2 Instrument动态代理 Instrument是一个类似ASM的工具 原理是在将二进制字节码加载到JVM之前，篡改二进制字节码 4.3 CGLIB动态代理（子类代理） 局限 不能对final修饰的类生成代理子类，但是ASM可以突破这种语法上的限制。 原理 底层也是使用ASM工具。 使用步骤 ​ 1.引入maven依赖 123456&lt;!-- https://mvnrepository.com/artifact/cglib/cglib --&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; ​ 2.编写一个需要被代理的类Example 1234567public class Example&#123; public void action()&#123; System.out.println(\"我是被代理对象！\");&#125;&#125; ​ 3.编写代理逻辑（拦截的逻辑） 1234567891011public MyInterceptor implement MethodInterceptor &#123;@Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"这个是产生的代理对象：\"+o.getClass().getName()); Object invoke =methodProxy.invokeSuper(o,objects); return invoke;&#125;&#125; ​ 4.Main逻辑 12345Enhancer enhancer=new Enhancer();enhancer.setSuperClass(Example.class);enhancer.setInterceptor(new MyInterceptor());Example proxy=enhancer.create();proxy.action(); 五、常见案例 Spring AOP使用了JDK动态代理和CGLIB子类代理 六、疑问？ JDK动态代理中如果接口当中定义了多个方法，是否生成的代理类中这些方法是否都调用了InvocationHandler::invoke()方法？ 是的，可以通过查看生成代理类的反编译源代码可以知道，代理子类中所有的方法都调用了InvocationHandler::invoke() 七、项目GitHub地址​ https://github.com/tokerr/designpatterns/tree/master/src/main/java/com/nyt/proxy","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://tokerr.github.io/tags/设计模式/"},{"name":"CGLIB","slug":"CGLIB","permalink":"https://tokerr.github.io/tags/CGLIB/"},{"name":"DesignPattern","slug":"DesignPattern","permalink":"https://tokerr.github.io/tags/DesignPattern/"}]},{"title":"Java线程池ThreadPoolExecutor","slug":"Java线程池ThreadPoolExecutor","date":"2020-02-16T09:56:00.000Z","updated":"2020-04-19T07:29:12.832Z","comments":true,"path":"2020/02/16/Java线程池ThreadPoolExecutor/","link":"","permalink":"https://tokerr.github.io/2020/02/16/Java线程池ThreadPoolExecutor/","excerpt":"ThreadPoolExecutor是JDK中线程池的重要体现，JDK中的Executors工厂类，提供了不同ThreaPoolExecutor的构建方法，本章的内容主要是对ThreadPoolExecutor的内部结构、运行原理和重点参数做介绍。 一、继承关系图 #二、内部结构组成 核心线程数 最大线程数工作队列 工作队列","text":"ThreadPoolExecutor是JDK中线程池的重要体现，JDK中的Executors工厂类，提供了不同ThreaPoolExecutor的构建方法，本章的内容主要是对ThreadPoolExecutor的内部结构、运行原理和重点参数做介绍。 一、继承关系图 #二、内部结构组成 核心线程数 最大线程数工作队列 工作队列 三、构造参数说明 corePoolSize：核心线程的数量 maximumPoolSize：最大线程的数量 keepAliveTime：普通线程空间之后的存活时间 workQueue：类型为BlockingQueue的工作队列，用于保存等待执行任务的任务阻塞队列，有以下几种： 1） ArrayBlockingQueue：是一个基于数组实现的有界阻塞队列 2）LinkedBlockingQueue：一个基于链表结构的无解阻塞队列 3）SynchronousQueue：一个不存储元素的阻塞队列，每一个插入操作都必须等待另一个线程调用移除操作，否则一直处于阻塞状态 RejectedExecutionHandler：饱和策略 1）CallerRunPolicy：只用调用者所在的线程来处理任务 2）AbortPolicy（默认）：表示无法处理新任务时抛出异常3）DiscardPolicy：不处理，直接丢弃4）DiscardOldestPolicy：丢弃工作队列里最近的一个任务，并执行当前任务 四、内部运行原理​ 线程池初始化完毕之后，内部先创建的线程属于核心线程​ 假设n为线程池中当前未完成的任务数量；因为有可能会出现类似CacheThreadPool的线程池（它的corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE） ，因此以下情况我们假设：corePoolSize &lt; maximumPoolSize。 当n &lt; corePoolSize时，对于新提交的任务，将创建新的线程去执行执行这一步需要获取全局锁 当n &gt;= corePoolSize时，对于提交的新任务，将任务保存到工作队列中，当核心线程中有执行完自己的任务，空闲下来后，则从工作队列中取出任务执行 如果工作队列任务已满，并且maximumPoolSize &gt;= n &gt;时，对于新提交的任务，将创建新的线程去执行执行这一步需要获取全局锁 当 n &gt;maximumPoolSize 时，对于新提交的任务，将使用饱和策略进行处理 五、向线程池提交任务的方法 Executor::execute()方法这个方法用于提交不需要返回值的任务，所以无法判断任务是否被线程执行成功，输入的类型是Runnable ExecutorService::submit()方法这个方法用于提交需要返回值的任务，方法可以输入Runnable或者Callable，方法返回一个Future类型的对象，通过Future::get()获取返回值 六、关闭线程池​ 调用shutdown()或shutdownNow()方法来关闭线程池，他们的原理都是遍历线程池中的工作线程，然后逐个调用interrupt()方法中断线程。两者的区别在于，shutdownNow()首先将线程池的状态设置为STOP，然后尝试停止所有的正在执行的或者暂停任务的线程，并返回等待执行任务的列表。shutdown()只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"线程池","slug":"线程池","permalink":"https://tokerr.github.io/tags/线程池/"},{"name":"多线程","slug":"多线程","permalink":"https://tokerr.github.io/tags/多线程/"}]},{"title":"事务隔离级别","slug":"事务隔离级别","date":"2019-12-01T11:40:11.000Z","updated":"2019-12-01T12:40:40.639Z","comments":true,"path":"2019/12/01/事务隔离级别/","link":"","permalink":"https://tokerr.github.io/2019/12/01/事务隔离级别/","excerpt":"简介​ 本文就Mysql数据库的事务进行阐述，包括事务的ACID特性、事务的隔离级别、事务隔离级别解决的问题、事务隔离级别的实现等内容。 事务的四大特性事务的ACID特性，也称为事务的四大特性，分别是： 原子性（Atomicity） 一致性（Consistency） 隔离性（Isolation） 持久性（Durability） 事务的隔离级别​ 事务的隔离性，当数据库中有多个事务执行的时候，就有可能出现“脏读”、“不可重复读”、“幻读”的问题，为了解决这些问题，于是就有了事务的“隔离级别”，事务的隔离级别包括： 读未提交（Read uncommitted） 读已提交（Read committed） 可重复读（Repeatable read） 串行化（Serializable）","text":"简介​ 本文就Mysql数据库的事务进行阐述，包括事务的ACID特性、事务的隔离级别、事务隔离级别解决的问题、事务隔离级别的实现等内容。 事务的四大特性事务的ACID特性，也称为事务的四大特性，分别是： 原子性（Atomicity） 一致性（Consistency） 隔离性（Isolation） 持久性（Durability） 事务的隔离级别​ 事务的隔离性，当数据库中有多个事务执行的时候，就有可能出现“脏读”、“不可重复读”、“幻读”的问题，为了解决这些问题，于是就有了事务的“隔离级别”，事务的隔离级别包括： 读未提交（Read uncommitted） 读已提交（Read committed） 可重复读（Repeatable read） 串行化（Serializable） 这里一张图可以清楚的看到，不同的隔离级别下可能会出现的问题（X表示不会出现，V表示可能出现）。 ​ 从上往下，事务的隔离级别依次递增，隔离级别越高导致数据库的处理效率越低。所以，需要选择适合自己业务系统的隔离级别，Mysql默认的隔离级别是“可重复读”、Oracle默认的隔离级别是“读已提交”。在将Oracle的数据迁移到Mysql的时候，记得将Mysql的事务隔离级别设置成“读已提交”。Mysql可以通过如下的方式查看和修改事务隔离级别。 ​ 使用 show variables 方式查询事务隔离级别： 1show variables like &quot;transaction_isolation&quot;; 修改事务隔离级别，可以通过修改配置文件，或者在线的方式修改。 修改配置，在系统全局生效： 在my.cnf中添加或者修改如下配置: 12[mysqld]transaction_isolation=REPEATABLE-READ transaction-isolation可选的值有READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ、SERIALIZABLE。 修改完成需要重启mysql。 修改当前会话的隔离级别（在线方式）： 1set session transaction isolation level read committed; 如果希望通过在线方式，全局修改事务隔离级别: 1set global transaction isolation level read uncommitted; 分别查看全局和当前会话的事务隔离级别： 事务隔离级别解决的问题事务的隔离级别解决的是“脏读（dirty read）”、“不可重复读（non-repeatable read）”、“幻读（phantom read）”的问题。 脏读：指的是一个事务读取到另一个事务没有提交的数据。 不可重复读：指的是一个事务访问同一条数据多次，得到的是不同的结果。偏向于指数据的修改。 幻读：指的是一个事务访问到 同时后者后启动事务插入的数据。偏向于指数据的插入和删除。 事务的启动方式 显示启动事务语句，begin或者start transaction。配套的提交语句是commit ，回滚语句是rollback; set autocommit=0，这个语句会将线程的自动提交关闭。为了避免长事务，应将自动提交开启：set autocommit=1。mysql默认是开启的。 我们可以通过查询information_schema库的innodb_trx这个表中查询长事务。如下语句是查询持续时间超过60s事务： 1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60; 一致性读视图 使用begin或者start transaction的方式启动事务，一致性读视图是在执行第一个快照读语句的时候创建的。 使用如下语句启动事务，一致性读视图是在执行该语句的时候创建的。 1start transaction with consistent snapshot; 注意，mysql里面有两个视图的概念： 一个是view。是用查询语句定义的一个虚拟表，创建视图的语法是create view …，查询方式与表一样。 另一个就是这里提到的，在innodb里面MVCC用到的一致性读视图：consistent read view，用于支持‘读已提交’和‘可重复读’事务隔离级别的实现。 事务隔离级别的实现​ 针对读已提交和可重复读两种事务隔离级别，在实现上，数据库会创建一个“一致性读视图”，事务访问的时候以一致性读视图的逻辑结果为准。可重复读级别的一致性读视图，是在事务启动的时候创建，整个时候存在期间都用这个视图；读已提交级别的一致性读视图是在每个SQL语句开始执行的时候创建的。读未提交级别直接返回记录上最新的记录，串行化级别使用加锁的方式避免并行访问，没有“一致性读视图”的概念。 ​ InnoDB中每一行记录都有多个版本（MySQL默认使用InnoDB存储引擎），也就是数据库的多版本并发控制（MVCC）。 ​ MySQL对每一条的记录更新都会记录一条回滚日志（undo log），记录最新的值，同时通过回滚日志可以得到上一个状态的值。 ​ 对于不同的‘一致性读视图’，可以通过对当前值，依次执行undo log回滚得到。 ​ 回滚日志什么时候删除？mysql会判断，当没有比这个回滚日志更早的一致性读视图时，会将这个回滚日志删除掉。因此，建议不要使用长事务，长事务会导致回滚日志很大，会导致大量占用存储空间。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://tokerr.github.io/tags/mysql/"},{"name":"事务","slug":"事务","permalink":"https://tokerr.github.io/tags/事务/"},{"name":"事务隔离级别","slug":"事务隔离级别","permalink":"https://tokerr.github.io/tags/事务隔离级别/"}]},{"title":"Java内存区域与内存溢出异常","slug":"Java内存区域与内存溢出异常","date":"2018-06-02T15:48:41.000Z","updated":"2019-05-01T13:51:07.474Z","comments":true,"path":"2018/06/02/Java内存区域与内存溢出异常/","link":"","permalink":"https://tokerr.github.io/2018/06/02/Java内存区域与内存溢出异常/","excerpt":"前言：Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。 Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。 无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。 通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。","text":"前言：Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。 Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。 无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。 通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和技术而简历和销毁的。Java虚拟所管理的内存区域将会包括一下几个运行时数据区域。 程序计数器介绍:程序计数器(Program counter register)是一块较小的内存控件，它的作用可以看做是当前线程所执行的字节码的行号指示器。 作用：在虚拟机的概念模型里，字节码的解析器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程回复等基础功能都需要依赖这个计数器来完成。 服务对象：由于Java虚拟机的多线程是通过线程的轮流切换并分配处理器执行时间的方式来时间的，在任何一个确定的时刻，一个处理器(对于多核处理器来说是一个内核)只会执行一条线程中的指令。因此，为了线程钱换后能回复到正确的执行为孩子，每条线程都需要有一个独立的程序计数器，各个线程之间的计数器互不影响，独立储存，我们称这块内存区域为”线程私有”的内存。 如果线程正在执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；此内存区域是唯一一个在Java虚拟规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈介绍：与程序计数器一样，Java虚拟机栈(JVM Stacks)也是线程自由的，他的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态连接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应这一个栈帧在虚拟机栈中从入栈和出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型(boolean,byte,char,short,int,float,long,double)、对象引用和returnAddress类型(指向了一条字节码指令的地址)。局部变量表所需要的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况:如果线程的栈深度大于虚拟机所允许的深的，将抛出StackOverflowError异常；如果虚拟机栈可以动态拓展，当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈本地方法栈(Native Method Stacks)与虚拟机栈所发挥的作用是非常的相似，其区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则是为虚拟机使用到的Navite方法服务。 简单地讲，一个Native Method就是一个java调用非java代码的接口，该方法的实现由非java语言实现。 java堆对于大多数的应用，Java堆(Java heap)是java虚拟机所管理的内存中最大的一块。java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例在这里分配内存。 java堆是垃圾收集器管理的主要区域，因此很多时候也被称为”GC堆”。 方法区方法区(Method Area)与java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。 PermGen（永久代）绝大部分 Java 程序员应该都见过 “java.lang.OutOfMemoryError: PermGen space “这个异常。这里的 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在 jsp 页面比较多的情况，容易出现永久代内存溢出。 在 JDK 1.8 中， HotSpot 已经没有 “PermGen space”这个区间了，取而代之是一个叫做 Metaspace（元空间） 的东西。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://tokerr.github.io/tags/jvm/"}]},{"title":"hadoop2.9.0 编译源码安装","slug":"hadoop2-9-0-编译源码安装","date":"2017-12-17T11:10:01.000Z","updated":"2019-05-01T13:51:07.476Z","comments":true,"path":"2017/12/17/hadoop2-9-0-编译源码安装/","link":"","permalink":"https://tokerr.github.io/2017/12/17/hadoop2-9-0-编译源码安装/","excerpt":"1.编译基础环境Requirements: * Unix System (我这里使用的是centos 6.8) * JDK 1.8+ * Maven 3.0 or later * Findbugs 1.3.9 (if running findbugs) * ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错） * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac * Zlib devel (if compiling native code) * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance) * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs) * Internet connection for first build (to fetch all Maven and Hadoop dependencies) * python (for releasedocs) * bats (for shell code testing) * Node.js / bower / Ember-cli (for YARN UI v2 building)","text":"1.编译基础环境Requirements: * Unix System (我这里使用的是centos 6.8) * JDK 1.8+ * Maven 3.0 or later * Findbugs 1.3.9 (if running findbugs) * ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错） * CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac * Zlib devel (if compiling native code) * openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance) * Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs) * Internet connection for first build (to fetch all Maven and Hadoop dependencies) * python (for releasedocs) * bats (for shell code testing) * Node.js / bower / Ember-cli (for YARN UI v2 building) 备注：由于这里的教程基本都是使用在线安装的方式，包括后面的使用maven对hadoop2.9的源码进行编译，需要下载依赖包，因此请确保服务器连接外网，如果你使用的是vmware虚拟机，可以参考我另一篇博客 vmware虚拟机host-only下配置与宿主机共享网络。 2.yum 源配置 首先安装wget （已安装则忽略） yum install -y wget 将CentOS的yum源更换为国内的阿里云源，我们使用默认的yum源，有时会连接到国外的镜像站导致yum下载比较慢。，所以将默认的yum源替换为阿里云的镜像站。 阿里云Linux安装镜像源地址：http://mirrors.aliyun.com/ 备份你的原镜像文件，以免出错后可以恢复。 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的CentOS-Base.repo 到/etc/yum.repos.d/ CentOS 5 使用下面的链接 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo CentOS 6 使用下面的链接 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo CentOS 7 使用下面的链接 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 运行yum makecache生成缓存 yum clean all yum makecache 3.yum 安装gcc对于配备了yum的Linux发行版而言，安装gcc编译器就变得so easy。我们只需要分别执行如下命令即可： yum -y install gcc gcc-c++ kernel-devel 4.安装CMake#wget https://cmake.org/files/v3.3/cmake-3.3.2.tar.gz #tar -zxvf cmake-2.8.10.2.tar.gz #cd cmake-2.8.10.2 #./bootstrap #gmake #gmake install 5.下载Hadoop源码包[root@hadoop001 sourcecode]# mkdir -p /opt/sourcecode [root@hadoop001 sourcecode]#wget http://apache.mirrors.tds.net/hadoop/common/stable/hadoop-2.9.0-src.tar.gz [root@hadoop001 sourcecode]#tar -xzvf hadoop-2.9.0-src.tar.gz [root@hadoop001 sourcecode]#cat ./hadoop-2.9.0-src/BUILDING.txt #从BUILDING文件中我们可以看到编译的要求 6.JDK安装这个安装起来相对简单，官网下载个tar包，解压配置环境变量就可以。可以自行百度和google ,可参考我如下系统环境变量配置文件： # cat /etc/profile JAVA_HOME=/usr/local/work/jdk1.8.0_144 MAVEN_HOME=/home/package/apache-maven-3.5.2 FINDBUGS_HOME=/home/package/findbugs-3.0.1 PROTOBUF_HOME=/usr/local/protobuf HADOOP_HOME=/home/hadoop/hadoop-2.9.0 CLASSPATH=.:$JAVA_HOME/lib/tools.jar PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$FINDBUGS_HOME/bin:$PROTOBUF_HOME/bin:$HADOOP_HOME/bin:$PATH export JAVA_HOME MAVEN_HOME FINDBUGS_HOME PROTOBUF_HOME HADOOP_HOME CLASSPATH PATH 7.Maven安装#wget 获取tar包 #解压 #配置环境变量 mvn --version #验证 8.protobuf安装protobuf要编译安装，需安装gcc、gcc-c++、 make 上传 protobuf-2.5.0.tar.gz tar -xzvf protobuf-2.5.0.tar.gz cd protobuf-2.5.0 yum install -y gcc gcc-c++ make ./configure --prefix=/usr/local/protobuf make &amp;&amp; make install #添加protobuf环境变量 source /etc/profile protoc --version 9.Findbugs安装下载tar包，解压，配置环境变量 10.安装snappy1.1.4,使Hadoop支持snappy压缩10.Snappy压缩库安装wget https://github.com/google/snappy/releases/download/1.1.4/snappy-1.1.4.tar.gz tar -zxvf snappy-1.1.4.tar.gz cd snappy-1.1.4 ./configure make &amp;&amp; make install ll -h /usr/local/lib |grep snappy 11.其他依赖安装yum install -y ant openssl openssl-devel svn ncurses-devel zlib-devel libtool svn yum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automake 12.编译进入Hadooop源码目录 cd hadoop-2.9.0-src mvn clean package -DskipTests -Pdist,native -Dtar -Dsnappy.lib=/usr/local/lib -Dbundle.snappy 13.生成tar包/home/hadoop/hadoop-2.9.0-src/hadoop-dist/target/hadoop-2.9.0.tar.gz 以下是我maven编译完成的信息，时间还是比较长的，跟网络也有关系： [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 02:44 h [INFO] Finished at: 2017-12-17T15:26:30+08:00 [INFO] Final Memory: 129M/237M [INFO] ------------------------------------------------------------------------ 注意事项： 由于Maven仓库在墙外，Maven在编译项目时下载包卡住情况，ctrl+c 中断，重新执行编译。 如果出现提示缺少了某个文件的情况，则要先清理maven(使用命令 mvn clean) 再重新编译。","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"}]},{"title":"虚拟机host-only下配置与宿主机共享网络","slug":"虚拟机host-only下配置与宿主机共享网络","date":"2017-12-17T10:52:41.000Z","updated":"2019-05-01T13:51:07.481Z","comments":true,"path":"2017/12/17/虚拟机host-only下配置与宿主机共享网络/","link":"","permalink":"https://tokerr.github.io/2017/12/17/虚拟机host-only下配置与宿主机共享网络/","excerpt":"准备 示例环境： 宿主机：windows7 虚拟机软件：vmware 12 pro 虚拟机：centos 6.8 备注：假设以上的环境已经全部安装完毕 1.在windows下打开网络适配器设置页面","text":"准备 示例环境： 宿主机：windows7 虚拟机软件：vmware 12 pro 虚拟机：centos 6.8 备注：假设以上的环境已经全部安装完毕 1.在windows下打开网络适配器设置页面点击进去，看到如下界面： 2.宿主机所连接的外网通过windows网络共享给VMnet1截图可以看到我宿主机所连接的网络是‘无线网络连接’，右键点击其属性，然后切换到共享网卡，勾选“允许其他网络用户通过此计算机的Internet连接来连接”，“请选择一个专用连接”下拉框选择“VMware Network Adapter VMnet1”，点击确定。 此时会提示VMware Network Adapter VMnet1的IP地址被修改为192.168.137.1，客户机网络配置要用到这个信息（本例为192.168.137.1，注意，这里经过试验，尽量不要修改这个ip地址，否则会出现配置不成功的现象）。 3.准备Linux环境3.1点击VMware快捷方式，右键打开文件所在位置 -&gt; 双击vmnetcfg.exe -&gt; VMnet1 host-only -&gt;修改subnet ip 设置网段：192.168.137.0 子网掩码：255.255.255.0 –&gt; 同时关闭DHCP服务-&gt; apply -&gt; ok在虚拟软件上 –My Computer -&gt; 选中虚拟机 -&gt; 右键 -&gt; settings -&gt; network adapter -&gt; host only -&gt; ok 3.3修改IP/配置DNS vim /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet UUID=6169d30a-2243-4a7d-9f03-455d9e0cefa6 ONBOOT=no NM_CONTROLLED=yes #BOOTPROTO=dhcp BOOTPROTO=static ##设置静态 IPADDR=192.168.137.101 ##配置ip NETMASK=255.255.255.0 ##配置子网 GATEWAY=192.168.137.2 ##配置网关 PREFIX=24 DNS1=8.8.8.8 ##配置dns DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no NAME=&quot;System eth0&quot; HWADDR=00:0C:29:44:CB:D8 LAST_CONNECT=1513431454 保存退出，重启网络服务： service network restart","categories":[],"tags":[{"name":"vmware","slug":"vmware","permalink":"https://tokerr.github.io/tags/vmware/"}]},{"title":"负载均衡session共享解决方法整理","slug":"负载均衡session共享解决方法整理","date":"2017-11-20T15:44:36.000Z","updated":"2019-05-01T13:51:07.482Z","comments":true,"path":"2017/11/20/负载均衡session共享解决方法整理/","link":"","permalink":"https://tokerr.github.io/2017/11/20/负载均衡session共享解决方法整理/","excerpt":"一、背景：最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！ 项目属于JavaWeb项目，部署在Tomcat环境下。 二、tomcat集群环境下session共享方法整理在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路： 一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；","text":"一、背景：最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！ 项目属于JavaWeb项目，部署在Tomcat环境下。 二、tomcat集群环境下session共享方法整理在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路： 一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；二是在集群中左右的节点进行Session数据的同步拷贝，所有节点的均保存了所有的Session数据。 2.1tomcat集群session同步方案有以下几种：1）使用tomcat自带的cluster方式，多个tomcat间自动实时复制session信息，配置起来很简单。使用组播的方式实现session的同步拷贝，但这个方案的效率比较低，在大并发下表现并不好。而且需要另外安装apache的HTTP Server，同样需要一台节点了协调session的拷贝，比较多余，使用的人少，网上的资料比较乱(建议去官网)。不推荐。 2）利用nginx的基于访问ip的hash路由策略，保证访问的ip始终被路由到同一个tomcat上，这个配置更简单。但如果应用是某一个局域网大量用户同时登录，这样负载均衡就没什么作用了。 3）利用nginx插件实现tomcat集群和session同步，nginx-upstream-jvm-route-0.1.tar.gz，是一个Nginx的扩展模块，用来实现基于Cookie的Session Sticky的功能。 4）利用memcached实现（MSM工具）。memcached存储session，并把多个tomcat的session集中管理，前端在利用nginx负载均衡和动静态资源分离，在兼顾系统水平扩展的同时又能保证较高的性能。 5）利用redis实现。使用redis不仅仅可以将缓存的session持久化，还因为它支持的单个对象比较大，而且数据类型丰富，不只是缓存 session，还可以做其他用途，可以一举几得。 6）利用filter+cookie方式实现。这种方法比较推荐，因为它的服务器使用范围比较多，不仅限于tomcat ，而且实现的原理比较简单容易控制。 最后三种方法是比较推荐，尝试过第一种方法，但是不推荐，原因已经写明；第四第五种方法，由于公司需要另外申请一台单独的session共享服务器，比较麻烦。最终还是选择了最后一种解决方案，思路简单，实现起来也不难。下面将介绍这种方案。 三、cookie+filter解决session共享问题下面是实现该方案涉及到的三个相关功能，重点在于过滤器的编写。 3.1 登录成功通知浏览器保存cookiepublic static void setCookie(HttpServletResponse response, HttpServletRequest request, String cookieName, String cookieValue) { /** * a.先判断是否存在cookie ，存在自己设置的cookie则重新设置过期的时间 b.不存在则创建自己cookie 通知客户端保存 * c.需要设置的属性如下： 设置value ,具体值视自己的业务而定，具体设置的之后可以通过构造方法设置name=value * ，注意使用算法加密 设置编码 设置过期时间 ，设置与session过期时间一致 设置domain 设置path */ // 声明 cookie Cookie autoCookie = null; // 获取所有的cookie Cookie cookies[] = request.getCookies(); HttpSession session = request.getSession(); // session.getMaxInactiveInterval();//session失效时间，值小于等于0代表永不超时 // 遍历cookie if (cookies != null &amp;&amp; cookies.length &gt; 0) { for (Cookie cookie : cookies) { // 判断是否存在自动登录记录 if (cookieName.equals(cookie.getName())) { autoCookie = cookie;// 赋值 break; } } } if (autoCookie == null) { // 不在创建 autoCookie = new Cookie(cookieName, cookieValue); } // 设置在执行秒数之后过期；负值意味着cookie不存储，浏览器退出则清除；值为零表示删除cookie autoCookie.setMaxAge(expiry);// 设置7天之内过期 // 设置编码 // 设置域名domain 默认情况下，Cookie只会返回给发送它们的服务器。 autoCookie.setDomain(request.getServerName()); // 设置path autoCookie.setPath(request.getContextPath()); // 浏览器的document对象中就看不到cookie autoCookie.setHttpOnly(true); response.addCookie(autoCookie);// 添加 } 3.2 登录退出通知浏览器清除cookiepublic static void cleanCookie(HttpServletRequest request, HttpServletResponse response, String cookieName) { Cookie cookies[] = request.getCookies(); if (cookies != null &amp;&amp; cookies.length &gt; 0) { for (Cookie cookie : cookies) { if (cookieName.equals(cookie.getName())) { cookie.setPath(request.getContextPath());// 浏览器回以同Name同Path同Domain覆盖原来的cookie cookie.setDomain(request.getServerName()); cookie.setMaxAge(0);// 通知浏览器删除 response.addCookie(cookie); } } } } } 3.3 编写自动登录过滤器 1）获取cookie判断用户是否已经登录 2）未登录则放行 3）已登录并且本地服务器没有相关session会话信息，则执行自动登录流程 4）自动登录完毕放行 @Override public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws IOException, ServletException { /** * a.到session获取认证信息 ，存在则通过认证，放行并终止程序 不存在执行下一步 b. * 不存在认证信息，获取cookie，遍历判断是否存在自己设置的cookie，不存在直接放行并终止程序 存在执行下一步 * c.执行自动登录流程，并查询用户必要的信息保存到session当中，执行完毕放行并终止程序 */ HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) resp; HttpSession session = request.getSession(); Object token = session.getAttribute(Constant.USER_CONTEXT_LOGGED); Cookie[] cookies = request.getCookies(); // 用户执行注销操作不进行自动登录 String uri = request.getRequestURI(); String logout = request.getParameter(&quot;logout&quot;); if (uri.contains(&quot;/projectContextPath/index.html&quot;) &amp;&amp; logout != null &amp;&amp; &quot;true&quot;.equals(logout)) { StringBuffer url = request.getRequestURL(); response.sendRedirect(url.toString()); return; } if (cookies != null &amp;&amp; cookies.length &gt; 0) {// 在session中没有获取到用户信息 Cookie autoCookie = null;// 已登录的cookie for (Cookie cookie : cookies) { // 未在本服务器登录，并且在客户端保存有响应的cookie，才会执行自动登录 if (Constant.COOKIE_NAME.equals(cookie.getName()) &amp;&amp; token == null) {// cookie存在 autoCookie = cookie; } } if (autoCookie != null ) {// 存在cookie // 开始自动登录，视具体业务根据cookie中的信息查询用户的信息并保存到session中完成自动登录 startAutoLogin(request, response, autoCookie); } } chain.doFilter(request, response);// 放行 } 另外， 安全性问题考虑，由于使用的是cookie保存了用户的信息，容易被黑客拦截篡改。通常cookie中会保存用户名、密码等敏感经过加密，很难反向破解，但也不是绝对的安全，黑客可以通过木马病毒盗取用户浏览器的cookie，直接骗取网站的信任。 最好是使用https。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"session","slug":"session","permalink":"https://tokerr.github.io/tags/session/"},{"name":"cookie","slug":"cookie","permalink":"https://tokerr.github.io/tags/cookie/"}]},{"title":"sqoop学习笔记","slug":"sqoop学习笔记","date":"2017-10-25T13:28:29.000Z","updated":"2019-05-01T13:51:07.478Z","comments":true,"path":"2017/10/25/sqoop学习笔记/","link":"","permalink":"https://tokerr.github.io/2017/10/25/sqoop学习笔记/","excerpt":"说明：这里以hadoop2和mysql为例。 1.上传sqoop到Hadoop集群任意一个节点2.安装和配置2.1 配置sqoop-env.sh文件在sqoop中conf目录下新复制一个sqoop-env.sh文件：[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh修改配置sqoop-env.sh文件：","text":"说明：这里以hadoop2和mysql为例。 1.上传sqoop到Hadoop集群任意一个节点2.安装和配置2.1 配置sqoop-env.sh文件在sqoop中conf目录下新复制一个sqoop-env.sh文件：[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh修改配置sqoop-env.sh文件： export HADOOP_COMMON_HOME=/home/hadoop/hadoop/hadoop-2.3.0 #Set path to where hadoop-*-core.jar is available export HADOOP_MAPRED_HOME=/home/hadoop/hadoop/hadoop-2.3.0 #set the path to where bin/hbase is available #export HBASE_HOME= #Set the path to where bin/hive is available #export HIVE_HOME= #Set the path for where zookeper config dir is #export ZOOCFGDIR= 不配置该项会出现Please set $HADOOP_COMMON_HOME to the root的错误提示。 2.2 添加数据库驱动将数据库连接驱动拷贝到$SQOOP_HOME/lib里。注意，这里使用的是Mysql驱动版本不能过低，尽量使用最新的版本，否则可能会出现一下错误： ERROR manager.SqlManager: Error reading from database: java.sql.SQLException: Streaming result set 3.配置mysql远程登录3.1 改表：只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%” 登录数据库：mysql -u root -pvmware mysql&gt;use mysql; mysql&gt;update user set host = ‘%’ where user = ‘root’; mysql&gt;select host, user from user; mysql&gt;FLUSH RIVILEGES 3.2 授权：(1)例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。 第一步：root用户登录；mysql&gt;mysql -u root -p rootpassword; 第二步：赋予权限；mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘myuser’@’%’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; 第三步：mysql&gt;FLUSH PRIVILEGES; (2)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器，并使用mypassword作为密码 mysql&gt;GRANT ALL PRIVILEGES ON . TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; mysql&gt;FLUSH PRIVILEGES; (3)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码 mysql&gt;GRANT ALL PRIVILEGES ON dk.* TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION; mysql&gt;FLUSH PRIVILEGES; 说明：这里我使用了第（1）种方法。没有允许mysql远程登录，在使用sqoop导入数据的时候，会出现以下错误： message from server: &quot;Host is not allowed to connect to this MySQL server 4.使用&amp;练习第一类：数据库中的数据导入到HDFS上 sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --columns &apos;id, account, income, expenses&apos; 指定输出路径、指定数据分隔符 sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --target-dir &apos;/sqoop/td&apos; --fields-terminated-by &apos;\\t&apos; 指定Map数量 -m sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --target-dir &apos;/sqoop/td1&apos; --fields-terminated-by &apos;\\t&apos; -m 2 增加where条件, 注意：条件必须用引号引起来 sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 --table trade_detail --where &apos;id&gt;3&apos; --target-dir &apos;/sqoop/td2&apos; 增加query语句(使用 \\ 将语句换行) sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 \\ --query &apos;SELECT * FROM trade_detail where id &gt; 2 AND $CONDITIONS&apos; --split-by trade_detail.id --target-dir &apos;/sqoop/td3&apos; 注意： 如果使用–query这个命令的时候，需要注意的是where后面的参数，AND $CONDITIONS这个参数必须加上 而且存在单引号与双引号的区别，如果–query后面使用的是双引号，那么需要在$CONDITIONS前加上\\即\\$CONDITIONS 如果设置map数量为1个时即-m 1，不用加上–split-by ${tablename.column}，否则需要加上 第二类：将HDFS上的数据导出到数据库中(不要忘记指定分隔符) sqoop export --connect jdbc:mysql://192.168.8.120:3306/nongyt --username root --password 123 --export-dir &apos;/td3&apos; --table td_bak -m 1 --fields-terminated-by &apos;,&apos;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"sqoop","slug":"sqoop","permalink":"https://tokerr.github.io/tags/sqoop/"}]},{"title":"hadoop+zookeeper集群搭建","slug":"hadoop-zookeeper集群搭建","date":"2017-10-24T14:50:21.000Z","updated":"2019-12-01T11:58:23.066Z","comments":true,"path":"2017/10/24/hadoop-zookeeper集群搭建/","link":"","permalink":"https://tokerr.github.io/2017/10/24/hadoop-zookeeper集群搭建/","excerpt":"前期准备:hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA 1.修改Linux主机名2.修改IP3.修改主机名和IP的映射关系","text":"前期准备:hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA 1.修改Linux主机名2.修改IP3.修改主机名和IP的映射关系 注意： 如果你们公司是租用的服务器或是使用的云主机（如华为用主机、阿里云主机等） /etc/hosts里面要配置的是内网IP地址和主机名的映射关系4.关闭防火墙5.ssh免登陆 6.安装JDK，配置环境变量等 集群规划：主机名 IP 安装的软件 运行的进程 nongyt01 192.168.1.201 jdk、hadoop NameNode、DFSZKFailoverController(zkfc) nongyt02 192.168.1.202 jdk、hadoop NameNode、DFSZKFailoverController(zkfc) nongyt03 192.168.1.203 jdk、hadoop ResourceManager nongyt04 192.168.1.204 jdk、hadoop ResourceManager nongyt05 192.168.1.205 jdk、hadoop、zookeeper DataNode、NodeManager、JournalNode、QuorumPeerMain nongyt06 192.168.1.206 jdk、hadoop、zookeeper DataNode、NodeManager、JournalNode、QuorumPeerMain nongyt07 192.168.1.207 jdk、hadoop、zookeeper DataNode、NodeManager、JournalNode、QuorumPeerMain 说明：1.在hadoop2.0中通常由两个NameNode组成，一个处于active状态，另一个处于standby状态。Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步active namenode的状态，以便能够在它失败时快速进行切换。hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode这里还配置了一个zookeeper集群，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode为standby状态 2.hadoop-2.2.0中依然存在一个问题，就是ResourceManager只有一个，存在单点故障，hadoop-2.4.1解决了这个问题，有两个ResourceManager，一个是Active，一个是Standby，状态由zookeeper进行协调 安装步骤：1.安装配置zooekeeper集群（在nongyt05上）1.1解压 tar -zxvf zookeeper-3.4.5.tar.gz -C /nongyt/ 1.2修改配置 cd /nongyt/zookeeper-3.4.5/conf/ cp zoo_sample.cfg zoo.cfg vim zoo.cfg 修改：dataDir=/nongyt/zookeeper-3.4.5/tmp 在最后添加： server.1=nongyt05:2888:3888 server.2=nongyt06:2888:3888 server.3=nongyt07:2888:3888 保存退出 然后创建一个tmp文件夹 mkdir /nongyt/zookeeper-3.4.5/tmp 再创建一个空文件 touch /nongyt/zookeeper-3.4.5/tmp/myid 最后向该文件写入ID echo 1 &gt; /nongyt/zookeeper-3.4.5/tmp/myid 1.3将配置好的zookeeper拷贝到其他节点(首先分别在nongyt06、nongyt07根目录下创建一个nongyt目录：mkdir /nongyt) scp -r /nongyt/zookeeper-3.4.5/ nongyt06:/nongyt/ scp -r /nongyt/zookeeper-3.4.5/ nongyt07:/nongyt/ 注意：修改nongyt06、nongyt07对应/nongyt/zookeeper-3.4.5/tmp/myid内容 nongyt06： echo 2 &gt; /nongyt/zookeeper-3.4.5/tmp/myid nongyt07： echo 3 &gt; /nongyt/zookeeper-3.4.5/tmp/myid 2.安装配置hadoop集群（在nongyt01上操作） 2.1解压 tar -zxvf hadoop-2.4.1.tar.gz -C /nongyt/ 2.2配置HDFS（hadoop2.0所有的配置文件都在$HADOOP_HOME/etc/hadoop目录下） #将hadoop添加到环境变量中 vim /etc/profile export JAVA_HOME=/usr/java/jdk1.7.0_55 export HADOOP_HOME=/nongyt/hadoop-2.4.1 export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin #hadoop2.0的配置文件全部在$HADOOP_HOME/etc/hadoop下 cd /nongyt/hadoop-2.4.1/etc/hadoop 2.2.1修改hadoo-env.sh export JAVA_HOME=/usr/java/jdk1.7.0_55 2.2.2修改core-site.xml &lt;configuration&gt; &lt;!-- 指定hdfs的nameservice为ns1 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop临时目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/nongyt/hadoop-2.4.1/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper地址 --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.3修改hdfs-site.xml &lt;configuration&gt; &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt; &lt;value&gt;nongyt01:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt; &lt;value&gt;nongyt01:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt; &lt;value&gt;nongyt02:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- nn2的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt; &lt;value&gt;nongyt02:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://nongyt05:8485;nongyt06:8485;nongyt07:8485/ns1&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/nongyt/hadoop-2.4.1/journal&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启NameNode失败自动切换 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置失败自动切换实现方式 --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt; sshfence shell(/bin/true) &lt;/value&gt; &lt;/property&gt; &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置sshfence隔离机制超时时间 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.4修改mapred-site.xml &lt;configuration&gt; &lt;!-- 指定mr框架为yarn方式 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.5修改yarn-site.xml &lt;configuration&gt; &lt;!-- 开启RM高可靠 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的cluster id --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 分别指定RM的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;nongyt03&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;nongyt04&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zk集群地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 2.2.6修改slaves(slaves是指定子节点的位置，因为要在nongyt01上启动HDFS、在nongyt03启动yarn，所以nongyt01上的slaves文件指定的是datanode的位置，nongyt03上的slaves文件指定的是nodemanager的位置) nongyt05 nongyt06 nongyt07 2.2.7配置免密码登陆 #首先要配置nongyt01到nongyt02、nongyt03、nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆 #在nongyt01上生产一对钥匙 ssh-keygen -t rsa #将公钥拷贝到其他节点，包括自己 ssh-coyp-id nongyt01 ssh-coyp-id nongyt02 ssh-coyp-id nongyt03 ssh-coyp-id nongyt04 ssh-coyp-id nongyt05 ssh-coyp-id nongyt06 ssh-coyp-id nongyt07 #配置nongyt03到nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆 #在nongyt03上生产一对钥匙 ssh-keygen -t rsa #将公钥拷贝到其他节点 ssh-coyp-id nongyt04 ssh-coyp-id nongyt05 ssh-coyp-id nongyt06 ssh-coyp-id nongyt07 #注意：两个namenode之间要配置ssh免密码登陆，别忘了配置nongyt02到nongyt01的免登陆 在nongyt02上生产一对钥匙 ssh-keygen -t rsa ssh-coyp-id -i nongyt01 2.4将配置好的hadoop拷贝到其他节点 scp -r /nongyt/ nongyt02:/ scp -r /nongyt/ nongyt03:/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt04:/nongyt/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt05:/nongyt/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt06:/nongyt/ scp -r /nongyt/hadoop-2.4.1/ root@nongyt07:/nongyt/ ###注意：严格按照下面的步骤 2.5启动zookeeper集群（分别在nongyt05、nongyt06、tcast07上启动zk） cd /nongyt/zookeeper-3.4.5/bin/ ./zkServer.sh start #查看状态：一个leader，两个follower ./zkServer.sh status 2.6启动journalnode（分别在在nongyt05、nongyt06、tcast07上执行） cd /nongyt/hadoop-2.4.1 sbin/hadoop-daemon.sh start journalnode #运行jps命令检验，nongyt05、nongyt06、nongyt07上多了JournalNode进程 2.7格式化HDFS #在nongyt01上执行命令: hdfs namenode -format #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/nongyt/hadoop-2.4.1/tmp，然后将/nongyt/hadoop-2.4.1/tmp拷贝到nongyt02的/nongyt/hadoop-2.4.1/下。 scp -r tmp/ nongyt02:/nongyt/hadoop-2.4.1/ 2.8格式化ZK(在nongyt01上执行即可) hdfs zkfc -formatZK 2.9启动HDFS(在nongyt01上执行) sbin/start-dfs.sh 2.10启动YARN(#####注意#####：是在nongyt03上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动) sbin/start-yarn.sh 到此，hadoop-2.4.1配置完毕，可以统计浏览器访问: http://192.168.1.201:50070 NameNode &apos;nongyt01:9000&apos; (active) http://192.168.1.202:50070 NameNode &apos;nongyt02:9000&apos; (standby) 验证HDFS HA 首先向hdfs上传一个文件 hadoop fs -put /etc/profile /profile hadoop fs -ls / 然后再kill掉active的NameNode kill -9 &lt;pid of NN&gt; 通过浏览器访问：http://192.168.1.202:50070 NameNode &apos;nongyt02:9000&apos; (active) 这个时候nongyt02上的NameNode变成了active 在执行命令： hadoop fs -ls / -rw-r--r-- 3 root supergroup 1926 2014-02-06 15:36 /profile 刚才上传的文件依然存在！！！ 手动启动那个挂掉的NameNode sbin/hadoop-daemon.sh start namenode 通过浏览器访问：http://192.168.1.201:50070 NameNode &apos;nongyt01:9000&apos; (standby) 验证YARN： 运行一下hadoop提供的demo中的WordCount程序： hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /out OK，大功告成！！！ zookeeper配置文件详解zookeeper的默认配置文件为zookeeper/conf/zoo_sample.cfg，需要将其修改为zoo.cfg。其中各配置项的含义，解释如下： 1.tickTime：CS通信心跳时间Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。tickTime=2000 2.initLimit：LF初始通信时限集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。initLimit=5 3.syncLimit：LF同步通信时限集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。syncLimit=2 4.dataDir：数据文件目录Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。dataDir=/home/michael/opt/zookeeper/data 5.clientPort：客户端连接端口客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。clientPort=2181 6.服务器名称与地址： 集群信息（服务器编号，服务器地址，LF通信端口，选举端口） 这个配置项的书写格式比较特殊，规则如下： server.N=YYY:A:B server.1=nongyt05:2888:3888 server.2=nongyt06:2888:3888 server.3=nongyt07:2888:3888","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://tokerr.github.io/tags/zookeeper/"},{"name":"cluster","slug":"cluster","permalink":"https://tokerr.github.io/tags/cluster/"}]},{"title":"Linux下tomcat启动慢的问题","slug":"Linux下tomcat启动慢的问题","date":"2017-10-24T14:37:32.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/10/24/Linux下tomcat启动慢的问题/","link":"","permalink":"https://tokerr.github.io/2017/10/24/Linux下tomcat启动慢的问题/","excerpt":"有两种解决办法：1）在Tomcat环境中解决 可以通过配置JRE使用非阻塞的Entropy Source。在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。","text":"有两种解决办法：1）在Tomcat环境中解决 可以通过配置JRE使用非阻塞的Entropy Source。在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。2）在JVM环境中解决 打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容：securerandom.source=file:/dev/urandom替换成securerandom.source=file:/dev/./urandom 彻底解决“Linux下的所有应用程序产生随机数都会用到这个，所以不仅仅是Tomcat可能被 阻塞 。如果你搜索会发现Apache、Nginx、OpenSSL都被这个问题坑过.”由于《彻底找到Tomcat启动速度慢的元凶》这篇原文网上被引用过多，我也分不清那个是原文，所以此处就不贴原文地址了，大家可自行百度关键字：彻底找到Tomcat启动速度慢的元凶","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://tokerr.github.io/tags/tomcat/"}]},{"title":"HDFS架构及其执行原理","slug":"HDFS架构极其执行原理","date":"2017-10-18T09:18:35.000Z","updated":"2019-05-01T13:51:07.472Z","comments":true,"path":"2017/10/18/HDFS架构极其执行原理/","link":"","permalink":"https://tokerr.github.io/2017/10/18/HDFS架构极其执行原理/","excerpt":"一、前言：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。 1.1、名词复习 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统） 内部主从结构 •主节点，只有一个: namenode •从节点，有很多个: datanode namenode负责：","text":"一、前言：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。 1.1、名词复习 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统） 内部主从结构 •主节点，只有一个: namenode •从节点，有很多个: datanode namenode负责： 接收用户操作请求 维护文件系统的目录结构 管理文件与block之间关系，block与datanode之间关系 datanode负责： 存储文件 文件被分成block存储在磁盘上 为保证数据安全，文件会有多个副本 备注：还有另外一个SecondaryNameNode，作为NameNode的辅助组件，但是不能替代NameNode，下面会简单的介绍。 1.2、Hadoop1.0和hadop2.0的对比 二、分布式文件系统与HDFS 数据量越来越多，在一个操作系统管辖的范围存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，因此迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统 。 是一种允许文件通过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。 通透性。让实际上是通过网络来访问文件的动作，由程序与用户看来，就像是访问本地的磁盘一般。 容错。即使系统中有某些节点脱机，整体来说系统仍然可以持续运作而不会有数据损失。 分布式文件管理系统很多，hdfs只是其中一种。适用于一次写入多次查询的情况，不支持并发写情况，小文件不合适。 三、HDFS体系结构与基本概念3.1 HDFS架构包括NameNode，DataNode，Secondary NameNode 3.2 原理图 3.3 NameNode是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求。 文件包括(hdfs-site.xml的dfs.name.dir属性)： fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。 edits:操作日志文件。 fstime:保存最近一次checkpoint的时间 以上这些文件是保存在linux的文件系统中。 NameNode工作特点： Namenode始终在内存中保存metedata，用于处理“读请求” 到有“写请求”到来时，namenode会首先写editlog到磁盘，即向edits文件中写日志，成功返回后，才会修改内存，并且向客户端返回 Hadoop会维护一个fsimage文件，也就是namenode中metedata的镜像，但是fsimage不会随时与namenode内存中的metedata保持一致，而是每隔一段时间通过合并edits文件来更新内容。Secondary namenode就是用来合并fsimage和edits文件来更新NameNode的metedata的。 3.4 SecondaryNameNode HA的一个解决方案。但不支持热备。配置即可。 执行过程：从NameNode上下载元数据信息（fsimage,edits），然后把二者合并，生成新的fsimage，在本地保存，并将其推送到NameNode，替换旧的fsimage. 默认在安装在NameNode节点上，但这样…不安全！ SecondaryNameNode工作流程： secondary通知namenode切换edits文件 secondary从namenode获得fsimage和edits(通过http) secondary将fsimage载入内存，然后开始合并edits secondary将新的fsimage发回给namenode namenode用新的fsimage替换旧的fsimage 下图是NameNode和SecondaryNameNode工作相互协调的过程： 3.5 DataNode 提供真实文件数据的存储服务。 文件块（block）：最基本的存储单位。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB，以一个256MB文件，共有256/128=2个Block. 不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间 Replication。多复本。默认是三个。 四、HDFS的shell操作 调用文件系统(FS)Shell命令应使用bin/hadoop fs 的形式。 所有的FS shell命令使用URI路径作为参数。 URI格式是scheme://authority/。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。 例如：/parent/child可以表示成hdfs://namenode:namenodePort/parent/child，或者更简单的/parent/child（假设配置文件是namenode:namenodePort） 大多数FS Shell命令的行为和对应的Unix Shell命令类似。 HDFS fs命令 -help [cmd] //显示命令的帮助信息 -ls(r) &lt;path&gt; //显示当前目录下所有文件 -du(s) &lt;path&gt; //显示目录中所有文件大小 -count[-q] &lt;path&gt; //显示目录中文件数量 -mv &lt;src&gt; &lt;dst&gt; //移动多个文件到目标目录 -cp &lt;src&gt; &lt;dst&gt; //复制多个文件到目标目录 -rm(r) //删除文件(夹) -put &lt;localsrc&gt; &lt;dst&gt; //本地文件复制到hdfs -copyFromLocal //同put -moveFromLocal //从本地文件移动到hdfs -get [-ignoreCrc] &lt;src&gt; &lt;localdst&gt; //复制文件到本地，可以忽略crc校验 -getmerge &lt;src&gt; &lt;localdst&gt; //将源目录中的所有文件排序合并到一个文件中 -cat &lt;src&gt; //在终端显示文件内容 -text &lt;src&gt; //在终端显示文件内容 -copyToLocal [-ignoreCrc] &lt;src&gt; &lt;localdst&gt; //复制到本地 -moveToLocal &lt;src&gt; &lt;localdst&gt; -mkdir &lt;path&gt; //创建文件夹 -touchz &lt;path&gt; //创建一个空文件","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"HDFS","slug":"HDFS","permalink":"https://tokerr.github.io/tags/HDFS/"},{"name":"YARN","slug":"YARN","permalink":"https://tokerr.github.io/tags/YARN/"}]},{"title":"Shuffle工作机制","slug":"Shuffle工作机制","date":"2017-10-16T15:41:34.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/10/16/Shuffle工作机制/","link":"","permalink":"https://tokerr.github.io/2017/10/16/Shuffle工作机制/","excerpt":"一、前言&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。 二、什么是Shuffle?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。","text":"一、前言&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。 二、什么是Shuffle?&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。 三、Shuffle工作机制：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从map端的输出开始。map函数开始产生输出时，不是简单地将它写到磁盘。这个过程更复杂，它利用缓冲的方式写到内存，井出于效率的考虑进行预排序。下图展示了这个过程每个map任务都有一个环形内存缓冲区，用于存储任务的输出。默认情况下，缓冲区的大为100MB，此值可以通过改变io.sort.mb属性来调整。一旦缓冲内容达到闹值(io.sort.spill.percent，默认为0.80，或80%)，一个后台线程便开始把内容写到(spill)磁盘中。在写磁盘过程中，map输出继续被写到缓冲区，但如果在此期间缓冲区被填楠，map会阻塞直到写磁盘过程完成。写磁盘将按轮询方式写到mapred.local.dir属性指定的作业特定子目录中的目录中。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在map输出写磁盘之前，线程首先根据数据最终要传送到的reducer把数据划分成相应的分区(partition)。在每个分区中，后台线程按键进行内排序，如果有一个combiner，它会在排序后的输出上运行。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦内存缓冲区达到溢出写的阀值，就会新建一个溢出写文件，因此在map任务写完其最后一个输出记录之后，会有几个溢出写文件。在任务完成之前，溢出写文件被合并成一个已分区且已排序的输出文件。配置属性io.sort.factor控制着一次最多能合并多少流，默认值是10.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果已经指定combiner，并且溢出写次数至少为3(min.num.spills.for.combine属性的取值)肘，则combiner就会在输出文件写到磁盘之前运行。combiner可以在输入上反复运行，如果combiner可拔插，添加Combiner绝不能改变最终的计算结果;不排除使用combiner作为在map端过滤数据的用途，比如空字符串或者其他无效的参数，这会影响reducer的计算结果。运行combiner的意义在于使map输出更紧凑，使得写到本地磁盘和传给reducer的数据更少。写盘时压缩map输出可以提高效率，因为这样会让写磁盘的速度更快，节约磁盘空间，并且减少传给reducer的数据量。默认情况下，输出是不压缩的，但只要将mapred.compress.map.output设置为true，就可以启用此功能。使用的压缩库库mapred.map.output.compression.codec指定.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，reducer通过HTTP方式得到输出文件的分区。","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://tokerr.github.io/tags/hadoop/"},{"name":"MapReducer","slug":"MapReducer","permalink":"https://tokerr.github.io/tags/MapReducer/"},{"name":"Shuffle","slug":"Shuffle","permalink":"https://tokerr.github.io/tags/Shuffle/"}]},{"title":"Jquery防止Ajax重复提交解决方案","slug":"Jquery防止Ajax重复提交解决方案","date":"2017-10-09T15:15:34.000Z","updated":"2019-05-01T13:51:07.474Z","comments":true,"path":"2017/10/09/Jquery防止Ajax重复提交解决方案/","link":"","permalink":"https://tokerr.github.io/2017/10/09/Jquery防止Ajax重复提交解决方案/","excerpt":"一、前言不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。 二、直接上代码/** * jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理 */ $(function(){ var pendingRequests = {}; // 所有ajax请求的通用前置filter $.ajaxPrefilter(function( options, originalOptions, jqXHR ) { var key = generatePendingRequestKey(options);","text":"一、前言不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。 二、直接上代码/** * jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理 */ $(function(){ var pendingRequests = {}; // 所有ajax请求的通用前置filter $.ajaxPrefilter(function( options, originalOptions, jqXHR ) { var key = generatePendingRequestKey(options); //请求是否已经存在 if(!pendingRequests[key]){ storePendingRequest(key,jqXHR); }else{ //如果ajax请求已经存在，下一次相同的请求则取消，防止重复请求 jqXHR.abort(); } //ajax请求完成时，从临时对象中清除请求对应的数据 var complete = options.complete; options.complete = function(jqXHR, textStatus) { //延时1000毫秒删除请求信息，表示同Key值请求不能在此时间段内重复提交 setTimeout(function(){ delete pendingRequests[jqXHR.pendingRequestKey]; },1000); if ($.isFunction(complete)) { complete.apply(this, arguments); } }; //统一的错误处理 var error = options.error; options.error = function(jqXHR, textStatus) { errorHandler(jqXHR, textStatus); if ($.isFunction(error)) { error.apply(this, arguments); } }; }); /** * 当ajax请求发生错误时，统一进行拦截处理的方法 */ function errorHandler(jqXHR, textStatus){ switch (jqXHR.status){ case(500): internalError(jqXHR); break; case(403): accessDenied(jqXHR); break; case(408): timeoutError(jqXHR); break; case(404): pageNotFound(jqXHR); break; default: //otherError(jqXHR, textStatus); } } function pageNotFound(jqXHR){ Component.warningMessageBox({ content:&quot;请求访问的地址或内容不存在！&quot; }); } function accessDenied(jqXHR){ Component.warningMessageBox({ content:&quot;你无权进行此操作或页面访问！&quot; }); } function internalError(jqXHR){ Component.warningMessageBox({ content:&quot;服务器存在错误，未能正确处理你的请求！&quot; }); } function timeoutError(jqXHR){ window.location.href=contextPath + &quot;/j_spring_security_logout&quot;; } function otherError(jqXHR, textStatus){ Component.warningMessageBox({ content:&quot;未知错误，错误代码：&quot; + textStatus }); } /** * 将ajax请求存储到临时对象中，用于根据key判断请求是否已经存在 */ function storePendingRequest(key, jqXHR){ pendingRequests[key] = jqXHR; jqXHR.pendingRequestKey = key; } /** * 根据ajax请求参数构建一个临时存储key,此处简单的使用url作为key， * 不考虑为解决请求类型为get时相同路径引起的缓存问题，采用随机码构建URL的情况 */ function generatePendingRequestKey(options){ return options.url; } });","categories":[],"tags":[{"name":"jquery","slug":"jquery","permalink":"https://tokerr.github.io/tags/jquery/"},{"name":"ajax","slug":"ajax","permalink":"https://tokerr.github.io/tags/ajax/"}]},{"title":"子查询的方式实现sql语句的先排序后分组","slug":"子查询的方式实现sql语句的先排序后分组","date":"2017-06-22T13:18:36.000Z","updated":"2019-05-01T13:51:07.479Z","comments":true,"path":"2017/06/22/子查询的方式实现sql语句的先排序后分组/","link":"","permalink":"https://tokerr.github.io/2017/06/22/子查询的方式实现sql语句的先排序后分组/","excerpt":"需求：查询学生表当中每一门课程成绩最高的记录。 思路：先按分数对记录进行降序，然后按照课程进行分组即可实现。","text":"需求：查询学生表当中每一门课程成绩最高的记录。 思路：先按分数对记录进行降序，然后按照课程进行分组即可实现。Student表结构： 现在手动添加如下数据进去： 起初，按照原来的思路，我编写的sql语句如下图(第一句)，得到的结果却不是我们想要的，可以看到group by字句先于Order by执行了，效果如图(下一部分)： 因此，使用子查询的方式先对数据进行降序，对新的结果集给一个别名，然后再按课程进行分组，如下：","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://tokerr.github.io/tags/sql/"}]},{"title":"String类型两种创建对象的方式的内存分配","slug":"String类型两种创建对象的方式的内存分配","date":"2017-06-04T15:25:47.000Z","updated":"2019-05-01T13:51:07.476Z","comments":true,"path":"2017/06/04/String类型两种创建对象的方式的内存分配/","link":"","permalink":"https://tokerr.github.io/2017/06/04/String类型两种创建对象的方式的内存分配/","excerpt":"","text":"一张图就可以看明白","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"String","slug":"String","permalink":"https://tokerr.github.io/tags/String/"}]},{"title":"Java运行时异常和非运行时异常","slug":"Java运行时异常和非运行时异常","date":"2017-05-28T02:21:04.000Z","updated":"2019-05-01T13:51:07.474Z","comments":true,"path":"2017/05/28/Java运行时异常和非运行时异常/","link":"","permalink":"https://tokerr.github.io/2017/05/28/Java运行时异常和非运行时异常/","excerpt":"1.Java异常机制Java把异常当做对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。Java中的异常分为两大类：错误Error和异常Exception，Java异常体系结构如下图所示： 2.ThrowableThrowable类是所有异常或错误的超类，它有两个子类：Error和Exception，分别表示错误和异常。其中异常Exception分为运行时异常(RuntimeException)和非运行时异常，也称之为不检查异常(Unchecked Exception)和检查异常(Checked Exception)。 3.Error一般是指java虚拟机相关的问题，如系统崩溃、虚拟机出错误、动态链接失败等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常应用程序无法处理这些错误，因此应用程序不应该捕获Error对象，也无须在其throws子句中声明该方法抛出任何Error或其子类。","text":"1.Java异常机制Java把异常当做对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。Java中的异常分为两大类：错误Error和异常Exception，Java异常体系结构如下图所示： 2.ThrowableThrowable类是所有异常或错误的超类，它有两个子类：Error和Exception，分别表示错误和异常。其中异常Exception分为运行时异常(RuntimeException)和非运行时异常，也称之为不检查异常(Unchecked Exception)和检查异常(Checked Exception)。 3.Error一般是指java虚拟机相关的问题，如系统崩溃、虚拟机出错误、动态链接失败等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常应用程序无法处理这些错误，因此应用程序不应该捕获Error对象，也无须在其throws子句中声明该方法抛出任何Error或其子类。 4.可查异常和不可查异常通常，Java的异常(包括Exception和Error)分为可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）。可查异常（编译器要求必须处置的异常）：正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。不可查异常(编译器不要求强制处置的异常):包括运行时异常（RuntimeException与其子类）和错误（Error）。如果使用throw在方法体中抛出可查异常，则需要在方法头部声明方法可能抛出的异常类型。程序会在throw语句后立即终止，它后面的语句执行不到，然后在包含它的所有try块中（可能在上层调用函数中）从里向外寻找含有与其匹配的catch子句的try块。 5.运行时异常和非运行时异常(1)运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。当出现RuntimeException的时候，我们可以不处理。当出现这样的异常时，总是由虚拟机接管。比如：我们从来没有人去处理过NullPointerException异常，它就是运行时异常，并且这种异常还是最常见的异常之一。出现运行时异常后，如果没有捕获处理这个异常（即没有catch），系统会把异常一直往上层抛，一直到最上层，如果是多线程就由Thread.run()抛出，如果是单线程就被main()抛出。抛出之后，如果是线程，这个线程也就退出了。如果是主程序抛出的异常，那么这整个程序也就退出了。运行时异常是Exception的子类，也有一般异常的特点，是可以被catch块处理的。只不过往往我们不对他处理罢了。也就是说，你如果不对运行时异常进行处理，那么出现运行时异常之后，要么是线程中止，要么是主程序终止。如果不想终止，则必须捕获所有的运行时异常，决不让这个处理线程退出。队列里面出现异常数据了，正常的处理应该是把异常数据舍弃，然后记录日志。不应该由于异常数据而影响下面对正常数据的处理。 (2)非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。如IOException、SQLException等以及用户自定义的Exception异常。对于这种异常，JAVA编译器强制要求我们必需对出现的这些异常进行catch并处理，否则程序就不能编译通过。所以，面对这种异常不管我们是否愿意，只能自己去写一大堆catch块去处理可能的异常。 6.finally关键字来看看下面这个test1()方法： public int test1() { try { return 1; } finally { return 2; } } 方法test1将返回2； 怎么解释呢？再来看看下面这个test2()方法： public int test2() { int i = 1; try { System.out.println(&quot;try语句块中&quot;); return 1; } finally { System.out.println(&quot;finally语句块中&quot;); return 2; } } 运行结果是： try语句块中 finally语句块中 2 从运行结果中可以发现，try中的return语句调用的函数先于finally中调用的函数执行，也就是说return语句先执行，finally语句后执行，所以，返回的结果是2。return并不是让函数马上返回，而是return语句执行后，将把返回结果放置进函数栈中，此时函数并不是马上返回，它要执行finally语句后才真正开始返回。 常见RuntimeException：ArrayStoreException 试图将错误类型的对象存储到一个对象数组时抛出的异常 ClassCastException 试图将对象强制转换为不是实例的子类时，抛出该异常 IllegalArgumentException 抛出的异常表明向方法传递了一个不合法或不正确的参数 IndexOutOfBoundsException 指示某排序索引（例如对数组、字符串或向量的排序）超出范围时抛出 NoSuchElementException 表明枚举中没有更多的元素 NullPointerException 当应用程序试图在需要对象的地方使用 null 时，抛出该异常","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"exception","slug":"exception","permalink":"https://tokerr.github.io/tags/exception/"},{"name":"异常","slug":"异常","permalink":"https://tokerr.github.io/tags/异常/"}]},{"title":"mybatis连接oracle执行sql语句出现ORA-00904: invalid identifier","slug":"mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier","date":"2017-05-07T10:03:30.000Z","updated":"2019-05-01T13:51:07.477Z","comments":true,"path":"2017/05/07/mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier/","link":"","permalink":"https://tokerr.github.io/2017/05/07/mybatis连接oracle执行sql语句出现ORA-00904-invalid-identifier/","excerpt":"一、总结使用mybatis连接oracle数据库进行查询，最好确保表命全大写，否者会出现ORA-00904: invalid identifier的问题 注：本人使用的mybatis版本是3.0.5 二、问题描述： 我使用ibator工具产生的代码，有一个Dao的测试类，但是一执行就出现了ORA-00904: invalid identifier，如图：","text":"一、总结使用mybatis连接oracle数据库进行查询，最好确保表命全大写，否者会出现ORA-00904: invalid identifier的问题 注：本人使用的mybatis版本是3.0.5 二、问题描述： 我使用ibator工具产生的代码，有一个Dao的测试类，但是一执行就出现了ORA-00904: invalid identifier，如图： 原因分析，大部分情况下是由于引用了不存在的列名导致的。 解决的办法就是检查自己引用的列名称是否一致。对于某些工具生成的sql，可能导致列名称和期望不符的情况，比如，有些工具生成的列名称会带双引号，从而导致此错误。 经过查询和本人的实践验证，oracle执行查询时（这里以11g为例），对于特殊的字段命名有着非常严格的语法要求，如果是字段名称按照单词首字母大写的规范进行命名，在进行条件查询的时候必须，字段名称必须与原来命名一样并且要加上双引号，否则会包ORA-00904: invalid identifier。以下是本案例的测试截图： 表结构： 执行查询： 从执行的结果可以知道，最终oracle在执行sql语句的时候把条件查询的字段名转成了全大写，遇到表中没有找到相关的字段(区分大小写)，就出现了此错误。查询指定字段的值也是如此： 表结构： 执行查询： 三、解决办法总结： 3.1oracle在执行sql语句进行查询的时候，默认的情况下(查询的时候不给字段加双引号)，会将字段名称转换成全大写之后再到表中进行匹配查询，比如：执行select from dept where id=1，则实际执行的是:select from DEPT where ID=1，这里表名和字段名全部都会转成全大写去匹配查询，一旦匹配不到(真正匹配字段名和名的时候区分大小写)，则会报错误。 3.2如果设计表的时候不想表名和字段名都全大写，则在进行查询的时候需要在表名或者字段名称加上双引号(相当于告知oracle不要对sql语句中指定的表名或者字段名转成全大写)，并且区分大小写，这样执行查询才不会发生错误。 ##解决方法##因此解决的办法就是，在给字段名称进行命名的时候，建议全大写，对于表名也是全大写命名，这样不管是进行条件查询还是查询指定字段的名称的时候，都不需要严格区分大小写了并且还要加上双引号了，Oracle会自动帮你先转成全大写之后再进行匹配查询。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://tokerr.github.io/tags/mybatis/"},{"name":"oracle","slug":"oracle","permalink":"https://tokerr.github.io/tags/oracle/"}]},{"title":"使用ibator无法根据oracle数据库中的表结构产生代码[解决方法]","slug":"关于使用ibator工具连接oracle数据库生成代码的使用问题","date":"2017-05-06T11:11:35.000Z","updated":"2019-05-01T13:51:07.479Z","comments":true,"path":"2017/05/06/关于使用ibator工具连接oracle数据库生成代码的使用问题/","link":"","permalink":"https://tokerr.github.io/2017/05/06/关于使用ibator工具连接oracle数据库生成代码的使用问题/","excerpt":"一、总结使用ibator根据oracle中的表结构生成代码时，一定要确保每张表的表命全大写，否则生成失败 二、问题描述想说的已经在上面描述出来了。下面描述问题的由来已经解决的过程： 就是下面这个工具，我已经集成到了Myeclipse当中","text":"一、总结使用ibator根据oracle中的表结构生成代码时，一定要确保每张表的表命全大写，否则生成失败 二、问题描述想说的已经在上面描述出来了。下面描述问题的由来已经解决的过程： 就是下面这个工具，我已经集成到了Myeclipse当中 以前开始使用的都是mysql数据库，表的名称都是按照首字母大写的规范进行设计，这次的毕业设计项目使用到的是oracle，因为设计表的时候表明也是按照每个单词的首字母大写进行命名的，但是没想到，在使用ibator代码生成器生成pojo 的时候，居然失败的，而且这个问题一直困扰了我一个多月，并且百度谷歌搜索都无果，让我百思不得其解。直到今天在做毕业设计的时候，终于让我把这个问题解决了。 万幸在于，让我发现突破这个问题的关键只所在，在某一次使用这个工具对oracle中的某一张表进行操作的时候成功了(这是在本地真机上的oracle)。之前我把oracle服务器安装在电脑的虚拟机，装的是oracle10g，在使用ibator就出现了这个问题，一直怀疑是可能是因为远程的问题，或者oracle是10G不是oracle11g的版本问题，我就在真机上面装了个oracle11g的数据库，测试的时候自己阴差阳错，建表的sql语句是网上复制过来了，并且表明刚好是全大写，因此那一次就测试成功了。但今天在真机的数据库建表，表名按照单词的首字母大写命名，因此又出现了这个问题。但幸好，经过一番测试对比，终于发现原因之所在，可以说是ibator这个工具的bug吧。 另外，个人惰性思维一发作，真的是可以让人变傻。只通过自己的怀疑推测，而没有经过实践的检验，就下定结论，这是我在这个问题上思维懒惰的一个很好体现，自己下定论千万不要去推测去瞎猜，一定是要在经过实际的检验之后。另一方面是要多思考，出现这个问题的时候我就是怀疑，是因为远程的原因 或者是因为oracle版本的原因，思维懒惰的结果就是我把自己的猜测当成了自己的结论，并以此去指导自己的行为(觉得自己好悲催，问题很严重)，而从没有进一步想过，之前公司的项目也是远程的Mysql数据库使用ibator生成代码的，使用没有问题，这样就可以排除是因为远程的问题导致ibator不可以用了呀；还有怀疑是因为数据库版本的问题，竟然数据库已经成功安装，可以整成使用，跟版本有多大的联系吗？这点就不能排除了，呵呵。 总之，在使用ibator获取oracle中的表结果生成代码时，一定要确保表名全大写；字段名称的命名的话，经过我的测验，字段名称全大写或者按照单词首字母大写的方式命名也是没有问题的，最终生成的pojo属性名都是全小写。 三、关于ibator集成到myeclipse直接把截图上面的两个文件扔到myeclipse安装目录下的dropins文件夹就可以了，这里提供文件的连接，我都已经打包到一起了，解压即可。点我下载","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://tokerr.github.io/tags/mybatis/"},{"name":"oracle","slug":"oracle","permalink":"https://tokerr.github.io/tags/oracle/"},{"name":"ibator","slug":"ibator","permalink":"https://tokerr.github.io/tags/ibator/"}]},{"title":"ORA-12541:TNS:无监听程序","slug":"ORA-12541-TNS-无监听程序","date":"2017-05-06T01:43:13.000Z","updated":"2019-05-01T13:51:07.475Z","comments":true,"path":"2017/05/06/ORA-12541-TNS-无监听程序/","link":"","permalink":"https://tokerr.github.io/2017/05/06/ORA-12541-TNS-无监听程序/","excerpt":"一、问题描述这两天在做毕业设计，项目用到的是oracle数据库，由于之前用的都是mysql，oracle数据库的应用比较少。于是莫名奇妙的出现了个‘ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务’，也是折腾了两天，无果，今天接着是‘ORA-12541:TNS:无监听程序’，在windows系统的cmd上不使用实例名连接倒是可以登录，但是无法进行正常的查询操作。今天按照网上某篇博客的教程，居然把这个问题解决了，关键的一步是 启动tnslsnr，然后问题就解决了。 其实在今天电脑开始之后，我直接把360安全卫士关闭了，不排除oracle在开机 的时候某些服务被360拦截关闭的情况。 二、附上cmd的操作日志C:\\Users\\Administrator&gt;sqlplus / as sysdba","text":"一、问题描述这两天在做毕业设计，项目用到的是oracle数据库，由于之前用的都是mysql，oracle数据库的应用比较少。于是莫名奇妙的出现了个‘ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务’，也是折腾了两天，无果，今天接着是‘ORA-12541:TNS:无监听程序’，在windows系统的cmd上不使用实例名连接倒是可以登录，但是无法进行正常的查询操作。今天按照网上某篇博客的教程，居然把这个问题解决了，关键的一步是 启动tnslsnr，然后问题就解决了。 其实在今天电脑开始之后，我直接把360安全卫士关闭了，不排除oracle在开机 的时候某些服务被360拦截关闭的情况。 二、附上cmd的操作日志C:\\Users\\Administrator&gt;sqlplus / as sysdba SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:23:15 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; conn tokerr/tokerr 已连接。 SQL&gt; SQL&gt; select table_name from user_tables; TABLE_NAME ------------------------------------------------------------ TESTTABLE1 TESTTABLE2 TESTTABLE3 TESTTABLE4 TESTTABLE5 SQL&gt; select * form TESTTABLE1; select * form TESTTABLE1 * 第 1 行出现错误: ORA-00923: 未找到要求的 FROM 关键字 SQL&gt; select * fROM TESTTABLE1; 未选定行 SQL&gt; select * fROM TESTTABLE2; 未选定行 SQL&gt; select * fROM TESTTABLE3; 未选定行 SQL&gt; exit 从 Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开 C:\\Users\\Administrator&gt;sqlplus tokerr/tokerr@orcl SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:27:17 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. ERROR: ORA-12541: TNS: 无监听程序 请输入用户名: C:\\Users\\Administrator&gt; C:\\Users\\Administrator&gt;sqlplus / as sysdba SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:37:26 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; startup ORA-01081: 无法启动已在运行的 ORACLE - 请首先关闭它 SQL&gt; 从 Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开 C:\\Users\\Administrator&gt;lsnrctl status LSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:39:09 Copyright (c) 1991, 2010, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误 TNS-00511: 无监听程序 64-bit Windows Error: 2: No such file or directory 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))) TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误 TNS-00511: 无监听程序 64-bit Windows Error: 61: Unknown error C:\\Users\\Administrator&gt;lsnrctl start LSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:39:40 Copyright (c) 1991, 2010, Oracle. All rights reserved. 启动tnslsnr: 请稍候... TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production 系统参数文件为F:\\Ora10InstantClient\\listener.ora 写入f:\\oracledb\\diag\\tnslsnr\\PC-20160512QTJL\\listener\\alert\\log.xml的日志信息 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\\\.\\pipe\\EXTPROC1521ipc))) 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production 启动日期 06-5月 -2017 09:39:46 正常运行时间 0 天 0 小时 0 分 8 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 F:\\Ora10InstantClient\\listener.ora 监听程序日志文件 f:\\oracledb\\diag\\tnslsnr\\PC-20160512QTJL\\listener\\alert\\log.xml 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\\\.\\pipe\\EXTPROC1521ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;CLRExtProc&quot; 包含 1 个实例。 实例 &quot;CLRExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 服务 &quot;orcl&quot; 包含 1 个实例。 实例 &quot;orcl&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 C:\\Users\\Administrator&gt;lsnrctl status LSNRCTL for 64-bit Windows: Version 11.2.0.1.0 - Production on 06-5月 -2017 09:41:30 Copyright (c) 1991, 2010, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 64-bit Windows: Version 11.2.0.1.0 - Production 启动日期 06-5月 -2017 09:39:46 正常运行时间 0 天 0 小时 1 分 48 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 F:\\Ora10InstantClient\\listener.ora 监听程序日志文件 f:\\oracledb\\diag\\tnslsnr\\PC-20160512QTJL\\listener\\alert\\log.xml 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=\\\\.\\pipe\\EXTPROC1521ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;CLRExtProc&quot; 包含 1 个实例。 实例 &quot;CLRExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 服务 &quot;orcl&quot; 包含 1 个实例。 实例 &quot;orcl&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 C:\\Users\\Administrator&gt;sqlplus tokerr/tokerr@orcl SQL*Plus: Release 11.2.0.1.0 Production on 星期六 5月 6 09:41:36 2017 Copyright (c) 1982, 2010, Oracle. All rights reserved. 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; select * from TESTTABLES; select * from TESTTABLES * 第 1 行出现错误: ORA-00942: 表或视图不存在 SQL&gt; select * from TESTTABLE1; 未选定行 SQL&gt; 三、正文在用PL/SQL Developer连接数据库时出现“ORA-12541:TNS:无监听程序”错误。 1、检查listener.log日志发现下面错误： TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:25:26 Copyright (c) 1991, 2005, Oracle. All rights reserved. 系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora 写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息 写入D:/oracle/product/10.2.0/db_1/network/trace/listener.trc的跟踪信息 跟踪级别当前为0 以 pid=1704 开始 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 监听该对象时出错: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521))) TNS-12545: 因目标主机或对象不存在, 连接失败 TNS-12560: TNS: 协议适配器错误 TNS-00515: 因目标主机或对象不存在, 连接失败 32-bit Windows Error: 49: Unknown error 不再监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 2、查看Oracle的listener是否启动C:/Documents and Settings/mengzhaoliang&gt;lsnrctl status LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:5 0:44 Copyright (c) 1991, 2005, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) TNS-12541: TNS: 无监听程序 TNS-12560: TNS: 协议适配器错误 TNS-00511: 无监听程序 32-bit Windows Error: 2: No such file or directory 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521))) TNS-12535: TNS: 操作超时 TNS-12560: TNS: 协议适配器错误 TNS-00505: 操作超时 32-bit Windows Error: 60: Unknown error 原来没有启动listener，用“lsnrctl start”命令也不能启动。 C:/Documents and Settings/mengzhaoliang&gt;lsnrctl start LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:5 2:16 Copyright (c) 1991, 2005, Oracle. All rights reserved. 启动tnslsnr: 请稍候... TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production 系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora 写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 监听该对象时出错: (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=0.5.0.5)(PORT=1521)) ) TNS-12545: 因目标主机或对象不存在, 连接失败 TNS-12560: TNS: 协议适配器错误 TNS-00515: 因目标主机或对象不存在, 连接失败 32-bit Windows Error: 49: Unknown error 监听程序未能启动。请参阅上面的错误消息… 3、查看listener.ora的内容：# listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PLSExtProc) (ORACLE_HOME = D:/oracle/product/10.2.0/db_1) (PROGRAM = extproc) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1)) (ADDRESS = (PROTOCOL = TCP)(HOST = 0.5.0.5)(PORT = 1521)) ) ) 原来本机的ip发生改变后，就出现了上述问题，改变数据库的监听ip地址:把(ADDRESS = (PROTOCOL = TCP)(HOST = 0.5.0.5)(PORT = 1521))改成(ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))127.0.0.1：也就是目前数据库正在用的ip地址。 4、再次启动oracle的listenerC:/Documents and Settings/mengzhaoliang&gt;lsnrctl start LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 10:5 4:40 Copyright (c) 1991, 2005, Oracle. All rights reserved. 启动tnslsnr: 请稍候... TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Production 系统参数文件为D:/oracle/product/10.2.0/db_1/network/admin/listener.ora 写入D:/oracle/product/10.2.0/db_1/network/log/listener.log的日志信息 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) 监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Produ ction 启动日期 20-9月 -2008 10:54:41 正常运行时间 0 天 0 小时 0 分 1 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 D:/oracle/product/10.2.0/db_1/network/admin/listener.o ra 监听程序日志文件 D:/oracle/product/10.2.0/db_1/network/log/listener.log 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;PLSExtProc&quot; 包含 1 个例程。 例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 启动已经成功， 5.再tnsnames.ora上添加上ORCL_127.0.0.1 = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) ) ) 6、再次用PL/SQL Developer再次连接数据库出现下面错误：TNS-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务再次检查listener.log日志 20-9月 -2008 11:01:54 * (CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=orcl)(CID= (PROGRAM=D:/plsql/plsqldev.exe)(HOST=RUIFEI-EF0ADC98)(USER=mengzhaoliang))) * (ADDRESS= (PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1267)) * establish * orcl * 12514 TNS-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务 查看listener： C:/Documents and Settings/mengzhaoliang&gt;lsnrctl services LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:1 1:09 Copyright (c) 1991, 2005, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) 服务摘要.. 服务 &quot;PLSExtProc&quot; 包含 1 个例程。 例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 处理程序: &quot;DEDICATED&quot; 已建立:0 已被拒绝:0 LOCAL SERVER 命令执行成功 7、用sqlplus也出现同样错误：C:/Documents and Settings/mengzhaoliang&gt;sqlplusscott/mzl@ORCL_127.0.0.1 SQL*Plus: Release 10.2.0.1.0 - Production on 星期六 9月 20 11:15:09 2008 Copyright (c) 1982, 2005, Oracle. All rights reserved. ERROR: ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务 8、查看listenser状态：C:/Documents and Settings/mengzhaoliang&gt;lsnrctl status LSNRCTL for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 -2008 11:2 6:42 Copyright (c) 1991, 2005, Oracle. All rights reserved. 正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1))) LISTENER 的 STATUS ------------------------ 别名 LISTENER 版本 TNSLSNR for 32-bit Windows: Version 10.2.0.1.0 - Produ ction 启动日期 20-9月 -2008 11:24:33 正常运行时间 0 天 0 小时 2 分 8 秒 跟踪级别 off 安全性 ON: Local OS Authentication SNMP OFF 监听程序参数文件 D:/oracle/product/10.2.0/db_1/network/admin/listener.o ra 监听程序日志文件 D:/oracle/product/10.2.0/db_1/network/log/listener.log 监听端点概要... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(PIPENAME=//./pipe/EXTPROC1ipc))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) 服务摘要.. 服务 &quot;PLSExtProc&quot; 包含 1 个例程。 例程 &quot;PLSExtProc&quot;, 状态 UNKNOWN, 包含此服务的 1 个处理程序... 命令执行成功 C:/Documents and Settings/mengzhaoliang&gt;tnsping orcl TNS Ping Utility for 32-bit Windows: Version 10.2.0.1.0 - Production on 20-9月 - 2008 11:27:43 Copyright (c) 1997, 2005, Oracle. All rights reserved. 已使用的参数文件: D:/oracle/product/10.2.0/db_1/network/admin/sqlnet.ora TNS-03505: 无法解析名称 9、查看sqlnet.ora内容：# sqlnet.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/sqlnet.ora # Generated by Oracle configuration tools. # This file is actually generated by netca. But if customers choose to # install &quot;Software Only&quot;, this file wont exist and without the native # authentication, they will not be able to connect to the database on NT. SQLNET.AUTHENTICATION_SERVICES= (NTS) NAMES.DIRECTORY_PATH= (TNSNAMES, EZCONNECT) 10.把listener.ora的内容： # listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PLSExtProc) (ORACLE_HOME = D:/oracle/product/10.2.0/db_1) (PROGRAM = extproc) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1)) (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) ) ) 改成下面的内容： # listener.ora Network Configuration File: D:/oracle/product/10.2.0/db_1/network/admin/listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = orcl) (ORACLE_HOME = D:/oracle/product/10.2.0/db_1) # (PROGRAM = extproc) ) ) LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = orcl)) (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) ) ) 11、然后关闭、再启动listener在cmd中执行“lsnrctl stop” 和“lsnrctl stop”命令，再次登陆正常！ C:/Documents and Settings/mengzhaoliang&gt;sqlplus scott/mzl@orcl SQL*Plus: Release 10.2.0.1.0 - Production on 星期六 9月 20 11:55:47 2008 Copyright (c) 1982, 2005, Oracle. All rights reserved. 连接到: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - Production With the Partitioning, OLAP and Data Mining options SQL&gt; 再次用PL/SQL Peveloper登陆就没有问题了。 完毕! 我通过以上步骤我的问题还没解决，然后重启了一下OracleOraDb10g_home1TNSListener服务就行了 原文链接","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://tokerr.github.io/tags/数据库/"},{"name":"Oracle","slug":"Oracle","permalink":"https://tokerr.github.io/tags/Oracle/"}]},{"title":"序列化和反序列化的简单理解","slug":"序列化和反序列化的简单理解","date":"2017-05-05T14:26:32.000Z","updated":"2019-05-01T13:51:07.480Z","comments":true,"path":"2017/05/05/序列化和反序列化的简单理解/","link":"","permalink":"https://tokerr.github.io/2017/05/05/序列化和反序列化的简单理解/","excerpt":"一、序列化和反序列化的概念 把对象转换为字节序列的过程称为对象的序列化。 把字节序列恢复为对象的过程称为对象的反序列化。 对象的序列化主要有两种用途： 1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 2） 在网络上传送对象的字节序列。","text":"一、序列化和反序列化的概念 把对象转换为字节序列的过程称为对象的序列化。 把字节序列恢复为对象的过程称为对象的反序列化。 对象的序列化主要有两种用途： 1） 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 2） 在网络上传送对象的字节序列。 在很多应用中，需要对某些对象进行序列化，让它们离开内存空间，入住物理硬盘，以便长期保存。比如最常见的是Web服务器中的Session对象，当有 10万用户并发访问，就有可能出现10万个Session对象，内存可能吃不消，于是Web容器就会把一些seesion先序列化到硬盘中，等要用了，再把保存在硬盘中的对象还原到内存中。 当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。 二、JDK类库中的序列化API java.io.ObjectOutputStream代表对象输出流，它的writeObject(Object obj)方法可对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中。 java.io.ObjectInputStream代表对象输入流，它的readObject()方法从一个源输入流中读取字节序列，再把它们反序列化为一个对象，并将其返回。 只有实现了Serializable和Externalizable接口的类的对象才能被序列化。Externalizable接口继承自 Serializable接口，实现Externalizable接口的类完全由自身来控制序列化的行为，而仅实现Serializable接口的类可以 采用默认的序列化方式 。 对象序列化包括如下步骤： 1） 创建一个对象输出流，它可以包装一个其他类型的目标输出流，如文件输出流； 2） 通过对象输出流的writeObject()方法写对象。 对象反序列化的步骤如下： 1） 创建一个对象输入流，它可以包装一个其他类型的源输入流，如文件输入流； 2） 通过对象输入流的readObject()方法读取对象。 对象序列化和反序列范例： 定义一个Person类，实现Serializable接口 1 import java.io.Serializable; 2 3 /** 4 * &lt;p&gt;ClassName: Person&lt;p&gt; 5 * &lt;p&gt;Description:测试对象序列化和反序列化&lt;p&gt; 6 * @author xudp 7 * @version 1.0 V 8 * @createTime 2014-6-9 下午02:33:25 9 */ 10 public class Person implements Serializable { 11 12 /** 13 * 序列化ID 14 */ 15 private static final long serialVersionUID = -5809782578272943999L; 16 private int age; 17 private String name; 18 private String sex; 19 20 public int getAge() { 21 return age; 22 } 23 24 public String getName() { 25 return name; 26 } 27 28 public String getSex() { 29 return sex; 30 } 31 32 public void setAge(int age) { 33 this.age = age; 34 } 35 36 public void setName(String name) { 37 this.name = name; 38 } 39 40 public void setSex(String sex) { 41 this.sex = sex; 42 } 43 } 序列化和反序列化Person类对象 1 import java.io.File; 2 import java.io.FileInputStream; 3 import java.io.FileNotFoundException; 4 import java.io.FileOutputStream; 5 import java.io.IOException; 6 import java.io.ObjectInputStream; 7 import java.io.ObjectOutputStream; 8 import java.text.MessageFormat; 9 10 /** 11 * &lt;p&gt;ClassName: TestObjSerializeAndDeserialize&lt;p&gt; 12 * &lt;p&gt;Description: 测试对象的序列化和反序列&lt;p&gt; 13 * @author xudp 14 * @version 1.0 V 15 * @createTime 2014-6-9 下午03:17:25 16 */ 17 public class TestObjSerializeAndDeserialize { 18 19 public static void main(String[] args) throws Exception { 20 SerializePerson();//序列化Person对象 21 Person p = DeserializePerson();//反序列Perons对象 22 System.out.println(MessageFormat.format(&quot;name={0},age={1},sex={2}&quot;, 23 p.getName(), p.getAge(), p.getSex())); 24 } 25 26 /** 27 * MethodName: SerializePerson 28 * Description: 序列化Person对象 29 * @author xudp 30 * @throws FileNotFoundException 31 * @throws IOException 32 */ 33 private static void SerializePerson() throws FileNotFoundException, 34 IOException { 35 Person person = new Person(); 36 person.setName(&quot;gacl&quot;); 37 person.setAge(25); 38 person.setSex(&quot;男&quot;); 39 // ObjectOutputStream 对象输出流，将Person对象存储到E盘的Person.txt文件中，完成对Person对象的序列化操作 40 ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream( 41 new File(&quot;E:/Person.txt&quot;))); 42 oo.writeObject(person); 43 System.out.println(&quot;Person对象序列化成功！&quot;); 44 oo.close(); 45 } 46 47 /** 48 * MethodName: DeserializePerson 49 * Description: 反序列Perons对象 50 * @author xudp 51 * @return 52 * @throws Exception 53 * @throws IOException 54 */ 55 private static Person DeserializePerson() throws Exception, IOException { 56 ObjectInputStream ois = new ObjectInputStream(new FileInputStream( 57 new File(&quot;E:/Person.txt&quot;))); 58 Person person = (Person) ois.readObject(); 59 System.out.println(&quot;Person对象反序列化成功！&quot;); 60 return person; 61 } 62 63 } 代码运行结果如下：序列化Person成功后在E盘生成了一个Person.txt文件，而反序列化Person是读取E盘的Person.txt后生成了一个Person对象 三、serialVersionUID的作用 s​e​r​i​a​l​V​e​r​s​i​o​n​U​I​D​:​ ​字​面​意​思​上​是​序​列​化​的​版​本​号​，凡是实现Serializable接口的类都有一个表示序列化版本标识符的静态变量 private static final long serialVersionUID serialVersionUID有两种生成方式： 采用这种方式生成的serialVersionUID是1L，例如： 1 private static final long serialVersionUID = 1L; 采用这种方式生成的serialVersionUID是根据类名，接口名，方法和属性等来生成的，例如： 1 private static final long serialVersionUID = 4603642343377807741L; 扯了那么多，那么serialVersionUID(序列化版本号)到底有什么用呢，我们用如下的例子来说明一下serialVersionUID的作用，看下面的代码： 1 import java.io.File; 2 import java.io.FileInputStream; 3 import java.io.FileNotFoundException; 4 import java.io.FileOutputStream; 5 import java.io.IOException; 6 import java.io.ObjectInputStream; 7 import java.io.ObjectOutputStream; 8 import java.io.Serializable; 9 10 public class TestSerialversionUID { 11 12 public static void main(String[] args) throws Exception { 13 SerializeCustomer();// 序列化Customer对象 14 Customer customer = DeserializeCustomer();// 反序列Customer对象 15 System.out.println(customer); 16 } 17 18 /** 19 * MethodName: SerializeCustomer 20 * Description: 序列化Customer对象 21 * @author xudp 22 * @throws FileNotFoundException 23 * @throws IOException 24 */ 25 private static void SerializeCustomer() throws FileNotFoundException, 26 IOException { 27 Customer customer = new Customer(&quot;gacl&quot;,25); 28 // ObjectOutputStream 对象输出流 29 ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream( 30 new File(&quot;E:/Customer.txt&quot;))); 31 oo.writeObject(customer); 32 System.out.println(&quot;Customer对象序列化成功！&quot;); 33 oo.close(); 34 } 35 36 /** 37 * MethodName: DeserializeCustomer 38 * Description: 反序列Customer对象 39 * @author xudp 40 * @return 41 * @throws Exception 42 * @throws IOException 43 */ 44 private static Customer DeserializeCustomer() throws Exception, IOException { 45 ObjectInputStream ois = new ObjectInputStream(new FileInputStream( 46 new File(&quot;E:/Customer.txt&quot;))); 47 Customer customer = (Customer) ois.readObject(); 48 System.out.println(&quot;Customer对象反序列化成功！&quot;); 49 return customer; 50 } 51 } 52 53 /** 54 * &lt;p&gt;ClassName: Customer&lt;p&gt; 55 * &lt;p&gt;Description: Customer实现了Serializable接口，可以被序列化&lt;p&gt; 56 * @author xudp 57 * @version 1.0 V 58 * @createTime 2014-6-9 下午04:20:17 59 */ 60 class Customer implements Serializable { 61 //Customer类中没有定义serialVersionUID 62 private String name; 63 private int age; 64 65 public Customer(String name, int age) { 66 this.name = name; 67 this.age = age; 68 } 69 70 /* 71 * @MethodName toString 72 * @Description 重写Object类的toString()方法 73 * @author xudp 74 * @return string 75 * @see java.lang.Object#toString() 76 */ 77 @Override 78 public String toString() { 79 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 80 } 81 } 运行结果： 序列化和反序列化都成功了。 下面我们修改一下Customer类，添加多一个sex属性，如下： 1 class Customer implements Serializable { 2 //Customer类中没有定义serialVersionUID 3 private String name; 4 private int age; 5 6 //新添加的sex属性 7 private String sex; 8 9 public Customer(String name, int age) { 10 this.name = name; 11 this.age = age; 12 } 13 14 public Customer(String name, int age,String sex) { 15 this.name = name; 16 this.age = age; 17 this.sex = sex; 18 } 19 20 /* 21 * @MethodName toString 22 * @Description 重写Object类的toString()方法 23 * @author xudp 24 * @return string 25 * @see java.lang.Object#toString() 26 */ 27 @Override 28 public String toString() { 29 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 30 } 31 } 然后执行反序列操作，此时就会抛出如下的异常信息： 1 Exception in thread &quot;main&quot; java.io.InvalidClassException: Customer; 2 local class incompatible: 3 stream classdesc serialVersionUID = -88175599799432325, 4 local class serialVersionUID = -5182532647273106745 意思就是说，文件流中的class和classpath中的class，也就是修改过后的class，不兼容了，处于安全机制考虑，程序抛出了错误，并且拒绝载入。那么如果我们真的有需求要在序列化后添加一个字段或者方法呢？应该怎么办？那就是自己去指定serialVersionUID。在TestSerialversionUID例子中，没有指定Customer类的serialVersionUID的，那么java编译器会自动给这个class进行一个摘要算法，类似于指纹算法，只要这个文件 多一个空格，得到的UID就会截然不同的，可以保证在这么多类中，这个编号是唯一的。所以，添加了一个字段后，由于没有显指定 serialVersionUID，编译器又为我们生成了一个UID，当然和前面保存在文件中的那个不会一样了，于是就出现了2个序列化版本号不一致的错误。因此，只要我们自己指定了serialVersionUID，就可以在序列化后，去添加一个字段，或者方法，而不会影响到后期的还原，还原后的对象照样可以使用，而且还多了方法或者属性可以用。 下面继续修改Customer类，给Customer指定一个serialVersionUID，修改后的代码如下： 1 class Customer implements Serializable { 2 /** 3 * Customer类中定义的serialVersionUID(序列化版本号) 4 */ 5 private static final long serialVersionUID = -5182532647273106745L; 6 private String name; 7 private int age; 8 9 //新添加的sex属性 10 //private String sex; 11 12 public Customer(String name, int age) { 13 this.name = name; 14 this.age = age; 15 } 16 17 /*public Customer(String name, int age,String sex) { 18 this.name = name; 19 this.age = age; 20 this.sex = sex; 21 }*/ 22 23 /* 24 * @MethodName toString 25 * @Description 重写Object类的toString()方法 26 * @author xudp 27 * @return string 28 * @see java.lang.Object#toString() 29 */ 30 @Override 31 public String toString() { 32 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 33 } 34 } 重新执行序列化操作，将Customer对象序列化到本地硬盘的Customer.txt文件存储，然后修改Customer类，添加sex属性，修改后的Customer类代码如下： 1 class Customer implements Serializable { 2 /** 3 * Customer类中定义的serialVersionUID(序列化版本号) 4 */ 5 private static final long serialVersionUID = -5182532647273106745L; 6 private String name; 7 private int age; 8 9 //新添加的sex属性 10 private String sex; 11 12 public Customer(String name, int age) { 13 this.name = name; 14 this.age = age; 15 } 16 17 public Customer(String name, int age,String sex) { 18 this.name = name; 19 this.age = age; 20 this.sex = sex; 21 } 22 23 /* 24 * @MethodName toString 25 * @Description 重写Object类的toString()方法 26 * @author xudp 27 * @return string 28 * @see java.lang.Object#toString() 29 */ 30 @Override 31 public String toString() { 32 return &quot;name=&quot; + name + &quot;, age=&quot; + age; 33 } 34 } 执行反序列操作，这次就可以反序列成功了，如下所示： 四、serialVersionUID的取值 serialVersionUID的取值是Java运行时环境根据类的内部细节自动生成的。如果对类的源代码作了修改，再重新编译，新生成的类文件的serialVersionUID的取值有可能也会发生变化。 类的serialVersionUID的默认值完全依赖于Java编译器的实现，对于同一个类，用不同的Java编译器编译，有可能会导致不同的 serialVersionUID，也有可能相同。为了提高serialVersionUID的独立性和确定性，强烈建议在一个可序列化类中显示的定义serialVersionUID，为它赋予明确的值。 显式地定义serialVersionUID有两种用途： 1、 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 2、 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。 原文连接","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"}]},{"title":"validation实现后台校验;","slug":"hibernate-validation实现后台校验","date":"2017-05-02T15:05:20.000Z","updated":"2019-05-01T13:51:07.477Z","comments":true,"path":"2017/05/02/hibernate-validation实现后台校验/","link":"","permalink":"https://tokerr.github.io/2017/05/02/hibernate-validation实现后台校验/","excerpt":"1 validation校验对前端的校验大多数通过js在页面校验，这种方法比较简单，如果对安全性考虑，还要在后台校验。 springmvc使用JSR-303（javaEE6规范的一部分）校验规范，springmvc使用的是Hibernate Validator（和Hibernate的ORM） 1.1 加入Hibernate Validator的jar","text":"1 validation校验对前端的校验大多数通过js在页面校验，这种方法比较简单，如果对安全性考虑，还要在后台校验。 springmvc使用JSR-303（javaEE6规范的一部分）校验规范，springmvc使用的是Hibernate Validator（和Hibernate的ORM） 1.1 加入Hibernate Validator的jar 1.2 在处理器适配器中配置校验器 1.3 创建CustomValidationMessages在classpath下创建CustomValidationMessages.properties 1.4 校验规则需求：商品信息提交时校验 ，商品生产日期不能为空，商品名称长度在1到30字符之间 1.5 捕获错误需要修改controller方法，在要校验的pojo前边加上@Validated， 错误信息输出： 1.6 在页面上展示错误 1.7 分组校验需求：针对不同的controller方法通过分组校验达到个性化校验的目的，修改商品修改功能，只校验生产日期不能为空。 第一步：创建分组接口 第二步：定义校验规则属于哪个分组 第三步：在controller方法定义使用校验的分组 1.8 hibernate-validator的配置以及使用此处只列出Hibernate Validator提供的大部分验证约束注解，请参考hibernate validator官方文档了解其他验证约束注解和进行自定义的验证约束注解定义。 springmvc参数自动转换:1.String to Date2.String to Integer or int3.String to Byte or int4.String to Long or loong Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.lang.Byte&apos; for property &apos;duration&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;128&quot; from type &apos;java.lang.String&apos; to type &apos;java.lang.Byte&apos;; nested exception is java.lang.NumberFormatException: Value out of range. Value:&quot;128&quot; Radix:10 Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.util.Date&apos; for property &apos;starttime&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;2017-01-23 16:25:45&quot; from type &apos;java.lang.String&apos; to type &apos;java.util.Date&apos;; nested exception is java.lang.IllegalStateException: JodaTime library not available - @DateTimeFormat not supported http://127.0.0.1:8888/mokao-back/empfollowups/addEmpfollowups?empId=12988&amp;starttime=2015-06-04%2009:06:29&amp;duration=128&amp;salesid=325 Validator校验器使用正常[ { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;duration&quot;, &quot;codes&quot;: [ &quot;empfollowups.duration&quot;, &quot;duration&quot; ], &quot;defaultMessage&quot;: &quot;duration&quot; } ], &quot;bindingFailure&quot;: true, &quot;code&quot;: &quot;typeMismatch&quot;, &quot;codes&quot;: [ &quot;typeMismatch.empfollowups.duration&quot;, &quot;typeMismatch.duration&quot;, &quot;typeMismatch.java.lang.Byte&quot;, &quot;typeMismatch&quot; ], &quot;defaultMessage&quot;: &quot;Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.lang.Byte&apos; for property &apos;duration&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;128&quot; from type &apos;java.lang.String&apos; to type &apos;java.lang.Byte&apos;; nested exception is java.lang.NumberFormatException: Value out of range. Value:&quot;128&quot; Radix:10&quot;, &quot;field&quot;: &quot;duration&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: &quot;128&quot; }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;starttime&quot;, &quot;codes&quot;: [ &quot;empfollowups.starttime&quot;, &quot;starttime&quot; ], &quot;defaultMessage&quot;: &quot;starttime&quot; } ], &quot;bindingFailure&quot;: true, &quot;code&quot;: &quot;typeMismatch&quot;, &quot;codes&quot;: [ &quot;typeMismatch.empfollowups.starttime&quot;, &quot;typeMismatch.starttime&quot;, &quot;typeMismatch.java.util.Date&quot;, &quot;typeMismatch&quot; ], &quot;defaultMessage&quot;: &quot;Failed to convert property value of type &apos;java.lang.String&apos; to required type &apos;java.util.Date&apos; for property &apos;starttime&apos;; nested exception is org.springframework.core.convert.ConversionFailedException: Unable to convert value &quot;2015-06-04 09:06:29&quot; from type &apos;java.lang.String&apos; to type &apos;java.util.Date&apos;; nested exception is java.lang.IllegalStateException: JodaTime library not available - @DateTimeFormat not supported&quot;, &quot;field&quot;: &quot;starttime&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: &quot;2015-06-04 09:06:29&quot; }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;goal&quot;, &quot;codes&quot;: [ &quot;empfollowups.goal&quot;, &quot;goal&quot; ], &quot;defaultMessage&quot;: &quot;goal&quot; } ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;NotNull&quot;, &quot;codes&quot;: [ &quot;NotNull.empfollowups.goal&quot;, &quot;NotNull.goal&quot;, &quot;NotNull.java.lang.String&quot;, &quot;NotNull&quot; ], &quot;defaultMessage&quot;: &quot;回访目的不能为空!&quot;, &quot;field&quot;: &quot;goal&quot;, &quot;objectName&quot;: &quot;empfollowups&quot; }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;salesid&quot;, &quot;codes&quot;: [ &quot;empfollowups.salesid&quot;, &quot;salesid&quot; ], &quot;defaultMessage&quot;: &quot;salesid&quot; }, 127, 0 ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;Range&quot;, &quot;codes&quot;: [ &quot;Range.empfollowups.salesid&quot;, &quot;Range.salesid&quot;, &quot;Range.java.lang.Integer&quot;, &quot;Range&quot; ], &quot;defaultMessage&quot;: &quot;回访时间范围请保持在0-127分钟之内!&quot;, &quot;field&quot;: &quot;salesid&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: 325 } ] OK【对于以上 String to Byte 类型错误的原因是：传过去的参数超出-127~127的范围，因此出现数字格式化异常，若是绑定的参数在正常范围内即-127~127之内则能正常绑定】NO【已经解决，@DateTimeFormat not support 对于日期格式的字符串配置的springmvc的转换去没有转换成功 异常原因：缺少jar包 导入如下jar包即可使用注解的方式将pojo中string类型字符串转换成日期对象:joda-time库】 二、以下是springmvc中validator的配置： 2.1先引入相关jar包:已附录在首行，3个相关jar包，若是需要使用注解对pojo中的Date类型进行转换，需要将joda-time也一并引入 2.2 配置： 控制器 2.3相关文件：源码文件，这里就不帖出来了 2.4 pojo属性类型转换除了@DateTimeFormat 注解用于转换日期之外，还有可用于数字类型的属性转换的注解:@NumberFormat@DateTimeFormat(pattern=”yyyy-MM-dd”) 可将形如1980-0-01的字符串转换到Date类@NumberFormat(pattern=”#,###.##”) 可将形如4,500.00的字符串转换成long类型 2.5 List allErrors = bindingResult.getAllErrors(); allErrors 实例展示(这里转换成了json字符串) http://127.0.0.1:8888/mokao-back/empfollowups/addEmpfollowups?empId=12988&amp;starttime=2015-06-04%2009:06:29&amp;duration=118&amp;salesid=325 [ { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;salesid&quot;, &quot;codes&quot;: [ &quot;empfollowups.salesid&quot;, &quot;salesid&quot; ], &quot;defaultMessage&quot;: &quot;salesid&quot; }, 127, 0 ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;Range&quot;, &quot;codes&quot;: [ &quot;Range.empfollowups.salesid&quot;, &quot;Range.salesid&quot;, &quot;Range.java.lang.Integer&quot;, &quot;Range&quot; ], &quot;defaultMessage&quot;: &quot;销售的id值请保持在0~127范围之内!&quot;, &quot;field&quot;: &quot;salesid&quot;, &quot;objectName&quot;: &quot;empfollowups&quot;, &quot;rejectedValue&quot;: 325 }, { &quot;arguments&quot;: [ { &quot;code&quot;: &quot;goal&quot;, &quot;codes&quot;: [ &quot;empfollowups.goal&quot;, &quot;goal&quot; ], &quot;defaultMessage&quot;: &quot;goal&quot; } ], &quot;bindingFailure&quot;: false, &quot;code&quot;: &quot;NotNull&quot;, &quot;codes&quot;: [ &quot;NotNull.empfollowups.goal&quot;, &quot;NotNull.goal&quot;, &quot;NotNull.java.lang.String&quot;, &quot;NotNull&quot; ], &quot;defaultMessage&quot;: &quot;回访目的不能为空!&quot;, &quot;field&quot;: &quot;goal&quot;, &quot;objectName&quot;: &quot;empfollowups&quot; } ] org.codehaus.jackson.map.JsonMappingException: No serializer found for class org.springframework.validation.DefaultMessageCodesResolver and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationConfig.Feature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: org.springframework.validation.BeanPropertyBindingResult[&quot;messageCodesResolver&quot;]) at org.codehaus.jackson.map.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:52) at org.codehaus.jackson.map.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:25) at org.codehaus.jackson.map.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:446) at org.codehaus.jackson.map.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:150) at org.codehaus.jackson.map.ser.BeanSerializer.serialize(BeanSerializer.java:112) at org.codehaus.jackson.map.ser.StdSerializerProvider._serializeValue(StdSerializerProvider.java:610) at org.codehaus.jackson.map.ser.StdSerializerProvider.serializeValue(StdSerializerProvider.java:256) at org.codehaus.jackson.map.ObjectMapper._configAndWriteValue(ObjectMapper.java:2575) at org.codehaus.jackson.map.ObjectMapper.writeValueAsString(ObjectMapper.java:2097) at com.skf.mokao.controller.empfollowups.EmpfollowupsController.addEmpfollowups(EmpfollowupsController.java:125) at com.skf.mokao.controller.empfollowups.EmpfollowupsController$$FastClassByCGLIB$$2006e11c.invoke(&lt;generated&gt;) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191) at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:688) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) at org.springframework.aop.aspectj.AspectJAfterAdvice.invoke(AspectJAfterAdvice.java:42) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:80) at com.skf.mokao.aspect.Aspect5_LoginCheck.around(Aspect5_LoginCheck.java:146) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:65) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:89) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:621) at com.skf.mokao.controller.empfollowups.EmpfollowupsController$$EnhancerByCGLIB$$8b5e69da.addEmpfollowups(&lt;generated&gt;) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.web.bind.annotation.support.HandlerMethodInvoker.invokeHandlerMethod(HandlerMethodInvoker.java:176) at org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter.invokeHandlerMethod(AnnotationMethodHandlerAdapter.java:426) at org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter.handle(AnnotationMethodHandlerAdapter.java:414) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:790) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:719) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:644) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:549) at javax.servlet.http.HttpServlet.service(HttpServlet.java:624) at javax.servlet.http.HttpServlet.service(HttpServlet.java:731) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at com.skf.mokao.filter.UserLoginFilter.doFilter(UserLoginFilter.java:63) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449) at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365) at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90) at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83) at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:380) at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362) at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125) at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:237) at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:167) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at com.skf.mokao.filter.RequestParametersFilter.doFilter(RequestParametersFilter.java:138) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122) at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:505) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:956) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:442) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1083) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:640) at org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.doRun(AprEndpoint.java:2517) at org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.run(AprEndpoint.java:2506) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745)","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"validation","slug":"validation","permalink":"https://tokerr.github.io/tags/validation/"},{"name":"spring","slug":"spring","permalink":"https://tokerr.github.io/tags/spring/"},{"name":"springmvc","slug":"springmvc","permalink":"https://tokerr.github.io/tags/springmvc/"},{"name":"hibernate-validation","slug":"hibernate-validation","permalink":"https://tokerr.github.io/tags/hibernate-validation/"}]},{"title":"在不同环境下使用Gson出现的Date格式化问题","slug":"在不同环境下使用Gson出现的Date格式化问题","date":"2017-04-27T15:03:17.000Z","updated":"2019-05-01T13:51:07.479Z","comments":true,"path":"2017/04/27/在不同环境下使用Gson出现的Date格式化问题/","link":"","permalink":"https://tokerr.github.io/2017/04/27/在不同环境下使用Gson出现的Date格式化问题/","excerpt":"在Java中处理JSON格式的数据时，Google Gson是个不错的选择，用起来挺方便的，也有一定灵活性。我现在工作中在参与的两个项目里都有用它。不过它在处理Date格式时有个小陷阱，在不同环境中部署时可能会遇到问题。 Gson默认处理Date对象的序列化/反序列化是通过一个SimpleDateFormat对象来实现的，通过下面的代码去获取实例：DateFormat.getDateTimeInstance() 在不同的locale环境中，这样获取到的SimpleDateFormat的模式字符串会不一样。例如说，在我的开发机是Windows XP SP3，zh_CN.GBK，模式字符串是：“yyyy-M-d H:mm:ss”","text":"在Java中处理JSON格式的数据时，Google Gson是个不错的选择，用起来挺方便的，也有一定灵活性。我现在工作中在参与的两个项目里都有用它。不过它在处理Date格式时有个小陷阱，在不同环境中部署时可能会遇到问题。 Gson默认处理Date对象的序列化/反序列化是通过一个SimpleDateFormat对象来实现的，通过下面的代码去获取实例：DateFormat.getDateTimeInstance() 在不同的locale环境中，这样获取到的SimpleDateFormat的模式字符串会不一样。例如说，在我的开发机是Windows XP SP3，zh_CN.GBK，模式字符串是：“yyyy-M-d H:mm:ss”而在我们的一台测试服务器上，RHEL 5.4，en_US.UTF-8，模式字符串则是：“MMM d, yyyy h:mm:ss a” 这就使得同样的Date对象通过Gson来序列化为JSON后内容不同。例如说要序列化的日期是2010-08-19 16:13:57，那么在我的开发机上得到的是：“2010-8-19 16:13:57” 而在那台测试服务器上则是：“Aug 19, 2010 4:13:57 PM” 这就……郁闷了。在一边序列化的内容在另一边会反序列化失败。 为了避免使用Gson时遇到locale影响Date格式的问题，使用GsonBuilder来创建Gson对象，在创建过程中调用GsonBuilder.setDateFormat(String)指定一个固定的格式即可。例如：Gson gson = new GsonBuilder() .setDateFormat(“yyyy-MM-dd HH:mm:ss”) .create(); 原文链接","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"google","slug":"google","permalink":"https://tokerr.github.io/tags/google/"},{"name":"json","slug":"json","permalink":"https://tokerr.github.io/tags/json/"},{"name":"gson","slug":"gson","permalink":"https://tokerr.github.io/tags/gson/"},{"name":"linux","slug":"linux","permalink":"https://tokerr.github.io/tags/linux/"},{"name":"windows","slug":"windows","permalink":"https://tokerr.github.io/tags/windows/"}]},{"title":"sql语句使用临时数据，模拟构建一张临时表(用于一次性查询的)","slug":"sql语句使用临时数据，模拟构建一张临时表-用于一次性查询的","date":"2017-04-26T13:31:02.000Z","updated":"2019-05-01T13:51:07.478Z","comments":true,"path":"2017/04/26/sql语句使用临时数据，模拟构建一张临时表-用于一次性查询的/","link":"","permalink":"https://tokerr.github.io/2017/04/26/sql语句使用临时数据，模拟构建一张临时表-用于一次性查询的/","excerpt":"一、问题描述：项目使用到了sendcloud的邮件服务，邮件的发送接口前期已经写好了，前几天突然需要看到取消接收我们公司发出去的邮件列表，由于又是后台的功能，所以交到了我们的手上，逻辑也简单，就是第一次去调用服务商的接口，至于如何调用，方法也不少，这里也不赘述，进入主题： 因为sendcloud服务商烦我返回的数据，除了一个邮箱的列表之外，没有必要的邮箱对应公司的名称(产品这边提的需求)，这点不难理解，详细的数据都在我们的数据库里面，因此在调用sendcloud的接口获取到邮箱列表之后还需要到我们的数据库中查询出对应的公司名称。 于是我就思考，每个邮箱单独去做一次查询，使用程序填装的方式，将企业名称一一对应封装，但是如果邮箱列表很多的情况下，就会影响数据库的性能，这是很不可取的，因此想着能不能通过sql的连接查询方式，把数据一次性的查询出来，只需要访问一次数据库即可：这样就需要将邮件列表在sql查询中组装成一张临时的表，然后再使用连接的方式查询企业的表从而获取到企业的详细信息，这样即使没有查到对应的企业，但是有限依然能正常显示。","text":"一、问题描述：项目使用到了sendcloud的邮件服务，邮件的发送接口前期已经写好了，前几天突然需要看到取消接收我们公司发出去的邮件列表，由于又是后台的功能，所以交到了我们的手上，逻辑也简单，就是第一次去调用服务商的接口，至于如何调用，方法也不少，这里也不赘述，进入主题： 因为sendcloud服务商烦我返回的数据，除了一个邮箱的列表之外，没有必要的邮箱对应公司的名称(产品这边提的需求)，这点不难理解，详细的数据都在我们的数据库里面，因此在调用sendcloud的接口获取到邮箱列表之后还需要到我们的数据库中查询出对应的公司名称。 于是我就思考，每个邮箱单独去做一次查询，使用程序填装的方式，将企业名称一一对应封装，但是如果邮箱列表很多的情况下，就会影响数据库的性能，这是很不可取的，因此想着能不能通过sql的连接查询方式，把数据一次性的查询出来，只需要访问一次数据库即可：这样就需要将邮件列表在sql查询中组装成一张临时的表，然后再使用连接的方式查询企业的表从而获取到企业的详细信息，这样即使没有查到对应的企业，但是有限依然能正常显示。 二、基本的操作直接上图，简洁明了，想我不愿意看那么长描述性问题的人，问题写了那么多，觉得有点废话。 select (&apos;111&apos;) AS num1,(5555) AS num2 UNION ALL select (&apos;111&apos;) AS num1,(null) AS num2 注意：上面使用到了union all的合并查询，剩下的自己去领悟 三、实际的应用：结合mybatis3.1sql语句的编写 sql语句：表结构就不贴出来了 SELECT temp.email, temp.num2, emp.id, emp. NAME FROM ( SELECT (&apos;2955*****@qq.com&apos;) AS email,(5555) AS num2 UNION ALL SELECT (&apos;hr@******.com&apos;) AS email,(5555) AS num2 UNION ALL SELECT (&apos;advertiser@****.com&apos;) AS email,(NULL) AS num2 UNION ALL SELECT (&apos;advertis@*****.com&apos;) AS email,(5555) AS num2 ) AS temp LEFT JOIN employers AS emp ON temp.email = emp.email WHERE emp.flag != &apos;D&apos; OR emp.flag IS NULL 3.2mapper.xml和dao接口3.2.1 dao接口： public List&lt;Employers&gt; queryUnsubscribeByPage_(@Param(&quot;emails&quot;) List&lt;SCEmailUnsubscribe.Data&gt; emails,@Param(&quot;condition&quot;)SCEmailUnsubscribe.Data condition,@Param(&quot;startNum&quot;)Integer startNum,@Param(&quot;pageSize&quot;)Integer pageSize); 3.2.2 mapper.xml &lt;sql id=&quot;Condition_And_Clause_&quot;&gt; &lt;if test=&quot;condition!=null&quot;&gt; &lt;if test=&quot;condition.empname!=null&quot;&gt; AND `Name` LIKE #{condition.empname,jdbcType=VARCHAR} &lt;/if&gt; &lt;if test=&quot;condition.email!=null&quot;&gt; AND `Email` LIKE #{condition.email,jdbcType=VARCHAR} &lt;/if&gt; &lt;/if&gt; &lt;/sql&gt; &lt;select id=&quot;queryUnsubscribeByPage_&quot; resultType=&quot;com.skf.mokao.pojo.Employers&quot;&gt; SELECT temp.email AS email, STR_TO_DATE(temp.unsubscribeTime,&apos;%Y-%m-%d %H:%i:%s&apos;) AS unsubscribeTime, emp.id AS id, emp.name AS name FROM ( &lt;if test=&quot;emails!=null&quot;&gt; &lt;foreach collection=&quot;emails&quot; open=&quot;SELECT &quot; close=&quot;&quot; item=&quot;item&quot; separator=&quot; UNION ALL SELECT &quot;&gt; (#{item.email}) AS email,(#{item.unsubscribeTime,jdbcType=TIMESTAMP}) AS unsubscribeTime &lt;/foreach&gt; &lt;/if&gt; ) AS temp LEFT JOIN employers AS emp ON temp.email = emp.email WHERE emp.flag != &apos;D&apos; OR emp.flag IS NULL &lt;include refid=&quot;Condition_And_Clause_&quot;/&gt; ORDER BY temp.unsubscribeTime DESC LIMIT #{startNum,jdbcType=INTEGER},#{pageSize,jdbcType=INTEGER} &lt;/select&gt; &lt;select id=&quot;queryUnsubscribeCount_&quot; resultType=&quot;java.lang.Integer&quot; &gt; SELECT COUNT(temp.email) FROM ( &lt;if test=&quot;emails!=null&quot;&gt; &lt;foreach collection=&quot;emails&quot; open=&quot;SELECT &quot; close=&quot;&quot; item=&quot;item&quot; separator=&quot; UNION ALL SELECT &quot;&gt; (#{item.email}) AS email,(#{item.unsubscribeTime,jdbcType=TIMESTAMP}) AS unsubscribeTime &lt;/foreach&gt; &lt;/if&gt; ) AS temp LEFT JOIN employers AS emp ON temp.email = emp.email WHERE emp.flag != &apos;D&apos; OR emp.flag IS NULL &lt;include refid=&quot;Condition_And_Clause_&quot;/&gt; &lt;/select&gt;","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://tokerr.github.io/tags/mysql/"},{"name":"临时表","slug":"临时表","permalink":"https://tokerr.github.io/tags/临时表/"},{"name":"mybatis","slug":"mybatis","permalink":"https://tokerr.github.io/tags/mybatis/"}]},{"title":"java.util.Date转java.sql.Date丢失时间问题","slug":"java-util-Date转java-sql-Date丢失时间问题","date":"2017-04-25T14:15:59.000Z","updated":"2019-05-01T13:51:07.477Z","comments":true,"path":"2017/04/25/java-util-Date转java-sql-Date丢失时间问题/","link":"","permalink":"https://tokerr.github.io/2017/04/25/java-util-Date转java-sql-Date丢失时间问题/","excerpt":"一.引发我写这篇博客的原因（问题描述）：由于项目使用的是springmvc+mybatis，前期的开发使用到了ibator这个dao层代码生成工具(ps:后来因为老板的原因，禁用了这个工具，但是以前的老代码还有在使用这个工具生成的代码)，其中提供的Example极大的方便开发是进行数据的各种查询的工作，但是使用过程出现了一些问题。在对日期时间类型的字段进行筛选的时候不能精确到时分秒，原因是Example里面默认的是将util的Date 转成 sql的Date，以至丢失时间 查询不能精确到时分秒","text":"一.引发我写这篇博客的原因（问题描述）：由于项目使用的是springmvc+mybatis，前期的开发使用到了ibator这个dao层代码生成工具(ps:后来因为老板的原因，禁用了这个工具，但是以前的老代码还有在使用这个工具生成的代码)，其中提供的Example极大的方便开发是进行数据的各种查询的工作，但是使用过程出现了一些问题。在对日期时间类型的字段进行筛选的时候不能精确到时分秒，原因是Example里面默认的是将util的Date 转成 sql的Date，以至丢失时间 查询不能精确到时分秒 二、问题原因以及解决方法：java.sql.Date 只存储日期数据不存储时间数据 // 会丢失时间数据 preparedStatement.setDate(1, new java.sql.Date(date.getTime())); //可以这样来处理 preparedStatement.setTimestamp(1, new java.sql.Timestamp(new java.util.Date().getTime())); //想要得到完整的数据，包括日期和时间，可以这样 java.util.Date d = resultSet.getTimestamp(1); //这样处理更合适一些，可以避免一些潜在Timestamp 问题 java.util.Date d = new java.util.Date(resultSet.getTimestamp(1).getTime()); 这样的话：往数据库存储的时候可以接收 java.util.Date类型 再用getTime()方法得到代表那个Date对象的long值，再以这个long值 构造一个Timestamp对象 存进数据库中。从存数据库里取的时候，可以先得到Timestamp用他的getTime()方法得到long值，再以这个long值构造一个 java.util.Date对象，这样就可以对这个Date对象操作了。例如 new SimpleTimeFormat(&quot;yyyyy-MM-dd HH:mm:ss&quot;).format()等等","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://tokerr.github.io/tags/java/"},{"name":"日期转换","slug":"日期转换","permalink":"https://tokerr.github.io/tags/日期转换/"}]},{"title":"简单易懂的更换hexo主题的教程","slug":"简单易懂的更换hexo主题的教程","date":"2017-04-05T14:47:29.000Z","updated":"2019-05-01T13:51:07.481Z","comments":true,"path":"2017/04/05/简单易懂的更换hexo主题的教程/","link":"","permalink":"https://tokerr.github.io/2017/04/05/简单易懂的更换hexo主题的教程/","excerpt":"以Smackdown为例：http://blog.smackdown.gebilaowu.cn/一、预览的页面 二、到github中找到hexo主题的demo一般的都会附带上github的demo地址，顺便附录上hexo官方的主题列表页面，大家可以在里面挑一款自己喜欢的(https://hexo.io/themes/)，这个官网的主题连接在_config.yml配置文件的themes属性配置的上面有。","text":"以Smackdown为例：http://blog.smackdown.gebilaowu.cn/一、预览的页面 二、到github中找到hexo主题的demo一般的都会附带上github的demo地址，顺便附录上hexo官方的主题列表页面，大家可以在里面挑一款自己喜欢的(https://hexo.io/themes/)，这个官网的主题连接在_config.yml配置文件的themes属性配置的上面有。图示的仓库地址：https://github.com/smackgg/hexo-theme-smackdown 三、将主题的demo克隆到本地一定要确保克隆到自己bolg下面的themes下面(置于克隆到其他的文件夹我没有试过) 四、更新操作： 五、修改配置文件，打开_config.yml文件： 六、启动本地预览效果： 七、部署到github服务器： 八、注意事项：8.1 由于windows的cmd一般是gbk方式编码，因此使用windows自带的cmd初始化blog之后，需要把_config.yml配置文件改成utf-8的编码格式，不然部署到服务器上浏览器打开会出现中文乱码。 8.2 我搭建hexo博客，部署deploy的时候出现了error deployer not found:github 的错误，附上当前解决这个问题的连接：http://www.jianshu.com/p/5e0ca2b14815","categories":[],"tags":[{"name":"hexo 主题 更换","slug":"hexo-主题-更换","permalink":"https://tokerr.github.io/tags/hexo-主题-更换/"}]}]}