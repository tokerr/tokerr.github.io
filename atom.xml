<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>农永滔的博客</title>
  <icon>https://www.gravatar.com/avatar/3c2e7ddddb8b1987b870857a7f766c20</icon>
  <subtitle>nongyongtao</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://tokerr.github.io/"/>
  <updated>2020-04-19T06:50:18.542Z</updated>
  <id>https://tokerr.github.io/</id>
  
  <author>
    <name>nongyongtao</name>
    <email>nytom@foxmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>单例模式还可以用枚举来实现吗？</title>
    <link href="https://tokerr.github.io/2020/04/19/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%EF%BC%88singleton%EF%BC%89/"/>
    <id>https://tokerr.github.io/2020/04/19/单例模式（singleton）/</id>
    <published>2020-04-19T06:03:00.000Z</published>
    <updated>2020-04-19T06:50:18.542Z</updated>
    
    <content type="html"><![CDATA[<h2 id="单例模式（singleton）"><a href="#单例模式（singleton）" class="headerlink" title="单例模式（singleton）"></a>单例模式（singleton）</h2><h2 id="一、什么是单例模式？"><a href="#一、什么是单例模式？" class="headerlink" title="一、什么是单例模式？"></a>一、什么是单例模式？</h2><ul><li>确保内存当中一个类的实例对象只要一个</li></ul><h2 id="二、两种单例模式"><a href="#二、两种单例模式" class="headerlink" title="二、两种单例模式"></a>二、两种单例模式</h2><ul><li><h3 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h3><ul><li><p>步骤</p><ul><li><p>在单例类中定义与自己类型相同的常量，并初始化</p><ul><li>private static final SingletonClass INSTANCE= new SingletonClass();</li></ul></li><li><p>私有化单例类的构造方法</p></li><li>定义一个publish的getInstance方法，返回实例化的常量</li></ul></li><li><p>特点</p><ul><li>在类初始化阶段就完成了单例对象的初始化</li><li>不存在多线程安全问题</li></ul></li></ul></li></ul><a id="more"></a><ul><li><h3 id="懒汉式"><a href="#懒汉式" class="headerlink" title="懒汉式"></a>懒汉式</h3><ul><li><p>特点</p><ul><li>在第一次调用getInstance方法的时候才会初始化单例对象，这也是与‘饿汉式’的区别。</li></ul></li><li><p>实现步骤</p><ul><li><p>单例类中定义一个与自己类型相同的静态变量，不初始化</p><ul><li>private static SIngletonClass INSTANCE;</li></ul></li><li>同样需要私有化单例类的构造方法</li><li>实现getInstance方法</li></ul></li></ul></li><li><h4 id="实现方式一"><a href="#实现方式一" class="headerlink" title="实现方式一"></a>实现方式一</h4></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SIngletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line"><span class="keyword">if</span>(INSTANCE == <span class="keyword">null</span>)&#123;</div><div class="line"> INSTANCE=<span class="keyword">new</span> SingletonClass();</div><div class="line">&#125;</div><div class="line"><span class="keyword">return</span> INSTANCE;</div><div class="line">&#125;</div></pre></td></tr></table></figure><ul><li><p>存在的问题</p><ul><li>存在多线程安全的问题，可能两个线程分别得到不同的实例</li></ul></li><li><h4 id="实现方式二：synchronized"><a href="#实现方式二：synchronized" class="headerlink" title="实现方式二：synchronized"></a>实现方式二：synchronized</h4><ul><li>在方式一的基础上，给getInstance方法加synchronized关键字</li><li><p>存在的问题</p><ul><li>解决了方式一的多线程安全问题，但是会大大降低运行效率</li></ul></li></ul></li><li><h4 id="实现方式三"><a href="#实现方式三" class="headerlink" title="实现方式三"></a>实现方式三</h4></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SIngletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line"><span class="keyword">if</span>( INSTANCE == <span class="keyword">null</span>)&#123;</div><div class="line"> <span class="keyword">synchronized</span>(SIngletonClass.class)&#123;</div><div class="line">  INSTANCE=<span class="keyword">new</span> SIngletonClass();</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">return</span> INSTANCE;</div><div class="line">&#125;</div></pre></td></tr></table></figure><ul><li><p>缺陷：同样有多线程安全问题</p></li><li><h4 id="实现方式四：双重判断加锁"><a href="#实现方式四：双重判断加锁" class="headerlink" title="实现方式四：双重判断加锁"></a>实现方式四：双重判断加锁</h4><ol><li>在方式三的基础上，在synchronized加锁之后，再次对INSTANCE做一次空判断，如果也为空，再初始化单例对象。</li><li>需要使用volatile关键字修饰变量，防止JIT对指令进行重排序<ul><li>private static volatile SingletonClass INSTANCE;</li></ul></li><li>多线程安全的问题得以解决</li></ol></li></ul><ul><li><h4 id="实现方式五：使用内部类的方式实现懒汉式"><a href="#实现方式五：使用内部类的方式实现懒汉式" class="headerlink" title="实现方式五：使用内部类的方式实现懒汉式"></a>实现方式五：使用内部类的方式实现懒汉式</h4><ul><li><p>指导思想：</p><ol><li>JVM“只对每个类加载一次”的原则，保证了多线程安全</li><li>JVM加载外部类时不会加载内部类，这样可以实现懒加载</li></ol></li><li><p>代码实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonClass</span></span>&#123;</div><div class="line"><span class="function"><span class="keyword">private</span> <span class="title">SingletonClass</span><span class="params">()</span></span>&#123;&#125;;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">InnerClass</span></span>&#123;</div><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> SingletonClass INSTANCE=<span class="keyword">new</span> SingletonClass();</div><div class="line">&#125; </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonClass <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line"><span class="keyword">return</span> InnerClass.INSTANCE;</div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></li></ul></li><li><h4 id="实现方式六：使用枚举类的方式实现懒汉式"><a href="#实现方式六：使用枚举类的方式实现懒汉式" class="headerlink" title="实现方式六：使用枚举类的方式实现懒汉式"></a>实现方式六：使用枚举类的方式实现懒汉式</h4></li><li><p>好处：</p><ul><li><p>不仅可以解决多线程安全问题，还可以防止反序列化。想其他几种单例的实现方式，都是可以通过反射的方式再次创建实例的。（枚举类没有构造方法）</p></li><li><p>是最简单和安全的实现方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">enum</span> SingletonClass&#123;</div><div class="line">INSTANCE;</div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method1</span><span class="params">()</span></span>&#123;&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></li></ul></li></ul><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>这里列出了7种单例的实现方式，并不是说一定要用哪一种，而是应该结合项目的情况，选择一种合适的实现方式。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;单例模式（singleton）&quot;&gt;&lt;a href=&quot;#单例模式（singleton）&quot; class=&quot;headerlink&quot; title=&quot;单例模式（singleton）&quot;&gt;&lt;/a&gt;单例模式（singleton）&lt;/h2&gt;&lt;h2 id=&quot;一、什么是单例模式？&quot;&gt;&lt;a href=&quot;#一、什么是单例模式？&quot; class=&quot;headerlink&quot; title=&quot;一、什么是单例模式？&quot;&gt;&lt;/a&gt;一、什么是单例模式？&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确保内存当中一个类的实例对象只要一个&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;二、两种单例模式&quot;&gt;&lt;a href=&quot;#二、两种单例模式&quot; class=&quot;headerlink&quot; title=&quot;二、两种单例模式&quot;&gt;&lt;/a&gt;二、两种单例模式&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;饿汉式&quot;&gt;&lt;a href=&quot;#饿汉式&quot; class=&quot;headerlink&quot; title=&quot;饿汉式&quot;&gt;&lt;/a&gt;饿汉式&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;步骤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在单例类中定义与自己类型相同的常量，并初始化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;private static final SingletonClass INSTANCE= new SingletonClass();&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;私有化单例类的构造方法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;定义一个publish的getInstance方法，返回实例化的常量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在类初始化阶段就完成了单例对象的初始化&lt;/li&gt;
&lt;li&gt;不存在多线程安全问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="https://tokerr.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="DesignPattern" scheme="https://tokerr.github.io/tags/DesignPattern/"/>
    
  </entry>
  
  <entry>
    <title>代理模式（Proxy）</title>
    <link href="https://tokerr.github.io/2020/04/12/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%EF%BC%88Proxy%EF%BC%89/"/>
    <id>https://tokerr.github.io/2020/04/12/代理模式（Proxy）/</id>
    <published>2020-04-12T08:44:00.000Z</published>
    <updated>2020-04-19T07:07:18.235Z</updated>
    
    <content type="html"><![CDATA[<h2 id="代理模式（Proxy）"><a href="#代理模式（Proxy）" class="headerlink" title="代理模式（Proxy）"></a>代理模式（Proxy）</h2><h2 id="一、说明"><a href="#一、说明" class="headerlink" title="一、说明"></a>一、说明</h2><ul><li>本文当中出现的代码均为伪代码，可参考文章末尾列出的项目代码地址。</li><li>假设我们的jar包使用maven进行管理。</li></ul><h2 id="二、模式定义"><a href="#二、模式定义" class="headerlink" title="二、模式定义"></a>二、模式定义</h2><ul><li>对访问（或请求）实现拦截和权限的控制，以决定是否需要执行用户的请求。常见的代理体现有Spring AOP、javax.servlet.Filter，与装饰模式很像</li></ul><h2 id="三、静态代理"><a href="#三、静态代理" class="headerlink" title="三、静态代理"></a>三、静态代理</h2><ul><li>使用继承的方式实现代理</li><li>使用组合的方式实现代理</li></ul><a id="more"></a><ul><li><p>缺点</p><ul><li>需要为不同的代理逻辑编写新的代理类</li></ul></li><li><p>角色</p><ul><li>代理</li><li>被代理对象</li></ul></li><li><p>类图</p><ul><li>代理和被代理对象都实现了同一个接口</li></ul></li></ul><h2 id="四、动态代理"><a href="#四、动态代理" class="headerlink" title="四、动态代理"></a>四、动态代理</h2><ul><li><h3 id="4-1JDK动态代理（接口代理）"><a href="#4-1JDK动态代理（接口代理）" class="headerlink" title="4.1JDK动态代理（接口代理）"></a>4.1JDK动态代理（接口代理）</h3></li><li><p>局限</p><ul><li>被代理类必须要实现至少一个接口</li><li>通过反编译查看生成的代理类，其实实现了指定的接口</li></ul></li><li><p>使用步骤</p><p>1.先定义一个接口</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Moveable</span></span>&#123;</div><div class="line">   <span class="function"><span class="keyword">void</span> <span class="title">move</span><span class="params">()</span></span>;</div><div class="line"> &#125;</div></pre></td></tr></table></figure><p>​        2.定义InvacationHandler</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> MyInvocationhandler implement InvocationHandler&#123;</div><div class="line">Moveable object;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">MyInvocationhandler</span><span class="params">(Moveable object)</span></span>&#123;</div><div class="line"> <span class="keyword">this</span>.object=object;</div><div class="line">&#125;</div><div class="line">  </div><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method , Object[] args)</span></span>&#123;</div><div class="line"></div><div class="line">System.out.println(<span class="string">"执行之前！"</span>);</div><div class="line"><span class="keyword">return</span> method.invoke(object,args);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>​        3.通过JDK API生成接口的代理对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Proxy.newProxyInstance(MoveableSub.class.getClassLoader(), <span class="keyword">new</span> Class[]&#123;Moveable.class&#125;,<span class="keyword">new</span> MyInvocationHandler(<span class="keyword">new</span> MoveableSub()))</div></pre></td></tr></table></figure><p>​        4.可以通过设置，将生成的字节码文件（代理类）保存到本地    </p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">System.setProperty(<span class="string">"sun.misc.ProxyGenerator.saveGeneratedFiles"</span>,<span class="string">"true"</span>)</div></pre></td></tr></table></figure><ul><li><p>原理</p><ul><li><p>a&gt; 使用的是一个小而快的字节码工具ASM，生成代理类。因此，Java的动态语言特性其实就是ASM。</p></li><li><p>b&gt; ASM可以直接修改class二进制字节码。</p></li></ul></li></ul><ul><li><h3 id="4-2-Instrument动态代理"><a href="#4-2-Instrument动态代理" class="headerlink" title="4.2 Instrument动态代理"></a>4.2 Instrument动态代理</h3><ul><li>Instrument是一个类似ASM的工具</li><li>原理是在将二进制字节码加载到JVM之前，篡改二进制字节码</li></ul></li><li><h3 id="4-3-CGLIB动态代理（子类代理）"><a href="#4-3-CGLIB动态代理（子类代理）" class="headerlink" title="4.3 CGLIB动态代理（子类代理）"></a>4.3 CGLIB动态代理（子类代理）</h3></li><li><p>局限</p><ul><li>不能对final修饰的类生成代理子类，但是ASM可以突破这种语法上的限制。</li></ul></li><li><p>原理</p><ul><li>底层也是使用ASM工具。</li></ul></li><li><p>使用步骤</p><p>​    1.引入maven依赖</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/cglib/cglib --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cglib<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>cglib<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure><p>​        2.编写一个需要被代理的类Example</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Example</span></span>&#123;</div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">action</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line">   System.out.println(<span class="string">"我是被代理对象！"</span>);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>​        3.编写代理逻辑（拦截的逻辑）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> MyInterceptor implement MethodInterceptor &#123;</div><div class="line"></div><div class="line"><span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">intercept</span><span class="params">(Object o, Method method, Object[] objects, MethodProxy methodProxy)</span> <span class="keyword">throws</span> Throwable </span>&#123;</div><div class="line">        System.out.println(<span class="string">"这个是产生的代理对象："</span>+o.getClass().getName());    </div><div class="line">    Object invoke =methodProxy.invokeSuper(o,objects);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> invoke;</div><div class="line"></div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>​        4.Main逻辑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Enhancer enhancer=<span class="keyword">new</span> Enhancer();</div><div class="line">enhancer.setSuperClass(Example.class);</div><div class="line">enhancer.setInterceptor(<span class="keyword">new</span> MyInterceptor());</div><div class="line">Example proxy=enhancer.create();</div><div class="line">proxy.action();</div></pre></td></tr></table></figure><h2 id="五、常见案例"><a href="#五、常见案例" class="headerlink" title="五、常见案例"></a>五、常见案例</h2><ul><li>Spring AOP使用了JDK动态代理和CGLIB子类代理</li></ul><h2 id="六、疑问？"><a href="#六、疑问？" class="headerlink" title="六、疑问？"></a>六、疑问？</h2><ul><li><p>JDK动态代理中如果接口当中定义了多个方法，是否生成的代理类中这些方法是否都调用了InvocationHandler::invoke()方法？</p><ul><li>是的，可以通过查看生成代理类的反编译源代码可以知道，代理子类中所有的方法都调用了InvocationHandler::invoke()</li></ul></li></ul><h2 id="七、项目GitHub地址"><a href="#七、项目GitHub地址" class="headerlink" title="七、项目GitHub地址"></a>七、项目GitHub地址</h2><p>​    <a href="https://github.com/tokerr/designpatterns/tree/master/src/main/java/com/nyt/proxy" target="_blank" rel="external">https://github.com/tokerr/designpatterns/tree/master/src/main/java/com/nyt/proxy</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;代理模式（Proxy）&quot;&gt;&lt;a href=&quot;#代理模式（Proxy）&quot; class=&quot;headerlink&quot; title=&quot;代理模式（Proxy）&quot;&gt;&lt;/a&gt;代理模式（Proxy）&lt;/h2&gt;&lt;h2 id=&quot;一、说明&quot;&gt;&lt;a href=&quot;#一、说明&quot; class=&quot;headerlink&quot; title=&quot;一、说明&quot;&gt;&lt;/a&gt;一、说明&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;本文当中出现的代码均为伪代码，可参考文章末尾列出的项目代码地址。&lt;/li&gt;
&lt;li&gt;假设我们的jar包使用maven进行管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;二、模式定义&quot;&gt;&lt;a href=&quot;#二、模式定义&quot; class=&quot;headerlink&quot; title=&quot;二、模式定义&quot;&gt;&lt;/a&gt;二、模式定义&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;对访问（或请求）实现拦截和权限的控制，以决定是否需要执行用户的请求。常见的代理体现有Spring AOP、javax.servlet.Filter，与装饰模式很像&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;三、静态代理&quot;&gt;&lt;a href=&quot;#三、静态代理&quot; class=&quot;headerlink&quot; title=&quot;三、静态代理&quot;&gt;&lt;/a&gt;三、静态代理&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;使用继承的方式实现代理&lt;/li&gt;
&lt;li&gt;使用组合的方式实现代理&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="设计模式" scheme="https://tokerr.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="CGLIB" scheme="https://tokerr.github.io/tags/CGLIB/"/>
    
      <category term="DesignPattern" scheme="https://tokerr.github.io/tags/DesignPattern/"/>
    
  </entry>
  
  <entry>
    <title>Java线程池ThreadPoolExecutor</title>
    <link href="https://tokerr.github.io/2020/02/16/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor/"/>
    <id>https://tokerr.github.io/2020/02/16/Java线程池ThreadPoolExecutor/</id>
    <published>2020-02-16T09:56:00.000Z</published>
    <updated>2020-02-16T10:03:45.456Z</updated>
    
    <content type="html"><![CDATA[<p>ThreadPoolExecutor是JDK中线程池的重要体现，JDK中的Executors工厂类，提供了不同ThreaPoolExecutor方法，本章的内容主要是对ThreadPoolExecutor的内部结构、运行原理和重点参数做介绍。</p><h1 id="一、继承关系图"><a href="#一、继承关系图" class="headerlink" title="一、继承关系图"></a>一、继承关系图</h1><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/3/3.png" alt="类继承关系图"></p><p>#二、内部结构组成</p><ul><li>核心线程数</li><li>最大线程数工作队列</li><li>工作队列</li></ul><a id="more"></a><h1 id="三、构造参数说明"><a href="#三、构造参数说明" class="headerlink" title="三、构造参数说明"></a>三、构造参数说明</h1><ul><li><p>corePoolSize：核心线程的数量</p></li><li><p>maximumPoolSize：最大线程的数量</p></li><li><p>keepAliveTime：普通线程空间之后的存活时间</p></li><li><p>workQueue：类型为BlockingQueue的工作队列，用于保存等待执行任务的任务阻塞队列，有以下几种：</p><pre><code>1） ArrayBlockingQueue：是一个基于数组实现的有界阻塞队列2）LinkedBlockingQueue：一个基于链表结构的无解阻塞队列3）SynchronousQueue：一个不存储元素的阻塞队列，每一个插入操作都必须等待另一个线程调用移除操作，否则一直处于阻塞状态</code></pre></li><li><p>RejectedExecutionHandler：饱和策略</p><p>1）CallerRunPolicy：只用调用者所在的线程来处理任务</p><p>2）AbortPolicy（默认）：表示无法处理新任务时抛出异常<br>3）DiscardPolicy：不处理，直接丢弃<br>4）DiscardOldestPolicy：丢弃工作队列里最近的一个任务，并执行当前任务</p></li></ul><h1 id="四、内部运行原理"><a href="#四、内部运行原理" class="headerlink" title="四、内部运行原理"></a>四、内部运行原理</h1><p>​        线程池初始化完毕之后，内部先创建的线程属于核心线程<br>​        假设n为线程池中当前未完成的任务数量；因为有可能会出现类似CacheThreadPool的线程池（它的corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE） ，因此以下情况我们假设：corePoolSize &lt; maximumPoolSize。</p><ol><li>当n &lt; corePoolSize时，对于新提交的任务，将创建新的线程去执行<pre><code>执行这一步需要获取全局锁</code></pre></li><li>当n &gt;= corePoolSize时，对于提交的新任务，将任务保存到工作队列中，当核心线程中有执行完自己的任务，空闲下来后，则从工作队列中取出任务执行</li><li>如果工作队列任务已满，并且maximumPoolSize  &gt;= n &gt;时，对于新提交的任务，将创建新的线程去执行<pre><code>执行这一步需要获取全局锁        </code></pre></li><li>当 n &gt;maximumPoolSize 时，对于新提交的任务，将使用饱和策略进行处理</li></ol><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/3/2.png" alt="ThreadPoolExecutor执行图"></p><h1 id="五、向线程池提交任务的方法"><a href="#五、向线程池提交任务的方法" class="headerlink" title="五、向线程池提交任务的方法"></a>五、向线程池提交任务的方法</h1><ol><li>Executor::execute()方法<pre><code>这个方法用于提交不需要返回值的任务，所以无法判断任务是否被线程执行成功，输入的类型是Runnable    </code></pre></li><li>ExecutorService::submit()方法<pre><code>这个方法用于提交需要返回值的任务，方法可以输入Runnable或者Callable，方法返回一个Future类型的对象，通过Future::get()获取返回值</code></pre></li></ol><h1 id="六、关闭线程池"><a href="#六、关闭线程池" class="headerlink" title="六、关闭线程池"></a>六、关闭线程池</h1><p>​        调用shutdown()或shutdownNow()方法来关闭线程池，他们的原理都是遍历线程池中的工作线程，然后逐个调用interrupt()方法中断线程。两者的区别在于，shutdownNow()首先将线程池的状态设置为STOP，然后尝试停止所有的正在执行的或者暂停任务的线程，并返回等待执行任务的列表。shutdown()只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ThreadPoolExecutor是JDK中线程池的重要体现，JDK中的Executors工厂类，提供了不同ThreaPoolExecutor方法，本章的内容主要是对ThreadPoolExecutor的内部结构、运行原理和重点参数做介绍。&lt;/p&gt;
&lt;h1 id=&quot;一、继承关系图&quot;&gt;&lt;a href=&quot;#一、继承关系图&quot; class=&quot;headerlink&quot; title=&quot;一、继承关系图&quot;&gt;&lt;/a&gt;一、继承关系图&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/pic/master/img/3/3.png&quot; alt=&quot;类继承关系图&quot;&gt;&lt;/p&gt;
&lt;p&gt;#二、内部结构组成&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心线程数&lt;/li&gt;
&lt;li&gt;最大线程数工作队列&lt;/li&gt;
&lt;li&gt;工作队列&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="线程池" scheme="https://tokerr.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    
      <category term="多线程" scheme="https://tokerr.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>事务隔离级别</title>
    <link href="https://tokerr.github.io/2019/12/01/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
    <id>https://tokerr.github.io/2019/12/01/事务隔离级别/</id>
    <published>2019-12-01T11:40:11.000Z</published>
    <updated>2019-12-01T12:40:40.639Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​    本文就Mysql数据库的事务进行阐述，包括事务的ACID特性、事务的隔离级别、事务隔离级别解决的问题、事务隔离级别的实现等内容。</p><h2 id="事务的四大特性"><a href="#事务的四大特性" class="headerlink" title="事务的四大特性"></a>事务的四大特性</h2><p>事务的ACID特性，也称为事务的四大特性，分别是：</p><ul><li>原子性（Atomicity）</li><li>一致性（Consistency）</li><li>隔离性（Isolation）</li><li>持久性（Durability）</li></ul><h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><p>​    事务的隔离性，当数据库中有多个事务执行的时候，就有可能出现“脏读”、“不可重复读”、“幻读”的问题，为了解决这些问题，于是就有了事务的“隔离级别”，事务的隔离级别包括：</p><ul><li>读未提交（Read uncommitted）</li><li>读已提交（Read committed）</li><li>可重复读（Repeatable read）</li><li>串行化（Serializable）</li></ul><a id="more"></a><p>这里一张图可以清楚的看到，不同的隔离级别下可能会出现的问题（X表示不会出现，V表示可能出现）。</p><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/2.jpg" alt="1.png"></p><p>​    从上往下，事务的隔离级别依次递增，隔离级别越高导致数据库的处理效率越低。所以，需要选择适合自己业务系统的隔离级别，Mysql默认的隔离级别是“可重复读”、Oracle默认的隔离级别是“读已提交”。在将Oracle的数据迁移到Mysql的时候，记得将Mysql的事务隔离级别设置成“读已提交”。Mysql可以通过如下的方式查看和修改事务隔离级别。</p><p>​    使用 show variables 方式查询事务隔离级别：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">show variables like &quot;transaction_isolation&quot;;</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/1.png" alt="查看事务隔离级别"></p><p>修改事务隔离级别，可以通过修改配置文件，或者在线的方式修改。</p><ol><li><p>修改配置，在系统全局生效：</p><p>在my.cnf中添加或者修改如下配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[mysqld]</div><div class="line">transaction_isolation=REPEATABLE-READ</div></pre></td></tr></table></figure><p>transaction-isolation可选的值有READ-UNCOMMITTED、READ-COMMITTED、REPEATABLE-READ、SERIALIZABLE。</p><p>修改完成需要重启mysql。</p></li><li><p>修改当前会话的隔离级别（在线方式）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set session transaction isolation level read committed;</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/3.png" alt="3"></p></li><li><p>如果希望通过在线方式，全局修改事务隔离级别:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set global transaction isolation level read uncommitted;</div></pre></td></tr></table></figure><p>分别查看全局和当前会话的事务隔离级别：</p><p><img src="https://raw.githubusercontent.com/tokerr/pic/master/img/2/4.png" alt="4"></p></li></ol><h2 id="事务隔离级别解决的问题"><a href="#事务隔离级别解决的问题" class="headerlink" title="事务隔离级别解决的问题"></a>事务隔离级别解决的问题</h2><p>事务的隔离级别解决的是“脏读（dirty read）”、“不可重复读（non-repeatable read）”、“幻读（phantom read）”的问题。</p><ul><li>脏读：指的是一个事务读取到另一个事务没有提交的数据。</li><li>不可重复读：指的是一个事务访问同一条数据多次，得到的是不同的结果。偏向于指数据的修改。</li><li>幻读：指的是一个事务访问到 同时后者后启动事务插入的数据。偏向于指数据的插入和删除。</li></ul><h2 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h2><ol><li><p>显示启动事务语句，begin或者start transaction。配套的提交语句是commit ，回滚语句是rollback;</p></li><li><p>set autocommit=0，这个语句会将线程的自动提交关闭。<strong>为了避免长事务</strong>，应将自动提交开启：set autocommit=1。mysql默认是开启的。</p><p>我们可以通过查询information_schema库的innodb_trx这个表中查询长事务。如下语句是查询持续时间超过60s事务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60;</div></pre></td></tr></table></figure></li></ol><h2 id="一致性读视图"><a href="#一致性读视图" class="headerlink" title="一致性读视图"></a>一致性读视图</h2><ol><li><p>使用begin或者start transaction的方式启动事务，一致性读视图是在执行第一个快照读语句的时候创建的。</p></li><li><p>使用如下语句启动事务，一致性读视图是在执行该语句的时候创建的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">start transaction with consistent snapshot;</div></pre></td></tr></table></figure></li></ol><p>注意，mysql里面有两个视图的概念：</p><ul><li>一个是view。是用查询语句定义的一个虚拟表，创建视图的语法是create view …，查询方式与表一样。</li><li>另一个就是这里提到的，在innodb里面MVCC用到的一致性读视图：consistent read view，用于支持‘读已提交’和‘可重复读’事务隔离级别的实现。</li></ul><h2 id="事务隔离级别的实现"><a href="#事务隔离级别的实现" class="headerlink" title="事务隔离级别的实现"></a>事务隔离级别的实现</h2><p>​    针对读已提交和可重复读两种事务隔离级别，在实现上，数据库会创建一个“一致性读视图”，事务访问的时候以一致性读视图的逻辑结果为准。可重复读级别的一致性读视图，是在事务启动的时候创建，整个时候存在期间都用这个视图；读已提交级别的一致性读视图是在每个SQL语句开始执行的时候创建的。读未提交级别直接返回记录上最新的记录，串行化级别使用加锁的方式避免并行访问，没有“一致性读视图”的概念。</p><p>​    InnoDB中每一行记录都有多个版本（MySQL默认使用InnoDB存储引擎），也就是数据库的多版本并发控制（MVCC）。</p><p>​    MySQL对每一条的记录更新都会记录一条回滚日志（undo log），记录最新的值，同时通过回滚日志可以得到上一个状态的值。</p><p>​    对于不同的‘一致性读视图’，可以通过对当前值，依次执行undo log回滚得到。</p><p>​    回滚日志什么时候删除？mysql会判断，当没有比这个回滚日志更早的一致性读视图时，会将这个回滚日志删除掉。因此，建议不要使用长事务，长事务会导致回滚日志很大，会导致大量占用存储空间。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;​    本文就Mysql数据库的事务进行阐述，包括事务的ACID特性、事务的隔离级别、事务隔离级别解决的问题、事务隔离级别的实现等内容。&lt;/p&gt;
&lt;h2 id=&quot;事务的四大特性&quot;&gt;&lt;a href=&quot;#事务的四大特性&quot; class=&quot;headerlink&quot; title=&quot;事务的四大特性&quot;&gt;&lt;/a&gt;事务的四大特性&lt;/h2&gt;&lt;p&gt;事务的ACID特性，也称为事务的四大特性，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原子性（Atomicity）&lt;/li&gt;
&lt;li&gt;一致性（Consistency）&lt;/li&gt;
&lt;li&gt;隔离性（Isolation）&lt;/li&gt;
&lt;li&gt;持久性（Durability）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;事务的隔离级别&quot;&gt;&lt;a href=&quot;#事务的隔离级别&quot; class=&quot;headerlink&quot; title=&quot;事务的隔离级别&quot;&gt;&lt;/a&gt;事务的隔离级别&lt;/h2&gt;&lt;p&gt;​    事务的隔离性，当数据库中有多个事务执行的时候，就有可能出现“脏读”、“不可重复读”、“幻读”的问题，为了解决这些问题，于是就有了事务的“隔离级别”，事务的隔离级别包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交（Read uncommitted）&lt;/li&gt;
&lt;li&gt;读已提交（Read committed）&lt;/li&gt;
&lt;li&gt;可重复读（Repeatable read）&lt;/li&gt;
&lt;li&gt;串行化（Serializable）&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="mysql" scheme="https://tokerr.github.io/tags/mysql/"/>
    
      <category term="事务" scheme="https://tokerr.github.io/tags/%E4%BA%8B%E5%8A%A1/"/>
    
      <category term="事务隔离级别" scheme="https://tokerr.github.io/tags/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>Java内存区域与内存溢出异常</title>
    <link href="https://tokerr.github.io/2018/06/02/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8/"/>
    <id>https://tokerr.github.io/2018/06/02/Java内存区域与内存溢出异常/</id>
    <published>2018-06-02T15:48:41.000Z</published>
    <updated>2019-05-01T13:51:07.474Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h1><p>Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。</p><p>Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。</p><p>无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。</p><p>通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。<br><a id="more"></a></p><h1 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h1><p>Java虚拟机在<strong>执行Java程序的过程</strong>中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和技术而简历和销毁的。Java虚拟所管理的内存区域将会包括一下几个运行时数据区域。</p><h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2><p><strong>介绍:</strong><br>程序计数器(Program counter register)是一块较小的内存控件，它的作用可以看做是当前线程所执行的字节码的行号指示器。</p><p><strong>作用：</strong><br>在虚拟机的概念模型里，字节码的解析器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程回复等基础功能都需要依赖这个计数器来完成。</p><p><strong>服务对象：</strong><br>由于Java虚拟机的多线程是通过线程的轮流切换并分配处理器执行时间的方式来时间的，在任何一个确定的时刻，一个处理器(对于多核处理器来说是一个内核)只会执行一条线程中的指令。因此，为了线程钱换后能回复到正确的执行为孩子，每条线程都需要有一个独立的程序计数器，各个线程之间的计数器互不影响，独立储存，我们称这块内存区域为”线程私有”的内存。</p><p>如果线程正在执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；此内存区域是唯一一个在Java虚拟规范中没有规定任何OutOfMemoryError情况的区域。</p><h2 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h2><p><strong>介绍：</strong><br>与程序计数器一样，Java虚拟机栈(JVM Stacks)也是线程自由的，他的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作栈、动态连接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应这一个栈帧在虚拟机栈中从入栈和出栈的过程。</p><p>局部变量表存放了编译期可知的各种基本数据类型(boolean,byte,char,short,int,float,long,double)、对象引用和returnAddress类型(指向了一条字节码指令的地址)。局部变量表所需要的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p><p>在Java虚拟机规范中，对这个区域规定了两种异常状况:<br>如果线程的栈深度大于虚拟机所允许的深的，将抛出StackOverflowError异常；<br>如果虚拟机栈可以动态拓展，当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常。</p><h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2><p>本地方法栈(Native Method Stacks)与虚拟机栈所发挥的作用是非常的相似，其区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则是为虚拟机使用到的Navite方法服务。</p><p>简单地讲，一个Native Method就是一个java调用非java代码的接口，该方法的实现由非java语言实现。</p><h2 id="java堆"><a href="#java堆" class="headerlink" title="java堆"></a>java堆</h2><p>对于大多数的应用，Java堆(Java heap)是java虚拟机所管理的内存中最大的一块。java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例在这里分配内存。</p><p>java堆是垃圾收集器管理的主要区域，因此很多时候也被称为”GC堆”。</p><h2 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h2><p>方法区(Method Area)与java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。</p><h3 id="PermGen（永久代）"><a href="#PermGen（永久代）" class="headerlink" title="PermGen（永久代）"></a>PermGen（永久代）</h3><p>绝大部分 Java 程序员应该都见过 “java.lang.OutOfMemoryError: PermGen space “这个异常。这里的 “PermGen space”其实指的就是方法区。不过方法区和“PermGen space”又有着本质的区别。前者是 JVM 的规范，而后者则是 JVM 规范的一种实现，并且只有 HotSpot 才有 “PermGen space”，而对于其他类型的虚拟机，如 JRockit（Oracle）、J9（IBM） 并没有“PermGen space”。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。最典型的场景就是，在 jsp 页面比较多的情况，容易出现永久代内存溢出。</p><p>在 JDK 1.8 中， HotSpot 已经没有 “PermGen space”这个区间了，取而代之是一个叫做 Metaspace（元空间） 的东西。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言：&quot;&gt;&lt;a href=&quot;#前言：&quot; class=&quot;headerlink&quot; title=&quot;前言：&quot;&gt;&lt;/a&gt;前言：&lt;/h1&gt;&lt;p&gt;Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人想出来。&lt;/p&gt;
&lt;p&gt;Java程序员把内存控制的权利交给了Java虚拟机（简称：jvm），一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那排插错误将会成为一项异常艰难的工作。&lt;/p&gt;
&lt;p&gt;无论是简单的只是做做增删改查的系统，还是做一个产品也好，很有必要去学习其虚拟机的内存底层结构，以及内存是如何分配和回收的，有助于程序员敲出更高效和稳定的代码。&lt;/p&gt;
&lt;p&gt;通过这篇文章，从概念上介绍JVM内存的各个区域，这些区域的作用、服务对象以及其中可能产生的问题。&lt;br&gt;
    
    </summary>
    
    
      <category term="jvm" scheme="https://tokerr.github.io/tags/jvm/"/>
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>hadoop2.9.0 编译源码安装</title>
    <link href="https://tokerr.github.io/2017/12/17/hadoop2-9-0-%E7%BC%96%E8%AF%91%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85/"/>
    <id>https://tokerr.github.io/2017/12/17/hadoop2-9-0-编译源码安装/</id>
    <published>2017-12-17T11:10:01.000Z</published>
    <updated>2019-05-01T13:51:07.476Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-编译基础环境"><a href="#1-编译基础环境" class="headerlink" title="1.编译基础环境"></a>1.编译基础环境</h3><pre><code>Requirements:* Unix System (我这里使用的是centos 6.8)* JDK 1.8+* Maven 3.0 or later* Findbugs 1.3.9 (if running findbugs)* ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错）* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac* Zlib devel (if compiling native code)* openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance)* Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs)* Internet connection for first build (to fetch all Maven and Hadoop dependencies)* python (for releasedocs)* bats (for shell code testing)* Node.js / bower / Ember-cli (for YARN UI v2 building)</code></pre><a id="more"></a><p>备注：由于这里的教程基本都是使用在线安装的方式，包括后面的使用maven对hadoop2.9的源码进行编译，需要下载依赖包，因此请确保服务器连接外网，如果你使用的是vmware虚拟机，可以参考我另一篇博客 <a href="https://tokerr.github.io/2017/12/17/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/">vmware虚拟机host-only下配置与宿主机共享网络</a>。</p><h3 id="2-yum-源配置"><a href="#2-yum-源配置" class="headerlink" title="2.yum 源配置"></a>2.yum 源配置</h3><ul><li><p>首先安装wget （已安装则忽略）</p><p>  yum install -y wget</p></li><li><p>将CentOS的yum源更换为国内的阿里云源，我们使用默认的yum源，有时会连接到国外的镜像站导致yum下载比较慢。，所以将默认的yum源替换为阿里云的镜像站。</p></li></ul><p>阿里云Linux安装镜像源地址：<a href="http://mirrors.aliyun.com/" target="_blank" rel="external">http://mirrors.aliyun.com/</a></p><p>备份你的原镜像文件，以免出错后可以恢复。</p><pre><code>mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</code></pre><ul><li>下载新的CentOS-Base.repo 到/etc/yum.repos.d/</li></ul><p>CentOS 5 使用下面的链接</p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo</code></pre><p>CentOS 6 使用下面的链接</p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo</code></pre><p>CentOS 7 使用下面的链接</p><pre><code>wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</code></pre><ul><li><p>运行yum makecache生成缓存</p><p>  yum clean all<br><br>  yum makecache</p></li></ul><h3 id="3-yum-安装gcc"><a href="#3-yum-安装gcc" class="headerlink" title="3.yum 安装gcc"></a>3.yum 安装gcc</h3><p>对于配备了yum的Linux发行版而言，安装gcc编译器就变得so easy。我们只需要分别执行如下命令即可：</p><pre><code>yum -y install gcc gcc-c++ kernel-devel</code></pre><h3 id="4-安装CMake"><a href="#4-安装CMake" class="headerlink" title="4.安装CMake"></a>4.安装CMake</h3><pre><code>#wget https://cmake.org/files/v3.3/cmake-3.3.2.tar.gz#tar -zxvf cmake-2.8.10.2.tar.gz#cd cmake-2.8.10.2#./bootstrap#gmake#gmake install</code></pre><h3 id="5-下载Hadoop源码包"><a href="#5-下载Hadoop源码包" class="headerlink" title="5.下载Hadoop源码包"></a>5.下载Hadoop源码包</h3><pre><code>[root@hadoop001 sourcecode]# mkdir -p /opt/sourcecode[root@hadoop001 sourcecode]#wget http://apache.mirrors.tds.net/hadoop/common/stable/hadoop-2.9.0-src.tar.gz[root@hadoop001 sourcecode]#tar -xzvf hadoop-2.9.0-src.tar.gz[root@hadoop001 sourcecode]#cat ./hadoop-2.9.0-src/BUILDING.txt#从BUILDING文件中我们可以看到编译的要求</code></pre><h3 id="6-JDK安装"><a href="#6-JDK安装" class="headerlink" title="6.JDK安装"></a>6.JDK安装</h3><p>这个安装起来相对简单，官网下载个tar包，解压配置环境变量就可以。可以自行百度和google ,可参考我如下系统环境变量配置文件：</p><pre><code># cat /etc/profileJAVA_HOME=/usr/local/work/jdk1.8.0_144MAVEN_HOME=/home/package/apache-maven-3.5.2FINDBUGS_HOME=/home/package/findbugs-3.0.1PROTOBUF_HOME=/usr/local/protobufHADOOP_HOME=/home/hadoop/hadoop-2.9.0CLASSPATH=.:$JAVA_HOME/lib/tools.jarPATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$FINDBUGS_HOME/bin:$PROTOBUF_HOME/bin:$HADOOP_HOME/bin:$PATHexport JAVA_HOME MAVEN_HOME FINDBUGS_HOME PROTOBUF_HOME HADOOP_HOME CLASSPATH PATH</code></pre><h3 id="7-Maven安装"><a href="#7-Maven安装" class="headerlink" title="7.Maven安装"></a>7.Maven安装</h3><pre><code>#wget 获取tar包#解压#配置环境变量mvn --version #验证</code></pre><h3 id="8-protobuf安装"><a href="#8-protobuf安装" class="headerlink" title="8.protobuf安装"></a>8.protobuf安装</h3><p>protobuf要编译安装，需安装gcc、gcc-c++、 make</p><pre><code>上传 protobuf-2.5.0.tar.gztar -xzvf protobuf-2.5.0.tar.gzcd protobuf-2.5.0yum install -y gcc gcc-c++ make./configure --prefix=/usr/local/protobufmake &amp;&amp; make install#添加protobuf环境变量source /etc/profileprotoc --version</code></pre><h3 id="9-Findbugs安装"><a href="#9-Findbugs安装" class="headerlink" title="9.Findbugs安装"></a>9.Findbugs安装</h3><p>下载tar包，解压，配置环境变量</p><h3 id="10-安装snappy1-1-4-使Hadoop支持snappy压缩10-Snappy压缩库安装"><a href="#10-安装snappy1-1-4-使Hadoop支持snappy压缩10-Snappy压缩库安装" class="headerlink" title="10.安装snappy1.1.4,使Hadoop支持snappy压缩10.Snappy压缩库安装"></a>10.安装snappy1.1.4,使Hadoop支持snappy压缩10.Snappy压缩库安装</h3><pre><code>wget https://github.com/google/snappy/releases/download/1.1.4/snappy-1.1.4.tar.gztar -zxvf snappy-1.1.4.tar.gzcd snappy-1.1.4./configuremake &amp;&amp; make installll -h /usr/local/lib |grep snappy</code></pre><h3 id="11-其他依赖安装"><a href="#11-其他依赖安装" class="headerlink" title="11.其他依赖安装"></a>11.其他依赖安装</h3><pre><code>yum install -y ant openssl openssl-devel svn ncurses-devel zlib-devel libtool svnyum install -y snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop autoconf automake</code></pre><h3 id="12-编译"><a href="#12-编译" class="headerlink" title="12.编译"></a>12.编译</h3><p>进入Hadooop源码目录</p><pre><code>cd hadoop-2.9.0-srcmvn clean package -DskipTests -Pdist,native -Dtar -Dsnappy.lib=/usr/local/lib -Dbundle.snappy</code></pre><h3 id="13-生成tar包"><a href="#13-生成tar包" class="headerlink" title="13.生成tar包"></a>13.生成tar包</h3><p>/home/hadoop/hadoop-2.9.0-src/hadoop-dist/target/hadoop-2.9.0.tar.gz</p><p>以下是我maven编译完成的信息，时间还是比较长的，跟网络也有关系：</p><pre><code>[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 02:44 h[INFO] Finished at: 2017-12-17T15:26:30+08:00[INFO] Final Memory: 129M/237M[INFO] ------------------------------------------------------------------------</code></pre><p>注意事项：</p><ul><li>由于Maven仓库在墙外，Maven在编译项目时下载包卡住情况，ctrl+c 中断，重新执行编译。</li><li>如果出现提示缺少了某个文件的情况，则要先清理maven(使用命令 mvn clean) 再重新编译。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-编译基础环境&quot;&gt;&lt;a href=&quot;#1-编译基础环境&quot; class=&quot;headerlink&quot; title=&quot;1.编译基础环境&quot;&gt;&lt;/a&gt;1.编译基础环境&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;Requirements:
* Unix System (我这里使用的是centos 6.8)
* JDK 1.8+
* Maven 3.0 or later
* Findbugs 1.3.9 (if running findbugs)
* ProtocolBuffer 2.5.0 （注意版本一定要保持一致，也不能选择更高的版本，否则编译报错）
* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac
* Zlib devel (if compiling native code)
* openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance)
* Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs)
* Internet connection for first build (to fetch all Maven and Hadoop dependencies)
* python (for releasedocs)
* bats (for shell code testing)
* Node.js / bower / Ember-cli (for YARN UI v2 building)
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>虚拟机host-only下配置与宿主机共享网络</title>
    <link href="https://tokerr.github.io/2017/12/17/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/"/>
    <id>https://tokerr.github.io/2017/12/17/虚拟机host-only下配置与宿主机共享网络/</id>
    <published>2017-12-17T10:52:41.000Z</published>
    <updated>2019-05-01T13:51:07.481Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul><li>示例环境：</li><li>宿主机：windows7</li><li>虚拟机软件：vmware 12 pro</li><li>虚拟机：centos 6.8</li></ul><p>备注：假设以上的环境已经全部安装完毕</p><h2 id="1-在windows下打开网络适配器设置页面"><a href="#1-在windows下打开网络适配器设置页面" class="headerlink" title="1.在windows下打开网络适配器设置页面"></a>1.在windows下打开网络适配器设置页面</h2><p><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/1.png?raw=true" alt=""><br><a id="more"></a><br>点击进去，看到如下界面：<br><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/2.png?raw=true" alt=""></p><h2 id="2-宿主机所连接的外网通过windows网络共享给VMnet1"><a href="#2-宿主机所连接的外网通过windows网络共享给VMnet1" class="headerlink" title="2.宿主机所连接的外网通过windows网络共享给VMnet1"></a>2.宿主机所连接的外网通过windows网络共享给VMnet1</h2><p>截图可以看到我宿主机所连接的网络是‘无线网络连接’，右键点击其属性，然后切换到共享网卡，勾选“允许其他网络用户通过此计算机的Internet连接来连接”，“请选择一个专用连接”下拉框选择“VMware Network Adapter VMnet1”，点击确定。<br><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/3.png?raw=true" alt=""></p><p>此时会提示VMware Network Adapter VMnet1的IP地址被修改为192.168.137.1，客户机网络配置要用到这个信息（本例为192.168.137.1，<strong>注意，这里经过试验，尽量不要修改这个ip地址，否则会出现配置不成功的现象</strong>）。</p><h2 id="3-准备Linux环境"><a href="#3-准备Linux环境" class="headerlink" title="3.准备Linux环境"></a>3.准备Linux环境</h2><p>3.1点击VMware快捷方式，右键打开文件所在位置 -&gt; 双击vmnetcfg.exe -&gt; VMnet1 host-only -&gt;修改subnet ip 设置网段：192.168.137.0 子网掩码：255.255.255.0 –&gt; 同时关闭DHCP服务-&gt; apply -&gt; ok<br><img src="https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/4.png?raw=true" alt=""><br>在虚拟软件上 –My Computer -&gt; 选中虚拟机 -&gt; 右键 -&gt; settings -&gt; network adapter -&gt; host only -&gt; ok </p><p>3.3修改IP/配置DNS</p><p>vim /etc/sysconfig/network-scripts/ifcfg-eth0</p><pre><code>DEVICE=eth0TYPE=EthernetUUID=6169d30a-2243-4a7d-9f03-455d9e0cefa6ONBOOT=noNM_CONTROLLED=yes#BOOTPROTO=dhcpBOOTPROTO=static  ##设置静态IPADDR=192.168.137.101 ##配置ipNETMASK=255.255.255.0 ##配置子网GATEWAY=192.168.137.2 ##配置网关PREFIX=24DNS1=8.8.8.8 ##配置dnsDEFROUTE=yesIPV4_FAILURE_FATAL=yesIPV6INIT=noNAME=&quot;System eth0&quot;HWADDR=00:0C:29:44:CB:D8LAST_CONNECT=1513431454</code></pre><p>保存退出，重启网络服务：</p><pre><code>service network restart</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;示例环境：&lt;/li&gt;
&lt;li&gt;宿主机：windows7&lt;/li&gt;
&lt;li&gt;虚拟机软件：vmware 12 pro&lt;/li&gt;
&lt;li&gt;虚拟机：centos 6.8&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;备注：假设以上的环境已经全部安装完毕&lt;/p&gt;
&lt;h2 id=&quot;1-在windows下打开网络适配器设置页面&quot;&gt;&lt;a href=&quot;#1-在windows下打开网络适配器设置页面&quot; class=&quot;headerlink&quot; title=&quot;1.在windows下打开网络适配器设置页面&quot;&gt;&lt;/a&gt;1.在windows下打开网络适配器设置页面&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/tokerr/markdownImage/blob/master/%E8%99%9A%E6%8B%9F%E6%9C%BAhost-only%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C/1.png?raw=true&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="vmware" scheme="https://tokerr.github.io/tags/vmware/"/>
    
  </entry>
  
  <entry>
    <title>负载均衡session共享解决方法整理</title>
    <link href="https://tokerr.github.io/2017/11/20/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1session%E5%85%B1%E4%BA%AB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E6%95%B4%E7%90%86/"/>
    <id>https://tokerr.github.io/2017/11/20/负载均衡session共享解决方法整理/</id>
    <published>2017-11-20T15:44:36.000Z</published>
    <updated>2019-05-01T13:51:07.482Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、背景："><a href="#一、背景：" class="headerlink" title="一、背景："></a>一、背景：</h2><p>最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！</p><p>项目属于JavaWeb项目，部署在Tomcat环境下。</p><h2 id="二、tomcat集群环境下session共享方法整理"><a href="#二、tomcat集群环境下session共享方法整理" class="headerlink" title="二、tomcat集群环境下session共享方法整理"></a>二、tomcat集群环境下session共享方法整理</h2><p>在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路：</p><p>一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；<br><a id="more"></a><br>二是在集群中左右的节点进行Session数据的同步拷贝，所有节点的均保存了所有的Session数据。</p><h3 id="2-1tomcat集群session同步方案有以下几种："><a href="#2-1tomcat集群session同步方案有以下几种：" class="headerlink" title="2.1tomcat集群session同步方案有以下几种："></a>2.1tomcat集群session同步方案有以下几种：</h3><p>1）使用tomcat自带的cluster方式，多个tomcat间自动实时复制session信息，配置起来很简单。使用组播的方式实现session的同步拷贝，但这个方案的效率比较低，在大并发下表现并不好。而且需要另外安装apache的HTTP Server，同样需要一台节点了协调session的拷贝，比较多余，使用的人少，网上的资料比较乱(建议去官网)。<strong>不推荐</strong>。</p><p>2）利用nginx的基于访问ip的hash路由策略，保证访问的ip始终被路由到同一个tomcat上，这个配置更简单。但如果应用是某一个局域网大量用户同时登录，这样负载均衡就没什么作用了。</p><p>3）利用nginx插件实现tomcat集群和session同步，nginx-upstream-jvm-route-0.1.tar.gz，是一个Nginx的扩展模块，用来实现基于Cookie的Session Sticky的功能。</p><p><strong>4）利用memcached实现（MSM工具）。memcached存储session，并把多个tomcat的session集中管理，前端在利用nginx负载均衡和动静态资源分离，在兼顾系统水平扩展的同时又能保证较高的性能。</strong></p><p><strong>5）利用redis实现。使用redis不仅仅可以将缓存的session持久化，还因为它支持的单个对象比较大，而且数据类型丰富，不只是缓存 session，还可以做其他用途，可以一举几得。</strong></p><p><strong>6）利用filter+cookie方式实现。这种方法比较推荐，因为它的服务器使用范围比较多，不仅限于tomcat ，而且实现的原理比较简单容易控制。</strong></p><p>最后三种方法是比较推荐，尝试过第一种方法，但是不推荐，原因已经写明；第四第五种方法，由于公司需要另外申请一台单独的session共享服务器，比较麻烦。最终还是选择了最后一种解决方案，思路简单，实现起来也不难。下面将介绍这种方案。</p><h2 id="三、cookie-filter解决session共享问题"><a href="#三、cookie-filter解决session共享问题" class="headerlink" title="三、cookie+filter解决session共享问题"></a>三、cookie+filter解决session共享问题</h2><p>下面是实现该方案涉及到的三个相关功能，重点在于过滤器的编写。</p><h3 id="3-1-登录成功通知浏览器保存cookie"><a href="#3-1-登录成功通知浏览器保存cookie" class="headerlink" title="3.1 登录成功通知浏览器保存cookie"></a>3.1 登录成功通知浏览器保存cookie</h3><pre><code>public static void setCookie(HttpServletResponse response, HttpServletRequest request, String cookieName,            String cookieValue) {        /**         * a.先判断是否存在cookie ，存在自己设置的cookie则重新设置过期的时间 b.不存在则创建自己cookie 通知客户端保存         * c.需要设置的属性如下： 设置value ,具体值视自己的业务而定，具体设置的之后可以通过构造方法设置name=value         * ，注意使用算法加密 设置编码 设置过期时间 ，设置与session过期时间一致 设置domain 设置path         */        // 声明 cookie        Cookie autoCookie = null;        // 获取所有的cookie        Cookie cookies[] = request.getCookies();        HttpSession session = request.getSession();        // session.getMaxInactiveInterval();//session失效时间，值小于等于0代表永不超时        // 遍历cookie        if (cookies != null &amp;&amp; cookies.length &gt; 0) {            for (Cookie cookie : cookies) {                // 判断是否存在自动登录记录                if (cookieName.equals(cookie.getName())) {                    autoCookie = cookie;// 赋值                    break;                }            }        }        if (autoCookie == null) {            // 不在创建            autoCookie = new Cookie(cookieName, cookieValue);        }        // 设置在执行秒数之后过期；负值意味着cookie不存储，浏览器退出则清除；值为零表示删除cookie        autoCookie.setMaxAge(expiry);// 设置7天之内过期        // 设置编码        // 设置域名domain 默认情况下，Cookie只会返回给发送它们的服务器。        autoCookie.setDomain(request.getServerName());        // 设置path        autoCookie.setPath(request.getContextPath());        // 浏览器的document对象中就看不到cookie        autoCookie.setHttpOnly(true);        response.addCookie(autoCookie);// 添加    }</code></pre><h3 id="3-2-登录退出通知浏览器清除cookie"><a href="#3-2-登录退出通知浏览器清除cookie" class="headerlink" title="3.2 登录退出通知浏览器清除cookie"></a>3.2 登录退出通知浏览器清除cookie</h3><pre><code>public static void cleanCookie(HttpServletRequest request, HttpServletResponse response, String cookieName) {        Cookie cookies[] = request.getCookies();        if (cookies != null &amp;&amp; cookies.length &gt; 0) {            for (Cookie cookie : cookies) {                if (cookieName.equals(cookie.getName())) {                    cookie.setPath(request.getContextPath());// 浏览器回以同Name同Path同Domain覆盖原来的cookie                    cookie.setDomain(request.getServerName());                    cookie.setMaxAge(0);// 通知浏览器删除                    response.addCookie(cookie);                }            }        }    }}</code></pre><h3 id="3-3-编写自动登录过滤器"><a href="#3-3-编写自动登录过滤器" class="headerlink" title="3.3 编写自动登录过滤器"></a>3.3 编写自动登录过滤器</h3><ul><li>1）获取cookie判断用户是否已经登录</li><li>2）未登录则放行</li><li>3）已登录并且本地服务器没有相关session会话信息，则执行自动登录流程</li><li><p>4）自动登录完毕放行</p><pre><code>@Override   public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain)           throws IOException, ServletException {       /**        * a.到session获取认证信息 ，存在则通过认证，放行并终止程序 不存在执行下一步 b.        * 不存在认证信息，获取cookie，遍历判断是否存在自己设置的cookie，不存在直接放行并终止程序 存在执行下一步        * c.执行自动登录流程，并查询用户必要的信息保存到session当中，执行完毕放行并终止程序        */       HttpServletRequest request = (HttpServletRequest) req;       HttpServletResponse response = (HttpServletResponse) resp;       HttpSession session = request.getSession();       Object token = session.getAttribute(Constant.USER_CONTEXT_LOGGED);       Cookie[] cookies = request.getCookies();       // 用户执行注销操作不进行自动登录       String uri = request.getRequestURI();       String logout = request.getParameter(&quot;logout&quot;);       if (uri.contains(&quot;/projectContextPath/index.html&quot;) &amp;&amp; logout != null &amp;&amp; &quot;true&quot;.equals(logout)) {           StringBuffer url = request.getRequestURL();           response.sendRedirect(url.toString());           return;       }       if (cookies != null &amp;&amp; cookies.length &gt; 0) {// 在session中没有获取到用户信息           Cookie autoCookie = null;// 已登录的cookie           for (Cookie cookie : cookies) {               // 未在本服务器登录，并且在客户端保存有响应的cookie，才会执行自动登录               if (Constant.COOKIE_NAME.equals(cookie.getName()) &amp;&amp; token == null) {// cookie存在                   autoCookie = cookie;               }           }           if (autoCookie != null ) {// 存在cookie                // 开始自动登录，视具体业务根据cookie中的信息查询用户的信息并保存到session中完成自动登录                                                                       startAutoLogin(request, response, autoCookie);           }       }       chain.doFilter(request, response);// 放行   }</code></pre></li></ul><p><em>另外， 安全性问题考虑，由于使用的是cookie保存了用户的信息，容易被黑客拦截篡改。通常cookie中会保存用户名、密码等敏感经过加密，很难反向破解，但也不是绝对的安全，黑客可以通过木马病毒盗取用户浏览器的cookie，直接骗取网站的信任。 最好是使用https。</em></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、背景：&quot;&gt;&lt;a href=&quot;#一、背景：&quot; class=&quot;headerlink&quot; title=&quot;一、背景：&quot;&gt;&lt;/a&gt;一、背景：&lt;/h2&gt;&lt;p&gt;最近项目需要上生产，需要部署的节点由原来的单台节点变成了两台节点，使用Nginx实现了负载均衡。因此，上生产之前必须解决登录出现的session共享问题。ps:运维与代码齐下，最后还是选择了一种比较合理并且自己熟悉的方式解决了这个问题！&lt;/p&gt;
&lt;p&gt;项目属于JavaWeb项目，部署在Tomcat环境下。&lt;/p&gt;
&lt;h2 id=&quot;二、tomcat集群环境下session共享方法整理&quot;&gt;&lt;a href=&quot;#二、tomcat集群环境下session共享方法整理&quot; class=&quot;headerlink&quot; title=&quot;二、tomcat集群环境下session共享方法整理&quot;&gt;&lt;/a&gt;二、tomcat集群环境下session共享方法整理&lt;/h2&gt;&lt;p&gt;在集群环境的多个节点保持数据的一致性，session信息这当中是非常重要的一块。要实现这一点，大致有两种思路：&lt;/p&gt;
&lt;p&gt;一是把所有的Session数据放在一台服务器或者数据库当中，集群中所有的节点通过访问这台Session服务器来获取数据；&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="session" scheme="https://tokerr.github.io/tags/session/"/>
    
      <category term="cookie" scheme="https://tokerr.github.io/tags/cookie/"/>
    
  </entry>
  
  <entry>
    <title>HBase简介（很好的梳理资料）</title>
    <link href="https://tokerr.github.io/2017/10/29/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/"/>
    <id>https://tokerr.github.io/2017/10/29/HBase简介（很好的梳理资料）/</id>
    <published>2017-10-29T11:30:30.000Z</published>
    <updated>2019-05-01T13:51:07.472Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博客梳理的太好了，附上大牛博主的<a href="http://jiajun.iteye.com/" target="_blank" rel="external">博客地址</a>。</p><h1 id="一、-简介"><a href="#一、-简介" class="headerlink" title="一、 简介"></a>一、 简介</h1><p><strong>history</strong></p><ul><li>started by chad walters and jim</li><li>2006.11 G release paper on BigTable</li><li>2007.2 inital HBase prototype created as Hadoop contrib</li><li>2007.10 First useable Hbase</li><li>2008.1 Hadoop become Apache top-level project and Hbase becomes subproject</li><li>2008.10 Hbase 0.18,0.19 released</li></ul><p>hbase是bigtable的开源山寨版本。是建立的hdfs之上，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统。<br><a id="more"></a><br>它介于nosql和RDBMS之间，仅能通过主键(row key)和主键的range来检索数据，仅支持单行事务(可通过hive支持来实现多表join等复杂操作)。主要用来存储非结构化和半结构化的松散数据。</p><p>与hadoop一样，Hbase目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。</p><p><br><br>HBase中的表一般有这样的特点：</p><ol><li>大：一个表可以有上亿行，上百万列</li><li>面向列:面向列(族)的存储和权限控制，列(族)独立检索。</li><li>稀疏:对于为空(null)的列，并不占用存储空间，因此，表可以设计的非常稀疏。</li></ol><p>下面一幅图是Hbase在Hadoop Ecosystem中的位置。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image.png" alt=""></p><h1 id="二、-逻辑视图"><a href="#二、-逻辑视图" class="headerlink" title="二、 逻辑视图"></a>二、 逻辑视图</h1><p>HBase以表的形式存储数据。表有行和列组成。列划分为若干个列族(row family)<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_11_.png" alt=""></p><h3 id="Row-Key"><a href="#Row-Key" class="headerlink" title="Row Key"></a>Row Key</h3><p>与nosql数据库们一样,row key是用来检索记录的主键。访问hbase table中的行，只有三种方式：</p><ol><li>通过单个row key访问</li><li>通过row key的range</li><li>全表扫描</li></ol><p>Row key行键 (Row key)可以是任意字符串(最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在hbase内部，row key保存为字节数组。</p><p>存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)<br>注意：<br>字典序对int排序的结果是1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,<br>…,9,91,92,93,94,95,96,97,98,99。要保持整形的自然序，行键必须用0作左填充。</p><p>行的一次读写是原子操作 (不论一次读写多少列)。这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。</p><h3 id="列族"><a href="#列族" class="headerlink" title="列族"></a>列族</h3><p>hbase表中的每个列，都归属与某个列族。列族是表的chema的一部分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如courses:history ， courses:math 都属于 courses 这个列族。<br>访问控制、磁盘和内存的使用统计都是在列族层面进行的。实际应用中，列族上的控制权限能 帮助我们管理不同类型的应用：我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据并创建继承的列族、一些应用则只允许浏览数据（甚至可能因 为隐私的原因不能浏览所有数据）。</p><h3 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h3><p>HBase中通过row和columns确定的为一个存贮单元称为cell。每个 cell都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64位整型。时间戳可以由hbase(在数据写入时自动 )赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个 cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。<br>为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，hbase提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。</p><h3 id="Cell"><a href="#Cell" class="headerlink" title="Cell"></a>Cell</h3><p>由{row key, column( =<family> + <label>), version} 唯一确定的单元。cell中的数据是没有类型的，全部是字节码形式存贮。</label></family></p><h1 id="三、-物理存储"><a href="#三、-物理存储" class="headerlink" title="三、 物理存储"></a>三、 物理存储</h1><p>1.已经提到过，Table中的所有行都按照row key的字典序排列。</p><p>2.Table 在行的方向上分割为多个Hregion。</p><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_1_.png" alt=""></p><p>3.region按大小分割的，每个表一开始只有一个region，随着数据不断插入表，region不断增大，当增大到一个阀值的时候，Hregion就会等分会两个新的Hregion。当table中的行不断增多，就会有越来越多的Hregion。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_2_.png" alt=""></p><p>4.Hregion是Hbase中分布式存储和负载均衡的最小单元。最小单元就表示不同的Hregion可以分布在不同的HRegion server上。但一个Hregion是不会拆分到多个server上的。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_3_.png" alt=""></p><p>5.<strong>HRegion虽然是分布式存储的最小单元，但并不是存储的最小单元。</strong></p><p>事实上，HRegion由一个或者多个Store组成，每个store保存一个columns family。</p><p>每个Strore又由一个memStore和0至多个StoreFile组成。如图：</p><p>StoreFile以HFile格式保存在HDFS上。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_4_.png" alt=""></p><p>HFile的格式为：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_5_.png" alt=""></p><p>Trailer部分的格式:<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_6_.png" alt=""></p><p><em>HFile分为六个部分：</em></p><ol><li>Data Block 段–保存表中的数据，这部分可以被压缩</li><li>Meta Block 段 (可选的)–保存用户自定义的kv对，可以被压缩。</li><li>File Info 段–Hfile的元信息，不被压缩，用户也可以在这一部分添加自己的元信息。</li><li>Data Block Index 段–Data Block的索引。每条索引的key是被索引的block的第一条记录的key。</li><li>Meta Block Index段 (可选的)–Meta Block的索引。</li><li>Trailer–这一段是定长的。保存了每一段的偏移量，读取一个HFile时，会首先 读取Trailer，Trailer保存了每个段的起始位置(段的Magic Number用来做安全check)，然后，DataBlock Index会被读取到内存中，这样，当检索某个key时，不需要扫描整个HFile，而只需从内存中找到key所在的block，通过一次磁盘io将整个 block读取到内存中，再找到需要的key。DataBlock Index采用LRU机制淘汰。</li></ol><p>HFile的Data Block，Meta Block通常采用压缩方式存储，压缩之后可以大大减少网络IO和磁盘IO，随之而来的开销当然是需要花费cpu进行压缩和解压缩。<br>目标Hfile的压缩支持两种方式：Gzip，Lzo。</p><p><em>HLog(WAL log)</em></p><p>WAL 意为Write ahead log(<a href="http://en.wikipedia.org/wiki/Write-ahead_logging)，类似mysql中的binlog,用来" target="_blank" rel="external">http://en.wikipedia.org/wiki/Write-ahead_logging)，类似mysql中的binlog,用来</a> 做灾难恢复只用，Hlog记录数据的所有变更,一旦数据修改，就可以从log中进行恢复。</p><p>每个Region Server维护一个Hlog,而不是每个Region一个。这样不同region(来自不同table)的日志会混在一起，这样做的目的是不断追加单个 文件相对于同时写多个文件而言，可以减少磁盘寻址次数，因此可以提高对table的写性能。带来的麻烦是，如果一台region server下线，为了恢复其上的region，需要将region server上的log进行拆分，然后分发到其它region server上进行恢复。</p><p>HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是”写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue，可参见上文描述。</p><h1 id="四、-系统架构"><a href="#四、-系统架构" class="headerlink" title="四、 系统架构"></a>四、 系统架构</h1><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_7_.png" alt=""><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_8_.png" alt=""></p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><ol><li>包含访问hbase的接口，client维护着一些cache来加快对hbase的访问，比如regione的位置信息。</li></ol><h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><ol><li>保证任何时候，集群中只有一个master</li><li>存贮所有Region的寻址入口。</li><li>实时监控Region Server的状态，将Region server的上线和下线信息实时通知给Master</li><li>存储Hbase的schema,包括有哪些table，每个table有哪些column family</li></ol><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><ol><li>为Region server分配region</li><li>负责region server的负载均衡</li><li>发现失效的region server并重新分配其上的region</li><li>GFS上的垃圾文件回收</li><li>处理schema更新请求</li></ol><h3 id="Region-Server"><a href="#Region-Server" class="headerlink" title="Region Server"></a>Region Server</h3><ol><li>Region server维护Master分配给它的region，处理对这些region的IO请求</li><li>Region server负责切分在运行过程中变得过大的region</li></ol><p>可以看到，client访问hbase上数据的过程并不需要master参与（寻址访问zookeeper和region server，数据读写访问regione server），master仅仅维护者table和region的元数据信息，负载很低。</p><h1 id="五、关键算法-流程"><a href="#五、关键算法-流程" class="headerlink" title="五、关键算法 / 流程"></a>五、关键算法 / 流程</h1><h3 id="region定位"><a href="#region定位" class="headerlink" title="region定位"></a>region定位</h3><p>系统如何找到某个row key (或者某个 row key range)所在的region</p><p>bigtable 使用三层类似B+树的结构来保存region位置。</p><p>第一层是保存zookeeper里面的文件，它持有root region的位置。</p><p>第二层root region是.META.表的第一个region其中保存了.META.z表其它region的位置。通过root region，我们就可以访问.META.表的数据。</p><p>.META.是第三层，它是一个特殊的表，保存了hbase中所有数据表的region 位置信息。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_9_.png" alt=""></p><p><strong>说明：</strong></p><p>1.root region永远不会被split，保证了最需要三次跳转，就能定位到任意region 。</p><p>2.META.表每行保存一个region的位置信息，row key 采用表名+表的最后一样编码而成。</p><p>3.为了加快访问，.META.表的全部region都保存在内存中。</p><p>假设，.META.表的一行在内存中大约占用1KB。并且每个region限制为128MB。</p><p>那么上面的三层结构可以保存的region数目为：</p><p>(128MB/1KB) * (128MB/1KB) = = 2(34)个region</p><p>4.client会将查询过的位置信息保存缓存起来，缓存不会主动失效，因此如果client上的缓存全部失效，则需要进行6次网络来回，才能定位到正确的region(其中三次用来发现缓存失效，另外三次用来获取位置信息)。</p><h3 id="读写过程"><a href="#读写过程" class="headerlink" title="读写过程"></a>读写过程</h3><p>上文提到，hbase使用MemStore和StoreFile存储对表的更新。</p><p>数据在更新时首先写入Log(WAL log)和内存(MemStore)中，MemStore中的数据是排序的，当MemStore累计到一定阈值时，就会创建一个新的MemStore，并 且将老的MemStore添加到flush队列，由单独的线程flush到磁盘上，成为一个StoreFile。于此同时，系统会在zookeeper中 记录一个redo point，表示这个时刻之前的变更已经持久化了。(minor compact)</p><p>当系统出现意外时，可能导致内存(MemStore)中的数据丢失，此时使用Log(WAL log)来恢复checkpoint之后的数据。</p><p>前面提到过StoreFile是只读的，一旦创建后就不可以再修改。因此Hbase的更 新其实是不断追加的操作。当一个Store中的StoreFile达到一定的阈值后，就会进行一次合并(major compact),将对同一个key的修改合并到一起，形成一个大的StoreFile，当StoreFile的大小达到一定阈值后，又会对 StoreFile进行split，等分为两个StoreFile。</p><p>由于对表的更新是不断追加的，处理读请求时，需要访问Store中全部的 StoreFile和MemStore，将他们的按照row key进行合并，由于StoreFile和MemStore都是经过排序的，并且StoreFile带有内存中索引，合并的过程还是比较快。</p><p>写请求处理过程<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HBase%E7%AE%80%E4%BB%8B%EF%BC%88%E5%BE%88%E5%A5%BD%E7%9A%84%E6%A2%B3%E7%90%86%E8%B5%84%E6%96%99%EF%BC%89/Image_10_.png" alt=""></p><ol><li>client向region server提交写请求</li><li>region server找到目标region</li><li>region检查数据是否与schema一致</li><li>如果客户端没有指定版本，则获取当前系统时间作为数据版本</li><li>将更新写入WAL log</li><li>将更新写入Memstore</li><li>判断Memstore的是否需要flush为Store文件。</li></ol><h3 id="region分配"><a href="#region分配" class="headerlink" title="region分配"></a>region分配</h3><p>任何时刻，一个region只能分配给一个region server。master记录了当前有哪些可用的region server。以及当前哪些region分配给了哪些region server，哪些region还没有分配。当存在未分配的region，并且有一个region server上有可用空间时，master就给这个region server发送一个装载请求，把region分配给这个region server。region server得到请求后，就开始对此region提供服务。</p><h3 id="region-server上线"><a href="#region-server上线" class="headerlink" title="region server上线"></a>region server上线</h3><p>master使用zookeeper来跟踪region server状态。当某个region server启动时，会首先在zookeeper上的server目录下建立代表自己的文件，并获得该文件的独占锁。由于master订阅了server 目录上的变更消息，当server目录下的文件出现新增或删除操作时，master可以得到来自zookeeper的实时通知。因此一旦region server上线，master能马上得到消息。</p><h3 id="region-server下线"><a href="#region-server下线" class="headerlink" title="region server下线"></a>region server下线</h3><p>当region server下线时，它和zookeeper的会话断开，zookeeper而自动释放代表这台server的文件上的独占锁。而master不断轮询 server目录下文件的锁状态。如果master发现某个region server丢失了它自己的独占锁，(或者master连续几次和region server通信都无法成功),master就是尝试去获取代表这个region server的读写锁，一旦获取成功，就可以确定：</p><ol><li>region server和zookeeper之间的网络断开了。</li><li>region server挂了。</li></ol><p>的其中一种情况发生了，无论哪种情况，region server都无法继续为它的region提供服务了，此时master会删除server目录下代表这台region server的文件，并将这台region server的region分配给其它还活着的同志。</p><p>如果网络短暂出现问题导致region server丢失了它的锁，那么region server重新连接到zookeeper之后，只要代表它的文件还在，它就会不断尝试获取这个文件上的锁，一旦获取到了，就可以继续提供服务。</p><h3 id="master上线"><a href="#master上线" class="headerlink" title="master上线"></a>master上线</h3><p>master启动进行以下步骤:</p><ol><li>从zookeeper上获取唯一一个代码master的锁，用来阻止其它master成为master。</li><li>扫描zookeeper上的server目录，获得当前可用的region server列表。</li><li>和2中的每个region server通信，获得当前已分配的region和region server的对应关系。</li><li>扫描.META.region的集合，计算得到当前还未分配的region，将他们放入待分配region列表。</li></ol><h3 id="master下线"><a href="#master下线" class="headerlink" title="master下线"></a>master下线</h3><p>由于master只维护表和region的元数据，而不参与表数据IO的过 程，master下线仅导致所有元数据的修改被冻结(无法创建删除表，无法修改表的schema，无法进行region的负载均衡，无法处理region 上下线，无法进行region的合并，唯一例外的是region的split可以正常进行，因为只有region server参与)，表的数据读写还可以正常进行。因此master下线短时间内对整个hbase集群没有影响。从上线过程可以看到，master保存的 信息全是可以冗余信息（都可以从系统其它地方收集到或者计算出来），因此，一般hbase集群中总是有一个master在提供服务，还有一个以上 的’master’在等待时机抢占它的位置。</p><h1 id="六、访问接口"><a href="#六、访问接口" class="headerlink" title="六、访问接口"></a>六、访问接口</h1><pre><code>HBase ShellJava clietn APIHBase non-java accesslanguages talking to the JVMJython interface to HBaseGroovy DSL for HBaseScala interface to HBaselanguages with a custom protocolREST gateway specification for HBase充分利用HTTP协议：GET POST PUT DELETE§text/plaintext/xmlapplication/jsonapplication/x-protobufThrift gateway specification for HBasejavacpprbpyperlphpHBase Map ReduceHive/Pig</code></pre><h1 id="七、结语："><a href="#七、结语：" class="headerlink" title="七、结语："></a>七、结语：</h1><p>全文对 Hbase做了 简单的介绍，有错误之处，敬请指正。未来将结合 Hbase 在淘宝数据平台的应用场景，在更多细节上进行深入。</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p>Bigtable: A Distributed Storage System for Structured Data</p><p>HFile: A Block-Indexed File Format to Store Sorted Key-Value Pairs for a thorough</p><p>introduction Hbase Architecture 101</p><p>Hbase source code</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇博客梳理的太好了，附上大牛博主的&lt;a href=&quot;http://jiajun.iteye.com/&quot;&gt;博客地址&lt;/a&gt;。&lt;/p&gt;
&lt;h1 id=&quot;一、-简介&quot;&gt;&lt;a href=&quot;#一、-简介&quot; class=&quot;headerlink&quot; title=&quot;一、 简介&quot;&gt;&lt;/a&gt;一、 简介&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;history&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;started by chad walters and jim&lt;/li&gt;
&lt;li&gt;2006.11 G release paper on BigTable&lt;/li&gt;
&lt;li&gt;2007.2 inital HBase prototype created as Hadoop contrib&lt;/li&gt;
&lt;li&gt;2007.10 First useable Hbase&lt;/li&gt;
&lt;li&gt;2008.1 Hadoop become Apache top-level project and Hbase becomes subproject&lt;/li&gt;
&lt;li&gt;2008.10 Hbase 0.18,0.19 released&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;hbase是bigtable的开源山寨版本。是建立的hdfs之上，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统。&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="zookeeper" scheme="https://tokerr.github.io/tags/zookeeper/"/>
    
      <category term="hbase" scheme="https://tokerr.github.io/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>sqoop学习笔记</title>
    <link href="https://tokerr.github.io/2017/10/25/sqoop%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://tokerr.github.io/2017/10/25/sqoop学习笔记/</id>
    <published>2017-10-25T13:28:29.000Z</published>
    <updated>2019-05-01T13:51:07.478Z</updated>
    
    <content type="html"><![CDATA[<p><strong>说明：这里以hadoop2和mysql为例。</strong></p><h2 id="1-上传sqoop到Hadoop集群任意一个节点"><a href="#1-上传sqoop到Hadoop集群任意一个节点" class="headerlink" title="1.上传sqoop到Hadoop集群任意一个节点"></a>1.上传sqoop到Hadoop集群任意一个节点</h2><h2 id="2-安装和配置"><a href="#2-安装和配置" class="headerlink" title="2.安装和配置"></a>2.安装和配置</h2><h3 id="2-1-配置sqoop-env-sh文件"><a href="#2-1-配置sqoop-env-sh文件" class="headerlink" title="2.1 配置sqoop-env.sh文件"></a>2.1 配置sqoop-env.sh文件</h3><p>在sqoop中conf目录下新复制一个sqoop-env.sh文件：<br><br>[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh<br><br>修改配置sqoop-env.sh文件：<br><a id="more"></a><br>    export HADOOP_COMMON_HOME=/home/hadoop/hadoop/hadoop-2.3.0</p><pre><code>#Set path to where hadoop-*-core.jar is availableexport HADOOP_MAPRED_HOME=/home/hadoop/hadoop/hadoop-2.3.0#set the path to where bin/hbase is available#export HBASE_HOME=#Set the path to where bin/hive is available#export HIVE_HOME=#Set the path for where zookeper config dir is#export ZOOCFGDIR=</code></pre><p> 不配置该项会出现Please set $HADOOP_COMMON_HOME to the root的错误提示。</p><h3 id="2-2-添加数据库驱动"><a href="#2-2-添加数据库驱动" class="headerlink" title="2.2 添加数据库驱动"></a>2.2 添加数据库驱动</h3><p>将数据库连接驱动拷贝到$SQOOP_HOME/lib里。注意，这里使用的是Mysql驱动版本不能过低，尽量使用最新的版本，否则可能会出现一下错误：</p><pre><code>ERROR manager.SqlManager: Error reading from database: java.sql.SQLException: Streaming result set</code></pre><h2 id="3-配置mysql远程登录"><a href="#3-配置mysql远程登录" class="headerlink" title="3.配置mysql远程登录"></a>3.配置mysql远程登录</h2><h3 id="3-1-改表："><a href="#3-1-改表：" class="headerlink" title="3.1 改表："></a>3.1 改表：</h3><p>只要在localhost的那台电脑，登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改称”%”</p><p>登录数据库：mysql -u root -pvmware</p><p>mysql&gt;use mysql;</p><p>mysql&gt;update user set host = ‘%’ where user = ‘root’;</p><p>mysql&gt;select host, user from user;</p><p>mysql&gt;FLUSH RIVILEGES </p><h3 id="3-2-授权："><a href="#3-2-授权：" class="headerlink" title="3.2 授权："></a>3.2 授权：</h3><p>(1)例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。</p><p>第一步：root用户登录；mysql&gt;mysql -u root -p rootpassword;</p><p>第二步：赋予权限；mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser’@’%’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><p>第三步：mysql&gt;FLUSH   PRIVILEGES;</p><p>(2)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器，并使用mypassword作为密码</p><p> mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><p> mysql&gt;FLUSH   PRIVILEGES;</p><p>(3)如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码</p><p> mysql&gt;GRANT ALL PRIVILEGES ON dk.* TO ‘myuser’@’192.168.1.3’ IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><p> mysql&gt;FLUSH   PRIVILEGES;</p><p>说明：这里我使用了第（1）种方法。没有允许mysql远程登录，在使用sqoop导入数据的时候，会出现以下错误：</p><pre><code>message from server: &quot;Host is not allowed to connect to this MySQL server</code></pre><h2 id="4-使用-amp-练习"><a href="#4-使用-amp-练习" class="headerlink" title="4.使用&amp;练习"></a>4.使用&amp;练习</h2><p><strong>第一类：数据库中的数据导入到HDFS上</strong></p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --columns &apos;id, account, income, expenses&apos;</code></pre><p>指定输出路径、指定数据分隔符</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td&apos; --fields-terminated-by &apos;\t&apos;</code></pre><p>指定Map数量 -m</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --target-dir &apos;/sqoop/td1&apos; --fields-terminated-by &apos;\t&apos; -m 2</code></pre><p>增加where条件, 注意：条件必须用引号引起来</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123  --table trade_detail --where &apos;id&gt;3&apos; --target-dir &apos;/sqoop/td2&apos;</code></pre><p>增加query语句(使用 \ 将语句换行)</p><pre><code>sqoop import --connect jdbc:mysql://192.168.1.10:3306/nongyt --username root --password 123 \--query &apos;SELECT * FROM trade_detail where id &gt; 2 AND $CONDITIONS&apos; --split-by trade_detail.id --target-dir &apos;/sqoop/td3&apos;</code></pre><p><strong><em>注意：</em></strong></p><ul><li><p><em>如果使用–query这个命令的时候，需要注意的是where后面的参数，AND $CONDITIONS这个参数必须加上</em></p></li><li><p><em>而且存在单引号与双引号的区别，如果–query后面使用的是双引号，那么需要在$CONDITIONS前加上\即\$CONDITIONS</em></p></li><li><p><em>如果设置map数量为1个时即-m 1，不用加上–split-by ${tablename.column}，否则需要加上</em></p></li></ul><p><strong>第二类：将HDFS上的数据导出到数据库中(不要忘记指定分隔符)</strong></p><pre><code>sqoop export --connect jdbc:mysql://192.168.8.120:3306/nongyt --username root --password 123 --export-dir &apos;/td3&apos; --table td_bak -m 1 --fields-terminated-by &apos;,&apos;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;说明：这里以hadoop2和mysql为例。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-上传sqoop到Hadoop集群任意一个节点&quot;&gt;&lt;a href=&quot;#1-上传sqoop到Hadoop集群任意一个节点&quot; class=&quot;headerlink&quot; title=&quot;1.上传sqoop到Hadoop集群任意一个节点&quot;&gt;&lt;/a&gt;1.上传sqoop到Hadoop集群任意一个节点&lt;/h2&gt;&lt;h2 id=&quot;2-安装和配置&quot;&gt;&lt;a href=&quot;#2-安装和配置&quot; class=&quot;headerlink&quot; title=&quot;2.安装和配置&quot;&gt;&lt;/a&gt;2.安装和配置&lt;/h2&gt;&lt;h3 id=&quot;2-1-配置sqoop-env-sh文件&quot;&gt;&lt;a href=&quot;#2-1-配置sqoop-env-sh文件&quot; class=&quot;headerlink&quot; title=&quot;2.1 配置sqoop-env.sh文件&quot;&gt;&lt;/a&gt;2.1 配置sqoop-env.sh文件&lt;/h3&gt;&lt;p&gt;在sqoop中conf目录下新复制一个sqoop-env.sh文件：&lt;br&gt;&lt;br&gt;[root@centos2 conf]# cp sqoop-env-template.sh sqoop-env.sh&lt;br&gt;&lt;br&gt;修改配置sqoop-env.sh文件：&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="sqoop" scheme="https://tokerr.github.io/tags/sqoop/"/>
    
  </entry>
  
  <entry>
    <title>hadoop+zookeeper集群搭建</title>
    <link href="https://tokerr.github.io/2017/10/24/hadoop-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://tokerr.github.io/2017/10/24/hadoop-zookeeper集群搭建/</id>
    <published>2017-10-24T14:50:21.000Z</published>
    <updated>2019-12-01T11:58:23.066Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备:"></a>前期准备:</h2><p>hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA</p><p>1.修改Linux主机名<br><br>2.修改IP<br><br>3.修改主机名和IP的映射关系<br><a id="more"></a><br>    注意：<br>    如果你们公司是租用的服务器或是使用的云主机（如华为用主机、阿里云主机等）<br>    /etc/hosts里面要配置的是内网IP地址和主机名的映射关系<br>4.关闭防火墙<br><br>5.ssh免登陆 <br><br>6.安装JDK，配置环境变量等<br></p><h2 id="集群规划："><a href="#集群规划：" class="headerlink" title="集群规划："></a>集群规划：</h2><pre><code>主机名        IP                安装的软件                    运行的进程nongyt01    192.168.1.201    jdk、hadoop                    NameNode、DFSZKFailoverController(zkfc)nongyt02    192.168.1.202    jdk、hadoop                    NameNode、DFSZKFailoverController(zkfc)nongyt03    192.168.1.203    jdk、hadoop                    ResourceManagernongyt04    192.168.1.204    jdk、hadoop                    ResourceManagernongyt05    192.168.1.205    jdk、hadoop、zookeeper        DataNode、NodeManager、JournalNode、QuorumPeerMainnongyt06    192.168.1.206    jdk、hadoop、zookeeper        DataNode、NodeManager、JournalNode、QuorumPeerMainnongyt07    192.168.1.207    jdk、hadoop、zookeeper        DataNode、NodeManager、JournalNode、QuorumPeerMain</code></pre><h3 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h3><p>1.在hadoop2.0中通常由两个NameNode组成，一个处于active状态，另一个处于standby状态。Active NameNode对外提供服务，而Standby NameNode则不对外提供服务，仅同步active namenode的状态，以便能够在它失败时快速进行切换。<br><br>hadoop2.0官方提供了两种HDFS HA的解决方案，一种是NFS，另一种是QJM。这里我们使用简单的QJM。在该方案中，主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode<br>这里还配置了一个zookeeper集群，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，会自动切换Standby NameNode为standby状态</p><p>2.hadoop-2.2.0中依然存在一个问题，就是ResourceManager只有一个，存在单点故障，hadoop-2.4.1解决了这个问题，有两个ResourceManager，一个是Active，一个是Standby，状态由zookeeper进行协调</p><h2 id="安装步骤："><a href="#安装步骤：" class="headerlink" title="安装步骤："></a>安装步骤：</h2><h3 id="1-安装配置zooekeeper集群（在nongyt05上）"><a href="#1-安装配置zooekeeper集群（在nongyt05上）" class="headerlink" title="1.安装配置zooekeeper集群（在nongyt05上）"></a>1.安装配置zooekeeper集群（在nongyt05上）</h3><pre><code>1.1解压    tar -zxvf zookeeper-3.4.5.tar.gz -C /nongyt/1.2修改配置    cd /nongyt/zookeeper-3.4.5/conf/    cp zoo_sample.cfg zoo.cfg    vim zoo.cfg    修改：dataDir=/nongyt/zookeeper-3.4.5/tmp    在最后添加：    server.1=nongyt05:2888:3888    server.2=nongyt06:2888:3888    server.3=nongyt07:2888:3888    保存退出    然后创建一个tmp文件夹    mkdir /nongyt/zookeeper-3.4.5/tmp    再创建一个空文件    touch /nongyt/zookeeper-3.4.5/tmp/myid    最后向该文件写入ID    echo 1 &gt; /nongyt/zookeeper-3.4.5/tmp/myid1.3将配置好的zookeeper拷贝到其他节点(首先分别在nongyt06、nongyt07根目录下创建一个nongyt目录：mkdir /nongyt)    scp -r /nongyt/zookeeper-3.4.5/ nongyt06:/nongyt/    scp -r /nongyt/zookeeper-3.4.5/ nongyt07:/nongyt/    注意：修改nongyt06、nongyt07对应/nongyt/zookeeper-3.4.5/tmp/myid内容    nongyt06：        echo 2 &gt; /nongyt/zookeeper-3.4.5/tmp/myid    nongyt07：        echo 3 &gt; /nongyt/zookeeper-3.4.5/tmp/myid</code></pre><h3 id="2-安装配置hadoop集群（在nongyt01上操作）"><a href="#2-安装配置hadoop集群（在nongyt01上操作）" class="headerlink" title="2.安装配置hadoop集群（在nongyt01上操作）"></a>2.安装配置hadoop集群（在nongyt01上操作）</h3><pre><code>    2.1解压        tar -zxvf hadoop-2.4.1.tar.gz -C /nongyt/    2.2配置HDFS（hadoop2.0所有的配置文件都在$HADOOP_HOME/etc/hadoop目录下）        #将hadoop添加到环境变量中        vim /etc/profile        export JAVA_HOME=/usr/java/jdk1.7.0_55        export HADOOP_HOME=/nongyt/hadoop-2.4.1        export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin        #hadoop2.0的配置文件全部在$HADOOP_HOME/etc/hadoop下        cd /nongyt/hadoop-2.4.1/etc/hadoop        2.2.1修改hadoo-env.sh            export JAVA_HOME=/usr/java/jdk1.7.0_55        2.2.2修改core-site.xml            &lt;configuration&gt;                &lt;!-- 指定hdfs的nameservice为ns1 --&gt;                &lt;property&gt;                    &lt;name&gt;fs.defaultFS&lt;/name&gt;                    &lt;value&gt;hdfs://ns1&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定hadoop临时目录 --&gt;                &lt;property&gt;                    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;                    &lt;value&gt;/nongyt/hadoop-2.4.1/tmp&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定zookeeper地址 --&gt;                &lt;property&gt;                    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;                    &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;        2.2.3修改hdfs-site.xml            &lt;configuration&gt;                &lt;!--指定hdfs的nameservice为ns1，需要和core-site.xml中的保持一致 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.nameservices&lt;/name&gt;                    &lt;value&gt;ns1&lt;/value&gt;                &lt;/property&gt;                &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;                    &lt;value&gt;nn1,nn2&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn1的RPC通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;                    &lt;value&gt;nongyt01:9000&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn1的http通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;                    &lt;value&gt;nongyt01:50070&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn2的RPC通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;                    &lt;value&gt;nongyt02:9000&lt;/value&gt;                &lt;/property&gt;                &lt;!-- nn2的http通信地址 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;                    &lt;value&gt;nongyt02:50070&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;                    &lt;value&gt;qjournal://nongyt05:8485;nongyt06:8485;nongyt07:8485/ns1&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;                    &lt;value&gt;/nongyt/hadoop-2.4.1/journal&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 开启NameNode失败自动切换 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;                    &lt;value&gt;true&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 配置失败自动切换实现方式 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;                    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;                    &lt;value&gt;                        sshfence                        shell(/bin/true)                    &lt;/value&gt;                &lt;/property&gt;                &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;                    &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 配置sshfence隔离机制超时时间 --&gt;                &lt;property&gt;                    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;                    &lt;value&gt;30000&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;        2.2.4修改mapred-site.xml            &lt;configuration&gt;                &lt;!-- 指定mr框架为yarn方式 --&gt;                &lt;property&gt;                    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;                    &lt;value&gt;yarn&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;            2.2.5修改yarn-site.xml            &lt;configuration&gt;                &lt;!-- 开启RM高可靠 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;                   &lt;value&gt;true&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定RM的cluster id --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;                   &lt;value&gt;yrc&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定RM的名字 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;                   &lt;value&gt;rm1,rm2&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 分别指定RM的地址 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;                   &lt;value&gt;nongyt03&lt;/value&gt;                &lt;/property&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;                   &lt;value&gt;nongyt04&lt;/value&gt;                &lt;/property&gt;                &lt;!-- 指定zk集群地址 --&gt;                &lt;property&gt;                   &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;                   &lt;value&gt;nongyt05:2181,nongyt06:2181,nongyt07:2181&lt;/value&gt;                &lt;/property&gt;                &lt;property&gt;                   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;                   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;                &lt;/property&gt;            &lt;/configuration&gt;        2.2.6修改slaves(slaves是指定子节点的位置，因为要在nongyt01上启动HDFS、在nongyt03启动yarn，所以nongyt01上的slaves文件指定的是datanode的位置，nongyt03上的slaves文件指定的是nodemanager的位置)            nongyt05            nongyt06            nongyt07        2.2.7配置免密码登陆            #首先要配置nongyt01到nongyt02、nongyt03、nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆            #在nongyt01上生产一对钥匙            ssh-keygen -t rsa            #将公钥拷贝到其他节点，包括自己            ssh-coyp-id nongyt01            ssh-coyp-id nongyt02            ssh-coyp-id nongyt03            ssh-coyp-id nongyt04            ssh-coyp-id nongyt05            ssh-coyp-id nongyt06            ssh-coyp-id nongyt07            #配置nongyt03到nongyt04、nongyt05、nongyt06、nongyt07的免密码登陆            #在nongyt03上生产一对钥匙            ssh-keygen -t rsa            #将公钥拷贝到其他节点            ssh-coyp-id nongyt04            ssh-coyp-id nongyt05            ssh-coyp-id nongyt06            ssh-coyp-id nongyt07            #注意：两个namenode之间要配置ssh免密码登陆，别忘了配置nongyt02到nongyt01的免登陆            在nongyt02上生产一对钥匙            ssh-keygen -t rsa            ssh-coyp-id -i nongyt01                    2.4将配置好的hadoop拷贝到其他节点        scp -r /nongyt/ nongyt02:/        scp -r /nongyt/ nongyt03:/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt04:/nongyt/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt05:/nongyt/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt06:/nongyt/        scp -r /nongyt/hadoop-2.4.1/ root@nongyt07:/nongyt/    ###注意：严格按照下面的步骤    2.5启动zookeeper集群（分别在nongyt05、nongyt06、tcast07上启动zk）        cd /nongyt/zookeeper-3.4.5/bin/        ./zkServer.sh start        #查看状态：一个leader，两个follower        ./zkServer.sh status    2.6启动journalnode（分别在在nongyt05、nongyt06、tcast07上执行）        cd /nongyt/hadoop-2.4.1        sbin/hadoop-daemon.sh start journalnode        #运行jps命令检验，nongyt05、nongyt06、nongyt07上多了JournalNode进程    2.7格式化HDFS        #在nongyt01上执行命令:        hdfs namenode -format        #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/nongyt/hadoop-2.4.1/tmp，然后将/nongyt/hadoop-2.4.1/tmp拷贝到nongyt02的/nongyt/hadoop-2.4.1/下。        scp -r tmp/ nongyt02:/nongyt/hadoop-2.4.1/    2.8格式化ZK(在nongyt01上执行即可)        hdfs zkfc -formatZK    2.9启动HDFS(在nongyt01上执行)        sbin/start-dfs.sh    2.10启动YARN(#####注意#####：是在nongyt03上执行start-yarn.sh，把namenode和resourcemanager分开是因为性能问题，因为他们都要占用大量资源，所以把他们分开了，他们分开了就要分别在不同的机器上启动)        sbin/start-yarn.sh到此，hadoop-2.4.1配置完毕，可以统计浏览器访问:    http://192.168.1.201:50070    NameNode &apos;nongyt01:9000&apos; (active)    http://192.168.1.202:50070    NameNode &apos;nongyt02:9000&apos; (standby)验证HDFS HA    首先向hdfs上传一个文件    hadoop fs -put /etc/profile /profile    hadoop fs -ls /    然后再kill掉active的NameNode    kill -9 &lt;pid of NN&gt;    通过浏览器访问：http://192.168.1.202:50070    NameNode &apos;nongyt02:9000&apos; (active)    这个时候nongyt02上的NameNode变成了active    在执行命令：    hadoop fs -ls /    -rw-r--r--   3 root supergroup       1926 2014-02-06 15:36 /profile    刚才上传的文件依然存在！！！    手动启动那个挂掉的NameNode    sbin/hadoop-daemon.sh start namenode    通过浏览器访问：http://192.168.1.201:50070    NameNode &apos;nongyt01:9000&apos; (standby)验证YARN：    运行一下hadoop提供的demo中的WordCount程序：    hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar wordcount /profile /outOK，大功告成！！！</code></pre><h2 id="zookeeper配置文件详解"><a href="#zookeeper配置文件详解" class="headerlink" title="zookeeper配置文件详解"></a>zookeeper配置文件详解</h2><p>zookeeper的默认配置文件为zookeeper/conf/zoo_sample.cfg，需要将其修改为zoo.cfg。其中各配置项的含义，解释如下：</p><ul><li><p>1.tickTime：CS通信心跳时间<br><br>Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。<br><br>tickTime=2000  </p></li><li><p>2.initLimit：LF初始通信时限<br><br>集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。<br><br>initLimit=5  </p></li><li><p>3.syncLimit：LF同步通信时限<br><br>集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。<br><br>syncLimit=2  </p></li><li><p>4.dataDir：数据文件目录<br><br>Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。<br>dataDir=/home/michael/opt/zookeeper/data  </p></li><li><p>5.clientPort：客户端连接端口<br><br>客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。<br><br>clientPort=2181 </p></li><li><p>6.服务器名称与地址：<br><br>  集群信息（服务器编号，服务器地址，LF通信端口，选举端口）<br><br>  这个配置项的书写格式比较特殊，规则如下：<br><br>  server.N=YYY:A:B <br><br>  server.1=nongyt05:2888:3888<br><br>  server.2=nongyt06:2888:3888<br><br>  server.3=nongyt07:2888:3888<br></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前期准备&quot;&gt;&lt;a href=&quot;#前期准备&quot; class=&quot;headerlink&quot; title=&quot;前期准备:&quot;&gt;&lt;/a&gt;前期准备:&lt;/h2&gt;&lt;p&gt;hadoop2.0已经发布了稳定版本了，增加了很多特性，比如HDFS HA、YARN等。最新的hadoop-2.4.1又增加了YARN HA&lt;/p&gt;
&lt;p&gt;1.修改Linux主机名&lt;br&gt;&lt;br&gt;2.修改IP&lt;br&gt;&lt;br&gt;3.修改主机名和IP的映射关系&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="zookeeper" scheme="https://tokerr.github.io/tags/zookeeper/"/>
    
      <category term="cluster" scheme="https://tokerr.github.io/tags/cluster/"/>
    
  </entry>
  
  <entry>
    <title>Linux下tomcat启动慢的问题</title>
    <link href="https://tokerr.github.io/2017/10/24/Linux%E4%B8%8Btomcat%E5%90%AF%E5%8A%A8%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://tokerr.github.io/2017/10/24/Linux下tomcat启动慢的问题/</id>
    <published>2017-10-24T14:37:32.000Z</published>
    <updated>2019-05-01T13:51:07.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="有两种解决办法："><a href="#有两种解决办法：" class="headerlink" title="有两种解决办法："></a>有两种解决办法：</h2><p>1）在Tomcat环境中解决</p><p>可以通过配置JRE使用非阻塞的Entropy Source。<br>在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。<br>加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。<br><a id="more"></a><br>2）在JVM环境中解决</p><p>打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容：<br><br>securerandom.source=file:/dev/urandom<br>替换成<br>securerandom.source=file:/dev/./urandom</p><h2 id="彻底解决"><a href="#彻底解决" class="headerlink" title="彻底解决"></a>彻底解决</h2><p>“Linux下的所有应用程序产生随机数都会用到这个，所以不仅仅是Tomcat可能被 阻塞 。如果你搜索会发现Apache、Nginx、OpenSSL都被这个问题坑过.”<br>由于《彻底找到Tomcat启动速度慢的元凶》这篇原文网上被引用过多，我也分不清那个是原文，所以此处就不贴原文地址了，大家可自行百度关键字：彻底找到Tomcat启动速度慢的元凶</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;有两种解决办法：&quot;&gt;&lt;a href=&quot;#有两种解决办法：&quot; class=&quot;headerlink&quot; title=&quot;有两种解决办法：&quot;&gt;&lt;/a&gt;有两种解决办法：&lt;/h2&gt;&lt;p&gt;1）在Tomcat环境中解决&lt;/p&gt;
&lt;p&gt;可以通过配置JRE使用非阻塞的Entropy Source。&lt;br&gt;在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。&lt;br&gt;加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。&lt;br&gt;
    
    </summary>
    
    
      <category term="tomcat" scheme="https://tokerr.github.io/tags/tomcat/"/>
    
  </entry>
  
  <entry>
    <title>HDFS架构及其执行原理</title>
    <link href="https://tokerr.github.io/2017/10/18/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/"/>
    <id>https://tokerr.github.io/2017/10/18/HDFS架构极其执行原理/</id>
    <published>2017-10-18T09:18:35.000Z</published>
    <updated>2019-05-01T13:51:07.472Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、前言："><a href="#一、前言：" class="headerlink" title="一、前言："></a>一、前言：</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。</p><h3 id="1-1、名词复习"><a href="#1-1、名词复习" class="headerlink" title="1.1、名词复习"></a>1.1、名词复习</h3><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统）<br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统）</p><pre><code>内部主从结构•主节点，只有一个: namenode•从节点，有很多个: datanode</code></pre><p> <strong>namenode负责：</strong><br><br><a id="more"></a></p><ul><li>接收用户操作请求</li><li>维护文件系统的目录结构</li><li><p>管理文件与block之间关系，block与datanode之间关系<br></p><p><strong>datanode负责：</strong></p></li><li><p>存储文件</p></li><li>文件被分成block存储在磁盘上</li><li>为保证数据安全，文件会有多个副本</li></ul><p>备注：还有另外一个SecondaryNameNode，作为NameNode的辅助组件，但是不能替代NameNode，下面会简单的介绍。</p><h3 id="1-2、Hadoop1-0和hadop2-0的对比"><a href="#1-2、Hadoop1-0和hadop2-0的对比" class="headerlink" title="1.2、Hadoop1.0和hadop2.0的对比"></a>1.2、Hadoop1.0和hadop2.0的对比</h3><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/1.png" alt=""></p><h2 id="二、分布式文件系统与HDFS"><a href="#二、分布式文件系统与HDFS" class="headerlink" title="二、分布式文件系统与HDFS"></a>二、分布式文件系统与HDFS</h2><ul><li><p>数据量越来越多，在一个操作系统管辖的范围存不下了，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，因此迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统 。</p></li><li><p>是一种允许文件通过网络在多台主机上分享的文件系统，可让多机器上的多用户分享文件和存储空间。</p></li><li><p>通透性。让实际上是通过网络来访问文件的动作，由程序与用户看来，就像是访问本地的磁盘一般。</p></li><li><p>容错。即使系统中有某些节点脱机，整体来说系统仍然可以持续运作而不会有数据损失。</p></li><li><p>分布式文件管理系统很多，hdfs只是其中一种。适用于一次写入多次查询的情况，不支持并发写情况，小文件不合适。</p></li></ul><h2 id="三、HDFS体系结构与基本概念"><a href="#三、HDFS体系结构与基本概念" class="headerlink" title="三、HDFS体系结构与基本概念"></a>三、HDFS体系结构与基本概念</h2><h3 id="3-1-HDFS架构"><a href="#3-1-HDFS架构" class="headerlink" title="3.1 HDFS架构"></a>3.1 HDFS架构</h3><p>包括NameNode，DataNode，Secondary NameNode</p><h3 id="3-2-原理图"><a href="#3-2-原理图" class="headerlink" title="3.2 原理图"></a>3.2 原理图</h3><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/2.jpg" alt=""></p><h3 id="3-3-NameNode"><a href="#3-3-NameNode" class="headerlink" title="3.3 NameNode"></a>3.3 NameNode</h3><p>是整个文件系统的管理节点。它维护着整个文件系统的文件目录树，文件/目录的元信息和每个文件对应的数据块列表。接收用户的操作请求。</p><pre><code>文件包括(hdfs-site.xml的dfs.name.dir属性)：fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。edits:操作日志文件。fstime:保存最近一次checkpoint的时间以上这些文件是保存在linux的文件系统中。</code></pre><p>NameNode工作特点：</p><ul><li>Namenode始终在内存中保存metedata，用于处理“读请求”</li><li>到有“写请求”到来时，namenode会首先写editlog到磁盘，即向edits文件中写日志，成功返回后，才会修改内存，并且向客户端返回</li><li>Hadoop会维护一个fsimage文件，也就是namenode中metedata的镜像，但是fsimage不会随时与namenode内存中的metedata保持一致，而是每隔一段时间通过合并edits文件来更新内容。Secondary namenode就是用来合并fsimage和edits文件来更新NameNode的metedata的。</li></ul><h3 id="3-4-SecondaryNameNode"><a href="#3-4-SecondaryNameNode" class="headerlink" title="3.4 SecondaryNameNode"></a>3.4 SecondaryNameNode</h3><ul><li>HA的一个解决方案。但不支持热备。配置即可。</li><li>执行过程：从NameNode上下载元数据信息（fsimage,edits），然后把二者合并，生成新的fsimage，在本地保存，并将其推送到NameNode，替换旧的fsimage.</li><li>默认在安装在NameNode节点上，但这样…不安全！</li></ul><p>SecondaryNameNode工作流程：</p><ol><li>secondary通知namenode切换edits文件</li><li>secondary从namenode获得fsimage和edits(通过http)</li><li>secondary将fsimage载入内存，然后开始合并edits</li><li>secondary将新的fsimage发回给namenode</li><li>namenode用新的fsimage替换旧的fsimage</li></ol><p>下图是NameNode和SecondaryNameNode工作相互协调的过程：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/HDFS%E6%9E%B6%E6%9E%84%E6%9E%81%E5%85%B6%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86/3.png" alt=""></p><h3 id="3-5-DataNode"><a href="#3-5-DataNode" class="headerlink" title="3.5 DataNode"></a>3.5 DataNode</h3><ul><li>提供真实文件数据的存储服务。</li><li>文件块（block）：最基本的存储单位。对于文件内容而言，一个文件的长度大小是size，那么从文件的０偏移开始，按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block。HDFS默认Block大小是128MB，以一个256MB文件，共有256/128=2个Block.</li><li>不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间</li><li>Replication。多复本。默认是三个。</li></ul><h2 id="四、HDFS的shell操作"><a href="#四、HDFS的shell操作" class="headerlink" title="四、HDFS的shell操作"></a>四、HDFS的shell操作</h2><ul><li>调用文件系统(FS)Shell命令应使用bin/hadoop fs 的形式。</li><li>所有的FS shell命令使用URI路径作为参数。</li><li>URI格式是scheme://authority/。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。</li><li>例如：/parent/child可以表示成hdfs://namenode:namenodePort/parent/child，或者更简单的/parent/child（假设配置文件是namenode:namenodePort）</li><li>大多数FS Shell命令的行为和对应的Unix Shell命令类似。</li></ul><p>HDFS   fs命令</p><pre><code>-help [cmd]    //显示命令的帮助信息-ls(r) &lt;path&gt;    //显示当前目录下所有文件-du(s) &lt;path&gt;    //显示目录中所有文件大小-count[-q] &lt;path&gt;    //显示目录中文件数量-mv &lt;src&gt; &lt;dst&gt;    //移动多个文件到目标目录-cp &lt;src&gt; &lt;dst&gt;    //复制多个文件到目标目录-rm(r)        //删除文件(夹)-put &lt;localsrc&gt; &lt;dst&gt;    //本地文件复制到hdfs-copyFromLocal    //同put-moveFromLocal    //从本地文件移动到hdfs-get [-ignoreCrc] &lt;src&gt; &lt;localdst&gt;    //复制文件到本地，可以忽略crc校验-getmerge &lt;src&gt; &lt;localdst&gt;        //将源目录中的所有文件排序合并到一个文件中-cat &lt;src&gt;    //在终端显示文件内容-text &lt;src&gt;    //在终端显示文件内容-copyToLocal [-ignoreCrc] &lt;src&gt; &lt;localdst&gt;    //复制到本地-moveToLocal &lt;src&gt; &lt;localdst&gt;-mkdir &lt;path&gt;    //创建文件夹-touchz &lt;path&gt;    //创建一个空文件</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、前言：&quot;&gt;&lt;a href=&quot;#一、前言：&quot; class=&quot;headerlink&quot; title=&quot;一、前言：&quot;&gt;&lt;/a&gt;一、前言：&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;HDFS和YARN作为hadoop的核心，前者用于海量数据的存储，后者负责资源管理调度。本文先对HDFS，就个人的掌握的程度进行简单的概要和回顾。关于 YARN结构以及内部执行原理，以及后面内部各个组件如何相互协调工作，后面再进行探讨。&lt;/p&gt;
&lt;h3 id=&quot;1-1、名词复习&quot;&gt;&lt;a href=&quot;#1-1、名词复习&quot; class=&quot;headerlink&quot; title=&quot;1.1、名词复习&quot;&gt;&lt;/a&gt;1.1、名词复习&lt;/h3&gt;&lt;p&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1）、YARN ——Yet Another Resource Negotiator（资源管理调度系统）&lt;br&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2）、HDFS——Hadoop Distributed File System（分布式文件系统）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;内部主从结构
•主节点，只有一个: namenode
•从节点，有很多个: datanode
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; &lt;strong&gt;namenode负责：&lt;/strong&gt;&lt;br&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="HDFS" scheme="https://tokerr.github.io/tags/HDFS/"/>
    
      <category term="YARN" scheme="https://tokerr.github.io/tags/YARN/"/>
    
  </entry>
  
  <entry>
    <title>Shuffle工作机制</title>
    <link href="https://tokerr.github.io/2017/10/16/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
    <id>https://tokerr.github.io/2017/10/16/Shuffle工作机制/</id>
    <published>2017-10-16T15:41:34.000Z</published>
    <updated>2019-05-01T13:51:07.475Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。</p><h2 id="二、什么是Shuffle"><a href="#二、什么是Shuffle" class="headerlink" title="二、什么是Shuffle?"></a>二、什么是Shuffle?</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/1.png" alt="MapReducer执行原理"><br><a id="more"></a></p><h2 id="三、Shuffle工作机制："><a href="#三、Shuffle工作机制：" class="headerlink" title="三、Shuffle工作机制："></a>三、Shuffle工作机制：</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从map端的输出开始。map函数开始产生输出时，不是简单地将它写到磁盘。这个过程更复杂，它利用缓冲的方式写到内存，井出于效率的考虑进行预排序。下图展示了这个过程每个map任务都有一个环形内存缓冲区，用于存储任务的输出。默认情况下，缓冲区的大为100MB，此值可以通过改变io.sort.mb属性来调整。一旦缓冲内容达到闹值(io.sort.spill.percent，默认为0.80，或80%)，一个后台线程便开始把内容写到(spill)磁盘中。在写磁盘过程中，map输出继续被写到缓冲区，但如果在此期间缓冲区被填楠，map会阻塞直到写磁盘过程完成。写磁盘将按轮询方式写到mapred.local.dir属性指定的作业特定子目录中的目录中。<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/2.png" alt="Shuffle工作机制"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在map输出写磁盘之前，线程首先根据数据最终要传送到的reducer把数据划分成相应的分区(partition)。在每个分区中，后台线程按键进行内排序，如果有一个combiner，它会在排序后的输出上运行。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦内存缓冲区达到溢出写的阀值，就会新建一个溢出写文件，因此在map任务写完其最后一个输出记录之后，会有几个溢出写文件。在任务完成之前，溢出写文件被合并成一个已分区且已排序的输出文件。配置属性io.sort.factor控制着一次最多能合并多少流，默认值是10.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果已经指定combiner，并且溢出写次数至少为3(min.num.spills.for.combine属性的取值)肘，则combiner就会在输出文件写到磁盘之前运行。combiner可以在输入上反复运行，如果combiner可拔插，添加Combiner绝不能改变最终的计算结果;不排除使用combiner作为在map端过滤数据的用途，比如空字符串或者其他无效的参数，这会影响reducer的计算结果。运行combiner的意义在于使map输出更紧凑，使得写到本地磁盘和传给reducer的数据更少。写盘时压缩map输出可以提高效率，因为这样会让写磁盘的速度更快，节约磁盘空间，并且减少传给reducer的数据量。默认情况下，输出是不压缩的，但只要将mapred.compress.map.output设置为true，就可以启用此功能。使用的压缩库库mapred.map.output.compression.codec指定.<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，reducer通过HTTP方式得到输出文件的分区。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;MapReduce 是现今一个非常流行的分布式计算框架，它被设计用于并行计算海量数据。第一个提出该技术框架的是Google 公司，而Google 的灵感则来自于函数式编程语言，如LISP，Scheme，ML 等。&lt;/br&gt;&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;MapReduce 框架的核心步骤主要分两部分：Map 和Reduce。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。&lt;/br&gt;&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Shuffle作为MapReducer的”心脏”，本文主要是对此做一次总结，只对其工作机制进行简单的概要，以便回顾，不涉及代码部分。&lt;/p&gt;
&lt;h2 id=&quot;二、什么是Shuffle&quot;&gt;&lt;a href=&quot;#二、什么是Shuffle&quot; class=&quot;headerlink&quot; title=&quot;二、什么是Shuffle?&quot;&gt;&lt;/a&gt;二、什么是Shuffle?&lt;/h2&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;MapReducer确保每个reducer的输入（也就是map的输出）都按键排序。将map task的输出结果 传给reducer(作为reducer输入) 的过程，称之为shuffle，参考下面这张MapReducer的工作流程机制，这个过程会经历排序和分区。&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/markdownImage/master/Shuffle%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/1.png&quot; alt=&quot;MapReducer执行原理&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://tokerr.github.io/tags/hadoop/"/>
    
      <category term="MapReducer" scheme="https://tokerr.github.io/tags/MapReducer/"/>
    
      <category term="Shuffle" scheme="https://tokerr.github.io/tags/Shuffle/"/>
    
  </entry>
  
  <entry>
    <title>Jquery防止Ajax重复提交解决方案</title>
    <link href="https://tokerr.github.io/2017/10/09/Jquery%E9%98%B2%E6%AD%A2Ajax%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>https://tokerr.github.io/2017/10/09/Jquery防止Ajax重复提交解决方案/</id>
    <published>2017-10-09T15:15:34.000Z</published>
    <updated>2019-05-01T13:51:07.474Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h3><p>不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。</p><h2 id="二、直接上代码"><a href="#二、直接上代码" class="headerlink" title="二、直接上代码"></a>二、直接上代码</h2><pre><code>/*** jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理*/$(function(){var pendingRequests = {};// 所有ajax请求的通用前置filter$.ajaxPrefilter(function( options, originalOptions, jqXHR ) {var key = generatePendingRequestKey(options);</code></pre><a id="more"></a>    <pre><code>//请求是否已经存在if(!pendingRequests[key]){storePendingRequest(key,jqXHR);}else{//如果ajax请求已经存在，下一次相同的请求则取消，防止重复请求jqXHR.abort();}//ajax请求完成时，从临时对象中清除请求对应的数据var complete = options.complete;options.complete = function(jqXHR, textStatus) {//延时1000毫秒删除请求信息，表示同Key值请求不能在此时间段内重复提交setTimeout(function(){delete pendingRequests[jqXHR.pendingRequestKey];},1000);if ($.isFunction(complete)) {complete.apply(this, arguments);}};//统一的错误处理var error = options.error;options.error = function(jqXHR, textStatus) {errorHandler(jqXHR, textStatus);if ($.isFunction(error)) {error.apply(this, arguments);}};});/*** 当ajax请求发生错误时，统一进行拦截处理的方法*/function errorHandler(jqXHR, textStatus){switch (jqXHR.status){case(500):internalError(jqXHR);break;case(403):accessDenied(jqXHR);break;case(408):timeoutError(jqXHR);break;case(404):pageNotFound(jqXHR);break;default://otherError(jqXHR, textStatus);}}function pageNotFound(jqXHR){Component.warningMessageBox({content:&quot;请求访问的地址或内容不存在！&quot;});}function accessDenied(jqXHR){Component.warningMessageBox({content:&quot;你无权进行此操作或页面访问！&quot;});}function internalError(jqXHR){Component.warningMessageBox({content:&quot;服务器存在错误，未能正确处理你的请求！&quot;});}function timeoutError(jqXHR){window.location.href=contextPath + &quot;/j_spring_security_logout&quot;;}function otherError(jqXHR, textStatus){Component.warningMessageBox({content:&quot;未知错误，错误代码：&quot; + textStatus});}/*** 将ajax请求存储到临时对象中，用于根据key判断请求是否已经存在*/function storePendingRequest(key, jqXHR){pendingRequests[key] = jqXHR;jqXHR.pendingRequestKey = key;}/*** 根据ajax请求参数构建一个临时存储key,此处简单的使用url作为key，* 不考虑为解决请求类型为get时相同路径引起的缓存问题，采用随机码构建URL的情况*/function generatePendingRequestKey(options){return options.url;}});</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h3&gt;&lt;p&gt;不同于全页面刷新的表单提交，以下方法通过jquery实现ajax的防止重复提交。&lt;/p&gt;
&lt;h2 id=&quot;二、直接上代码&quot;&gt;&lt;a href=&quot;#二、直接上代码&quot; class=&quot;headerlink&quot; title=&quot;二、直接上代码&quot;&gt;&lt;/a&gt;二、直接上代码&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;/**
* jquery ajax请求过滤，防止ajax请求重复发送，对ajax发送错误时进行统一处理
*/
$(function(){
var pendingRequests = {};
// 所有ajax请求的通用前置filter
$.ajaxPrefilter(function( options, originalOptions, jqXHR ) {
var key = generatePendingRequestKey(options);
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="jquery" scheme="https://tokerr.github.io/tags/jquery/"/>
    
      <category term="ajax" scheme="https://tokerr.github.io/tags/ajax/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot – JSP View Example</title>
    <link href="https://tokerr.github.io/2017/08/16/Spring-Boot-%E2%80%93-JSP-View-Example/"/>
    <id>https://tokerr.github.io/2017/08/16/Spring-Boot-–-JSP-View-Example/</id>
    <published>2017-08-16T14:51:30.000Z</published>
    <updated>2019-05-01T13:51:07.475Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Learn-to-create-and-configure-spring-boot-application-which-uses-JSP-template-files-to-render-view-layer-It-uses-embedded-Tomcat-server-to-run-the-application"><a href="#Learn-to-create-and-configure-spring-boot-application-which-uses-JSP-template-files-to-render-view-layer-It-uses-embedded-Tomcat-server-to-run-the-application" class="headerlink" title="Learn to create and configure spring boot application which uses JSP template files to render view layer. It uses embedded Tomcat server to run the application."></a>Learn to create and configure spring boot application which uses JSP template files to render view layer. It uses embedded Tomcat server to run the application.</h4><h2 id="Sourcecode-Structure"><a href="#Sourcecode-Structure" class="headerlink" title="Sourcecode Structure"></a>Sourcecode Structure</h2><p>The files in this application are placed as given structure in image.<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Spring%20Boot%20%E2%80%93%20JSP%20View%20Example/1.png" alt="Spring Boot Application Structure"></p><h2 id="Maven-dependencies-–-pom-xml"><a href="#Maven-dependencies-–-pom-xml" class="headerlink" title="Maven dependencies – pom.xml"></a>Maven dependencies – pom.xml</h2><p>This application uses given below dependencies.<br><a id="more"></a><br>    <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemalocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"><br>        <modelversion>4.0.0</modelversion><br>        <groupid>com.howtodoinjava</groupid><br>        <artifactid>spring-boot-demo</artifactid><br>        <packaging>war</packaging><br>        <version>0.0.1-SNAPSHOT</version><br>        <name>spring-boot-demo Maven Webapp</name><br>        <url><a href="http://maven.apache.org" target="_blank" rel="external">http://maven.apache.org</a></url><br>        <parent><br>            <groupid>org.springframework.boot</groupid><br>            <artifactid>spring-boot-starter-parent</artifactid><br>            <version>1.5.1.RELEASE</version><br>        </parent><br>        <properties><br>            <java.version>1.8</java.version><br>        </properties><br>        <dependencies><br>            <!-- Web --><br>            <dependency><br>                <groupid>org.springframework.boot</groupid><br>                <artifactid>spring-boot-starter-web</artifactid><br>            </dependency><br>            <!-- Tomcat Embed --><br>            <dependency><br>                <groupid>org.springframework.boot</groupid><br>                <artifactid>spring-boot-starter-tomcat</artifactid><br>                <scope>provided</scope><br>            </dependency><br>            <!-- JSTL --><br>            <dependency><br>                <groupid>javax.servlet</groupid><br>                <artifactid>jstl</artifactid><br>            </dependency><br>            <!-- To compile JSP files --><br>            <dependency><br>                <groupid>org.apache.tomcat.embed</groupid><br>                <artifactid>tomcat-embed-jasper</artifactid><br>                <scope>provided</scope><br>            </dependency><br>        </dependencies><br>    </project></p><h2 id="Spring-Boot-Application-Initializer"><a href="#Spring-Boot-Application-Initializer" class="headerlink" title="Spring Boot Application Initializer"></a>Spring Boot Application Initializer</h2><p>The first step in producing a deployable war file is to provide a SpringBootServletInitializer subclass and override its configure() method. This makes use of Spring Framework’s Servlet 3.0 support and allows you to configure your application when it’s launched by the servlet container.</p><pre><code>package com.howtodoinjava.app.controller;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.web.support.SpringBootServletInitializer;@SpringBootApplicationpublic class SpringBootWebApplication extends SpringBootServletInitializer {    @Override    protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {        return application.sources(SpringBootWebApplication.class);    }    public static void main(String[] args) throws Exception {        SpringApplication.run(SpringBootWebApplication.class, args);    }}</code></pre><h2 id="Spring-Controller"><a href="#Spring-Controller" class="headerlink" title="Spring Controller"></a>Spring Controller</h2><p>Controller classes can have methods mapped to specific URLs in the application. In given application, it has two views i.e. “/” and “/next”.</p><pre><code>package com.howtodoinjava.app.controller;import java.util.Map;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class IndexController {    @RequestMapping(&quot;/&quot;)    public String home(Map&lt;String, Object&gt; model) {        model.put(&quot;message&quot;, &quot;HowToDoInJava Reader !!&quot;);        return &quot;index&quot;;    }    @RequestMapping(&quot;/next&quot;)    public String next(Map&lt;String, Object&gt; model) {        model.put(&quot;message&quot;, &quot;You are in new page !!&quot;);        return &quot;next&quot;;    }}</code></pre><h2 id="Configure-JSP-View-Resolver"><a href="#Configure-JSP-View-Resolver" class="headerlink" title="Configure JSP View Resolver"></a>Configure JSP View Resolver</h2><p>To resolve JSP files location, you can have two approaches.</p><h3 id="1-Add-entries-in-application-properties"><a href="#1-Add-entries-in-application-properties" class="headerlink" title="1) Add entries in application.properties"></a>1) Add entries in application.properties</h3><pre><code>spring.mvc.view.prefix=/WEB-INF/view/spring.mvc.view.suffix=.jsp//For detailed logging during developmentlogging.level.org.springframework=TRACElogging.level.com=TRACE</code></pre><h3 id="2-Configure-InternalResourceViewResolver"><a href="#2-Configure-InternalResourceViewResolver" class="headerlink" title="2) Configure InternalResourceViewResolver"></a>2) Configure InternalResourceViewResolver</h3><pre><code>package com.howtodoinjava.app.controller;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.ViewResolverRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import org.springframework.web.servlet.view.InternalResourceViewResolver;import org.springframework.web.servlet.view.JstlView;@Configuration@EnableWebMvc@ComponentScanpublic class MvcConfiguration extends WebMvcConfigurerAdapter{    @Override    public void configureViewResolvers(ViewResolverRegistry registry) {        InternalResourceViewResolver resolver = new InternalResourceViewResolver();        resolver.setPrefix(&quot;/WEB-INF/view/&quot;);        resolver.setSuffix(&quot;.jsp&quot;);        resolver.setViewClass(JstlView.class);        registry.viewResolver(resolver);    }}</code></pre><h2 id="JSP-Files"><a href="#JSP-Files" class="headerlink" title="JSP Files"></a>JSP Files</h2><h3 id="index-jsp"><a href="#index-jsp" class="headerlink" title="index.jsp"></a>index.jsp</h3><pre><code>&lt;!DOCTYPE html&gt;&lt;%@ taglib prefix=&quot;spring&quot; uri=&quot;http://www.springframework.org/tags&quot;%&gt;&lt;html lang=&quot;en&quot;&gt;&lt;body&gt;    &lt;div&gt;        &lt;div&gt;            &lt;h1&gt;Spring Boot JSP Example&lt;/h1&gt;            &lt;h2&gt;Hello ${message}&lt;/h2&gt;            Click on this &lt;strong&gt;&lt;a href=&quot;next&quot;&gt;link&lt;/a&gt;&lt;/strong&gt; to visit another page.        &lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="next-jsp"><a href="#next-jsp" class="headerlink" title="next.jsp"></a>next.jsp</h3><pre><code>&lt;!DOCTYPE html&gt;&lt;%@ taglib prefix=&quot;spring&quot; uri=&quot;http://www.springframework.org/tags&quot;%&gt;&lt;html lang=&quot;en&quot;&gt;&lt;body&gt;    &lt;div&gt;        &lt;div&gt;            &lt;h1&gt;Another page&lt;/h1&gt;            &lt;h2&gt;Hello ${message}&lt;/h2&gt;            Click on this &lt;strong&gt;&lt;a href=&quot;/&quot;&gt;link&lt;/a&gt;&lt;/strong&gt; to visit previous page.        &lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="Run-the-application"><a href="#Run-the-application" class="headerlink" title="Run the application"></a>Run the application</h2><p>After whole code is written and placed inside folders, run the application by executing <code>main()</code> method in <code>SpringBootWebApplication</code> class.</p><p><strong>Now hit the URL: <a href="http://localhost:8080/" target="_blank" rel="external">http://localhost:8080/</a></strong><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Spring%20Boot%20%E2%80%93%20JSP%20View%20Example/2.png" alt="Spring Boot Application – index"></p><p><strong>Click next link</strong></p><p><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/Spring%20Boot%20%E2%80%93%20JSP%20View%20Example/3.png" alt="Spring Boot Application – next"></p><h2 id="Spring-Boot-JSP-example-Source-Code"><a href="#Spring-Boot-JSP-example-Source-Code" class="headerlink" title="Spring Boot JSP example Source Code"></a>Spring Boot JSP example Source Code</h2><p>Download the sourcecode of this application with below ink.<br><a href="https://raw.githubusercontent.com/tokerr/markdownImage/master/Spring%20Boot%20–%20JSP%20View%20Example/spring-boot-demo-jsp-example.zip" target="_blank" rel="external">Download Source Code</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Learn-to-create-and-configure-spring-boot-application-which-uses-JSP-template-files-to-render-view-layer-It-uses-embedded-Tomcat-server-to-run-the-application&quot;&gt;&lt;a href=&quot;#Learn-to-create-and-configure-spring-boot-application-which-uses-JSP-template-files-to-render-view-layer-It-uses-embedded-Tomcat-server-to-run-the-application&quot; class=&quot;headerlink&quot; title=&quot;Learn to create and configure spring boot application which uses JSP template files to render view layer. It uses embedded Tomcat server to run the application.&quot;&gt;&lt;/a&gt;Learn to create and configure spring boot application which uses JSP template files to render view layer. It uses embedded Tomcat server to run the application.&lt;/h4&gt;&lt;h2 id=&quot;Sourcecode-Structure&quot;&gt;&lt;a href=&quot;#Sourcecode-Structure&quot; class=&quot;headerlink&quot; title=&quot;Sourcecode Structure&quot;&gt;&lt;/a&gt;Sourcecode Structure&lt;/h2&gt;&lt;p&gt;The files in this application are placed as given structure in image.&lt;br&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tokerr/markdownImage/master/Spring%20Boot%20%E2%80%93%20JSP%20View%20Example/1.png&quot; alt=&quot;Spring Boot Application Structure&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Maven-dependencies-–-pom-xml&quot;&gt;&lt;a href=&quot;#Maven-dependencies-–-pom-xml&quot; class=&quot;headerlink&quot; title=&quot;Maven dependencies – pom.xml&quot;&gt;&lt;/a&gt;Maven dependencies – pom.xml&lt;/h2&gt;&lt;p&gt;This application uses given below dependencies.&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="springboot" scheme="https://tokerr.github.io/tags/springboot/"/>
    
      <category term="jsp" scheme="https://tokerr.github.io/tags/jsp/"/>
    
  </entry>
  
  <entry>
    <title>对赋值语句中short类型转换的理解[转]</title>
    <link href="https://tokerr.github.io/2017/07/05/%E5%AF%B9%E8%B5%8B%E5%80%BC%E8%AF%AD%E5%8F%A5%E4%B8%ADshort%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>https://tokerr.github.io/2017/07/05/对赋值语句中short类型转换的理解/</id>
    <published>2017-07-05T04:38:02.000Z</published>
    <updated>2019-12-01T07:54:58.639Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、问题的提出"><a href="#一、问题的提出" class="headerlink" title="一、问题的提出"></a>一、问题的提出</h2><p>有这么几个赋值语句：</p><pre><code>1. short b = 1;2. short b = 1; ++b;3. short b = 1; b+=1;4. short b = 1; b = b + 1;</code></pre><p>前三段代码没问题，最后一段代码编译器会报错：cannot convert from int to short<br><a id="more"></a></p><h2 id="二、问题的分析与解答"><a href="#二、问题的分析与解答" class="headerlink" title="二、问题的分析与解答"></a>二、问题的分析与解答</h2><p>我之前学过C，C标准规定，整数常量的类型是能容纳该整数的最小类型。所以在C中，b=b+1是不会报错的。Java不一样，Java语言规范明确说：整数常量如果末尾带L是long类型，不带L则是int类型(An integer literal is of type long if it is suffixed with an ASCII letter L or l (ell); otherwise it is of type int )。所以1是int类型，b+1的结果是int类型，而b是short类型，int赋值给short又没有经过强转就会报错。按这个思路，++和+＝为啥不报错？有人说++和+＝会自动强转。好，我先接受这个说法。那么b＝1为什么也不报错？</p><p>带着困惑，我又去查了Java语言规范。Java把short、byte提升到int这种情况称为<strong>widening conversion</strong>，把int转为short或byte这种情况称为<strong>narrowing conversion</strong>。在赋值时，Java要求赋值=右边的类型必须被转为＝左边的类型。Java会自动执行5种转换，其中有widening conversion而没有narrowing conversion。所以， 上面第4段代码中b=b+1的右边是int，Java不会自动转为short，于是造成＝左右类型不一致，报错。</p><p>好，问题来了：<br><br><strong>short b=1 、++b 和 b+=1也有int转short的情况，为什么不报错？答案只能是：它们属于特殊情况。</strong></p><p>对于short b = 1 Java语言规范说：如果＝的右边是常量表达式，而且类型是byte、short、char或int，那么Java在必要时会自动执行narrowing conversion，只要这个<strong>常量表达式的值在＝左边,并且变量的取值范围之内</strong>(if the expression is a constant expression  of type byte, short, char, or int: A narrowing primitive conversion may be used if the type of the variable is byte, short, or char, and the value of the constant expression is representable in the type of the variable) 哦，原来如此！short b = 1; 1是常量表达式，类型是int，且在short的取值范围之内，所以Java自动强转，不会报错。但如果你写short b=200000，200000虽然是常量，但超过short取值范围，照样报错。 </p><p>对于++， Java语言规范说：如有必要，++计算之后的结果会先执行narrowing conversion，再存入变量中（If necessary, the sum is narrowed by a narrowing primitive conversion  and/or subjected to boxing conversion (§5.1.7) to the type of the variable before it is stored）。也就是说，虽然b是short类型，但Java在++运算上的自动强转保证了++b不会报错<br>同样，对于+=Java也会自动强转。对于b+＝1，Java会转成b = (short)(b+1)</p><p>因为之前受C语言的影响，这两天看到相关帖子，搞得我云里雾里。查了Java语言规范，总算是搞清楚了，发出来和大家分享一下。</p><p><a href="http://bbs.itheima.com/thread-127149-1-1.html" title="原文连接" target="_blank" rel="external">原文连接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、问题的提出&quot;&gt;&lt;a href=&quot;#一、问题的提出&quot; class=&quot;headerlink&quot; title=&quot;一、问题的提出&quot;&gt;&lt;/a&gt;一、问题的提出&lt;/h2&gt;&lt;p&gt;有这么几个赋值语句：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. short b = 1;
2. short b = 1; ++b;
3. short b = 1; b+=1;
4. short b = 1; b = b + 1;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;前三段代码没问题，最后一段代码编译器会报错：cannot convert from int to short&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>子查询的方式实现sql语句的先排序后分组</title>
    <link href="https://tokerr.github.io/2017/06/22/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/"/>
    <id>https://tokerr.github.io/2017/06/22/子查询的方式实现sql语句的先排序后分组/</id>
    <published>2017-06-22T13:18:36.000Z</published>
    <updated>2019-05-01T13:51:07.479Z</updated>
    
    <content type="html"><![CDATA[<h3 id="需求："><a href="#需求：" class="headerlink" title="需求："></a>需求：</h3><p>查询学生表当中每一门课程成绩最高的记录。</p><h3 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h3><p>先按分数对记录进行降序，然后按照课程进行分组即可实现。<br><a id="more"></a><br>Student表结构：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/1.png" alt=""></p><p>现在手动添加如下数据进去：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/2.png" alt=""></p><p>起初，按照原来的思路，我编写的sql语句如下图(第一句)，得到的结果却不是我们想要的，可以看到group by字句先于Order by执行了，效果如图(下一部分)：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/3.png" alt=""></p><p>因此，使用子查询的方式先对数据进行降序，对新的结果集给一个别名，然后再按课程进行分组，如下：<br><br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AD%90%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0sql%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%85%88%E6%8E%92%E5%BA%8F%E5%90%8E%E5%88%86%E7%BB%84/4.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;需求：&quot;&gt;&lt;a href=&quot;#需求：&quot; class=&quot;headerlink&quot; title=&quot;需求：&quot;&gt;&lt;/a&gt;需求：&lt;/h3&gt;&lt;p&gt;查询学生表当中每一门课程成绩最高的记录。&lt;/p&gt;
&lt;h3 id=&quot;思路：&quot;&gt;&lt;a href=&quot;#思路：&quot; class=&quot;headerlink&quot; title=&quot;思路：&quot;&gt;&lt;/a&gt;思路：&lt;/h3&gt;&lt;p&gt;先按分数对记录进行降序，然后按照课程进行分组即可实现。&lt;br&gt;
    
    </summary>
    
    
      <category term="sql" scheme="https://tokerr.github.io/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>JVM加载class文件的原理机制[转]</title>
    <link href="https://tokerr.github.io/2017/06/07/JVM%E5%8A%A0%E8%BD%BDclass%E6%96%87%E4%BB%B6%E7%9A%84%E5%8E%9F%E7%90%86%E6%9C%BA%E5%88%B6-%E8%BD%AC/"/>
    <id>https://tokerr.github.io/2017/06/07/JVM加载class文件的原理机制-转/</id>
    <published>2017-06-07T13:56:54.000Z</published>
    <updated>2019-05-01T13:51:07.473Z</updated>
    
    <content type="html"><![CDATA[<p>JVM加载class文件的原理机制</p><h2 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h2><p>当执行 java <em>*</em>.class 的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。</p><h2 id="二、JVM-简介"><a href="#二、JVM-简介" class="headerlink" title="二、JVM 简介"></a>二、JVM 简介</h2><p>是我们Javase 的最基本功底了，刚开始学Java 的时候，一般都是从“Hello World ”开始的，然后会写个复杂点class ，然后再找一些开源框架，比如Spring ，Hibernate 等等，再然后就开发企业级的应用，比如网站、企业内部应用、实时交易系统等等，直到某一天突然发现做的系统咋就这么慢呢，而且时不时还来个内存溢出什么的，今天是交易系统报了StackOverflowError ，明天是网站系统报了个OutOfMemoryError ，这种错误又很难重现，只有分析Javacore 和dump 文件，运气好点还能分析出个结果，运行遭的点，就直接去庙里烧香吧！每天接客户的电话都是战战兢兢的，生怕再出什么幺蛾子了。我想Java 做的久一点的都有这样的经历，那这些问题的最终根结是在哪呢？—— JVM 。</p><p>JVM 全称是Java Virtual Machine ，Java 虚拟机，也就是在计算机上再虚拟一个计算机，这和我们使用 VMWare不一样，那个虚拟的东西你是可以看到的，这个JVM 你是看不到的，它存在内存中。我们知道计算机的基本构成是：运算器、控制器、存储器、输入和输出设备，那这个JVM 也是有这成套的元素，运算器是当然是交给硬件CPU 还处理了，只是为了适应“一次编译，随处运行”的情况，需要做一个翻译动作，于是就用了JVM 自己的命令集，这与汇编的命令集有点类似，每一种汇编命令集针对一个系列的CPU ，比如8086 系列的汇编也是可以用在8088 上的，但是就不能跑在8051 上，而JVM 的命令集则是可以到处运行的，因为JVM 做了翻译，根据不同的CPU ，翻译成不同的机器语言。</p><p>JVM 中我们最需要深入理解的就是它的存储部分，存储？硬盘？NO ，NO ， JVM 是一个内存中的虚拟机，那它的存储就是内存了，我们写的所有类、常量、变量、方法都在内存中，这决定着我们程序运行的是否健壮、是否高效，接下来的部分就是重点介绍之一。<br><a id="more"></a></p><h2 id="三、JVM-的组成部分"><a href="#三、JVM-的组成部分" class="headerlink" title="三、JVM 的组成部分"></a>三、JVM 的组成部分</h2><p>我们先把JVM 这个虚拟机画出来，如下图所示：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/JVM%E5%8A%A0%E8%BD%BDclass%E6%96%87%E4%BB%B6%E7%9A%84%E5%8E%9F%E7%90%86%E6%9C%BA%E5%88%B6-%E8%BD%AC/1.png" alt=""></p><p>从这个图中可以看到，JVM 是运行在操作系统之上的，它与硬件没有直接的交互。我们再来看下JVM 有哪些组成部分，如下图所示：<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/JVM%E5%8A%A0%E8%BD%BDclass%E6%96%87%E4%BB%B6%E7%9A%84%E5%8E%9F%E7%90%86%E6%9C%BA%E5%88%B6-%E8%BD%AC/2.png" alt=""></p><p>该图参考了网上广为流传的JVM 构成图，大家看这个图，整个JVM 分为四部分：</p><h3 id="Class-Loader-类加载器"><a href="#Class-Loader-类加载器" class="headerlink" title="Class Loader 类加载器"></a>Class Loader 类加载器</h3><p>类加载器的作用是加载类文件到内存，比如编写一个HelloWord.java 程序，然后通过javac 编译成class 文件，那怎么才能加载到内存中被执行呢？Class Loader 承担的就是这个责任，那不可能随便建立一个.class 文件就能被加载的，Class Loader 加载的class 文件是有格式要求，在《JVM Specification 》中式这样定义Class 文件的结构：</p><pre><code>ClassFile {  u4 magic;  u2 minor_version;   u2 major_version;  u2 constant_pool_count;  cp_info constant_pool[constant_pool_count-1];  u2 access_flags;  u2 this_class;  u2 super_class;  u2 interfaces_count;  u2 interfaces[interfaces_count];  u2 fields_count;  field_info fields[fields_count];  u2 methods_count;  method_info methods[methods_count];  u2 attributes_count;  attribute_info attributes[attributes_count];}</code></pre><p>需要详细了解的话，可以仔细阅读《JVM Specification 》的第四章“The class File Format ”，这里不再详细说明。<br>友情提示：Class Loader 只管加载，只要符合文件结构就加载，至于说能不能运行，则不是它负责的，那是由Execution Engine 负责的。</p><h3 id="Execution-Engine-执行引擎"><a href="#Execution-Engine-执行引擎" class="headerlink" title="Execution Engine 执行引擎"></a>Execution Engine 执行引擎</h3><p>执行引擎也叫做解释器(Interpreter) ，负责解释命令，提交操作系统执行。</p><h3 id="Native-Interface-本地接口"><a href="#Native-Interface-本地接口" class="headerlink" title="Native Interface 本地接口"></a>Native Interface 本地接口</h3><p>本地接口的作用是融合不同的编程语言为Java 所用，它的初衷是融合C/C++ 程序，Java 诞生的时候是C/C++ 横行的时候，要想立足，必须有一个聪明的、睿智的调用C/C++ 程序，于是就在内存中专门开辟了一块区域处理标记为native 的代码，它的具体做法是Native Method Stack 中登记native 方法，在Execution Engine 执行时加载native libraies 。目前该方法使用的是越来越少了，除非是与硬件有关的应用，比如通过Java 程序驱动打印机，或者Java 系统管理生产设备，在企业级应用中已经比较少见，因为现在的异构领域间的通信很发达，比如可以使用Socket 通信，也可以使用Web Service 等等，不多做介绍。</p><h3 id="Runtime-data-area-运行数据区"><a href="#Runtime-data-area-运行数据区" class="headerlink" title="Runtime data area 运行数据区"></a>Runtime data area 运行数据区</h3><p>运行数据区是整个JVM 的重点。我们所有写的程序都被加载到这里，之后才开始运行，Java 生态系统如此的繁荣，得益于该区域的优良自治，下一章节详细介绍之。</p><p>&emsp;&emsp;整个JVM 框架由加载器加载文件，然后执行器在内存中处理数据，需要与异构系统交互是可以通过本地接口进行，瞧，一个完整的系统诞生了！</p><h2 id="三、JVM加载class文件的原理机制"><a href="#三、JVM加载class文件的原理机制" class="headerlink" title="三、JVM加载class文件的原理机制"></a>三、JVM加载class文件的原理机制</h2><ol><li>Java中的所有类，必须被装载到jvm中才能运行，这个装载工作是由jvm中的类装载器完成的,类装载器所做的工作实质是把类文件从硬盘读取到内存中 </li></ol><ol><li>java中的类大致分为三种：<br><br> 1.系统类 <br><br> 2.扩展类 <br><br> 3.由程序员自定义的类 <br></li></ol><ol><li>类装载方式，有两种 <br><br> 1.隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中<br><br> 2.显式装载， 通过class.forname()等方法，显式加载需要的类<br><br>隐式加载与显式加载的区别，两者本质是一样? </li></ol><ol><li>类加载的动态性体现 <br><br>&emsp;&emsp;一个应用程序总是由n多个类组成，Java程序启动时，并不是一次把所有的类全部加载后再运行，它总是先把保证程序运行的基础类一次性加载到jvm中，其它类等到jvm用到的时候再加载，这样的好处是节省了内存的开销，因为java最早就是为嵌入式系统而设计的，内存宝贵，这是一种可以理解的机制，而用到时再加载这也是java动态性的一种体现 </li></ol><ol><li><p>java类装载器 <br><br>Java中的类装载器实质上也是类，功能是把类载入jvm中，值得注意的是jvm的类装载器并不是一个，而是三个，层次结构如下：<br> </p><p> Bootstrap Loader  - 负责加载系统类 <br><br> &emsp;&emsp;&emsp;&emsp;| <br><br> &emsp;&emsp;- - ExtClassLoader  - 负责加载扩展类<br><br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; | <br><br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;- - AppClassLoader  - 负责加载应用类<br>  </p><p> &emsp;&emsp;为什么要有三个类加载器，一方面是分工，各自负责各自的区块，另一方面为了实现委托模型，下面会谈到该模型 </p></li></ol><ol><li>类加载器之间是如何协调工作的<br>&emsp;&emsp;前面说了，java中有三个类加载器，问题就来了，碰到一个类需要加载时，它们之间是如何协调工作的，即java是如何区分一个类该由哪个类加载器来完成呢。<br><br>&emsp;&emsp;在这里java采用了委托模型机制，这个机制简单来讲，就是“类装载器有载入类的需求时，会先请示其Parent使用其搜索路径帮忙载入，如果Parent 找不到,那么才由自己依照自己的搜索路径搜索类”，注意喔，这句话具有递归性</li></ol><p>Java代码  </p><pre><code>1. /**  2.  * @author Jamson Huang  3.  *  4.  */   5. public   class  TestClass {  6.   7.     /**  8.      * @param args  9.      */   10.     public   static   void  main(String[] args)   throws  Exception{  11.         //调用class加载器   12.         ClassLoader cl = TestClass.class .getClassLoader();  13.         System.out.println(cl);  14.         //调用上一层Class加载器   15.         ClassLoader clParent = cl.getParent();  16.         System.out.println(clParent);  17.         //调用根部Class加载器   18.         ClassLoader clRoot = clParent.getParent();  19.         System.out.println(clRoot);  20.           21.     }  22.   23. }  </code></pre><p>Result代码  </p><pre><code>1. Run， Console中出现的log信息如下：  2. sun.misc.Launcher$AppClassLoader@7259da  3. sun.misc.Launcher$ExtClassLoader@16930e2  4. null  </code></pre><p>&emsp;&emsp;可以看出TestClass是由AppClassLoader加载器加载的AppClassLoader的Parent 加载器是ExtClassLoader但是ExtClassLoader的Parent为 null 是怎么回事呵，朋友们留意的话，前面有提到Bootstrap Loader是用C++语言写的,依java的观点来看，逻辑上并不存在Bootstrap Loader的类实体，所以在java程序代码里试图打印出其内容时，我们就会看到输出为null <br><br><em>【注：以下内容大部分引用java深度历险】</em> <br><br>&emsp;&emsp;弄明白了上面的示例，接下来直接进入类装载的委托模型实例，写两个文件，如下：<br><br>Java代码  </p><pre><code>1. /**  2.  * @author Jamson Huang  3.  *  4.  */   5. public   class  Test1 {  6.   7.     /**  8.      * @param args  9.      */   10.     public   static   void  main(String[] args) throws  Exception {  11.         System.out.println(Test1.class .getClassLoader());  12.           13.         Test2 test2 = new  Test2();  14.           15.         test2.print();  16.     }  17.   18. }  19. /**  20.  * @author Jamson Huang  21.  *  22.  */   23. public   class  Test2 {  24.     public   void  print(){  25.         System.out.println(Test2.class );  26.         System.out.println(this .getClass());  27.         System.out.println(Test2.class .getClassLoader());  28.     }  29. }  </code></pre><p>Result代码  </p><pre><code>1. Run,Console出现log如下：  2. sun.misc.Launcher$AppClassLoader@7259da  3. class com.java.test.Test2  4. class com.java.test.Test2  5. sun.misc.Launcher$AppClassLoader@7259da  </code></pre><ol><li>7.预先加载与依需求加载 </li></ol><p>&emsp;&emsp;Java 运行环境为了优化系统，提高程序的执行速度，在 JRE 运行的开始会将 Java 运行所需要的基本类采用预先加载（ pre-loading ）的方法全部加载要内存当中，因为这些单元在 Java 程序运行的过程当中经常要使用的，主要包括 JRE 的 rt.jar 文件里面所有的 .class 文件。 <br><br>&emsp;&emsp;当 java.exe 虚拟机开始运行以后，它会找到安装在机器上的 JRE 环境，然后把控制权交给 JRE ， JRE 的类加载器会将 lib 目录下的 rt.jar 基础类别文件库加载进内存，这些文件是 Java 程序执行所必须的，所以系统在开始就将这些文件加载，避免以后的多次 IO 操作，从而提高程序执行效率。 </p><p>图（ 2 ）我们可以看到多个基础类被加载,java.lang.Object,java.io.Serializable 等等。<br><br>&emsp;&emsp;相对于预先加载，我们在程序中需要使用自己定义的类的时候就要使用依需求加载方法（ load-on-demand ），就是在 Java 程序需要用到的时候再加载，以减少内存的消耗，因为 Java 语言的设计初衷就是面向嵌入式领域的。 </p><ol><li>8.自定义类加载机制 </li></ol><p>&emsp;&emsp;之前我们都是调用系统的类加载器来实现加载的，其实我们是可以自己定义类加载器的。利用 Java 提供的 java.net.URLClassLoader 类就可以实现。下面我们看一段范例： </p><p>Java代码  </p><pre><code>1. try {   2. URL url = new  URL( &quot;file:/d:/test/lib/&quot; );   3. URLClassLoader urlCL = new  URLClassLoader( new  URL[]{url});   4. Class c = urlCL.loadClass(&quot;TestClassA&quot; );   5. TestClassA object = (TestClassA)c.newInstance();   6. object.method();   7. }catch (Exception e){   8. e.printStackTrace();   9. }   </code></pre><p>&emsp;&emsp;我们通过自定义的类加载器实现了 TestClassA 类的加载并调用 method （）方法。分析一下这个程序：首先定义 URL 指定类加载器从何处加载类， URL 可以指向网际网络上的任何位置，也可以指向我们计算机里的文件系统 ( 包含 JAR 文件 ) 。上述范例当中我们从 file:/d:/test/lib/ 处寻找类；然后定义 URLClassLoader 来加载所需的类，最后即可使用该实例了。 </p><ol><li>9.类加载器的阶层体系 </li></ol><p>讨论了这么多以后，接下来我们仔细研究一下 Java 的类加载器的工作原理： <br><br>当执行 java <em>*</em>.class 的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。<br></p><p>下面的图形可以表示三者之间的关系： <br><br>BootstrapLoader &lt;—(Extends)—-AppClassLoader &lt;—(Extends)—-ExtClassLoader<br> </p><p>这三个加载器就构成我们的 Java 类加载体系。他们分别从以下的路径寻找程序所需要的类： <br></p><p>BootstrapLoader ： sun.boot.class.path <br><br>ExtClassLoader: java.ext.dirs <br><br>AppClassLoader: java.class.path <br></p><p>这三个系统参量可以通过 System.getProperty() 函数得到具体对应的路径。大家可以自己编程实现查看具体的路径。</p><p><a href="http://samuschen.iteye.com/blog/1119539" target="_blank" rel="external">原文连接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;JVM加载class文件的原理机制&lt;/p&gt;
&lt;h2 id=&quot;一、摘要&quot;&gt;&lt;a href=&quot;#一、摘要&quot; class=&quot;headerlink&quot; title=&quot;一、摘要&quot;&gt;&lt;/a&gt;一、摘要&lt;/h2&gt;&lt;p&gt;当执行 java &lt;em&gt;*&lt;/em&gt;.class 的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。&lt;/p&gt;
&lt;h2 id=&quot;二、JVM-简介&quot;&gt;&lt;a href=&quot;#二、JVM-简介&quot; class=&quot;headerlink&quot; title=&quot;二、JVM 简介&quot;&gt;&lt;/a&gt;二、JVM 简介&lt;/h2&gt;&lt;p&gt;是我们Javase 的最基本功底了，刚开始学Java 的时候，一般都是从“Hello World ”开始的，然后会写个复杂点class ，然后再找一些开源框架，比如Spring ，Hibernate 等等，再然后就开发企业级的应用，比如网站、企业内部应用、实时交易系统等等，直到某一天突然发现做的系统咋就这么慢呢，而且时不时还来个内存溢出什么的，今天是交易系统报了StackOverflowError ，明天是网站系统报了个OutOfMemoryError ，这种错误又很难重现，只有分析Javacore 和dump 文件，运气好点还能分析出个结果，运行遭的点，就直接去庙里烧香吧！每天接客户的电话都是战战兢兢的，生怕再出什么幺蛾子了。我想Java 做的久一点的都有这样的经历，那这些问题的最终根结是在哪呢？—— JVM 。&lt;/p&gt;
&lt;p&gt;JVM 全称是Java Virtual Machine ，Java 虚拟机，也就是在计算机上再虚拟一个计算机，这和我们使用 VMWare不一样，那个虚拟的东西你是可以看到的，这个JVM 你是看不到的，它存在内存中。我们知道计算机的基本构成是：运算器、控制器、存储器、输入和输出设备，那这个JVM 也是有这成套的元素，运算器是当然是交给硬件CPU 还处理了，只是为了适应“一次编译，随处运行”的情况，需要做一个翻译动作，于是就用了JVM 自己的命令集，这与汇编的命令集有点类似，每一种汇编命令集针对一个系列的CPU ，比如8086 系列的汇编也是可以用在8088 上的，但是就不能跑在8051 上，而JVM 的命令集则是可以到处运行的，因为JVM 做了翻译，根据不同的CPU ，翻译成不同的机器语言。&lt;/p&gt;
&lt;p&gt;JVM 中我们最需要深入理解的就是它的存储部分，存储？硬盘？NO ，NO ， JVM 是一个内存中的虚拟机，那它的存储就是内存了，我们写的所有类、常量、变量、方法都在内存中，这决定着我们程序运行的是否健壮、是否高效，接下来的部分就是重点介绍之一。&lt;br&gt;
    
    </summary>
    
    
      <category term="jvm" scheme="https://tokerr.github.io/tags/jvm/"/>
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="javase" scheme="https://tokerr.github.io/tags/javase/"/>
    
      <category term="java虚拟机" scheme="https://tokerr.github.io/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>实现Set或者List集合的升(降)排序（实现Comparator接口的方式）</title>
    <link href="https://tokerr.github.io/2017/06/06/%E5%AE%9E%E7%8E%B0Set%E6%88%96%E8%80%85List%E9%9B%86%E5%90%88%E7%9A%84%E5%8D%87-%E9%99%8D-%E6%8E%92%E5%BA%8F%EF%BC%88%E5%AE%9E%E7%8E%B0Comparable%E6%8E%A5%E5%8F%A3%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%89/"/>
    <id>https://tokerr.github.io/2017/06/06/实现Set或者List集合的升-降-排序（实现Comparable接口的方式）/</id>
    <published>2017-06-06T15:01:38.000Z</published>
    <updated>2019-05-01T13:51:07.480Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、知识储备"><a href="#一、知识储备" class="headerlink" title="一、知识储备"></a>一、知识储备</h3><h4 id="实现集合排序的两种方式："><a href="#实现集合排序的两种方式：" class="headerlink" title="实现集合排序的两种方式："></a>实现集合排序的两种方式：</h4><p>实现集合的排序有两种方式，下面以TreeSet集合为例:</p><p>方式一：元素自身具备比较性<br>元素自身具备比较性，需要元素实现Comparable接口，重写compareTo方法，也就是让元素自身具备比较性，这种方式叫做元素的自然排序也叫做默认排序。</p><p>方式二：容器具备比较性<br>当元素自身不具备比较性，或者自身具备的比较性不是所需要的。那么此时可以让容器自身具备。需要定义一个类实现接口Comparator，重写compare方法，并将该接口的子类实例对象作为参数传递给TreeMap集合的构造方法。<br>注意：在重写compareTo或者compare方法时，必须要明确比较的主要条件相等时要比较次要条件。（假设姓名和年龄一直的人为相同的人，如果想要对人按照年龄的大小来排序，如果年龄相同的人，需要如何处理？不能直接return 0，因为可能姓名不同（年龄相同姓名不同的人是不同的人）。此时就需要进行次要条件判断（需要判断姓名），只有姓名和年龄同时相等的才可以返回0.）<br>通过return 0来判断唯一性。<br><a id="more"></a></p><h4 id="TreeSet集合"><a href="#TreeSet集合" class="headerlink" title="TreeSet集合"></a>TreeSet集合</h4><p> TreeSet内部是<em>红-黑树</em>的数据结构，默认对元素进行自然排序（String）。如果在比较的时候两个对象返回值为0，那么元素重复。</p><p>红黑树是一种特定类型的二叉树。<br><img src="https://raw.githubusercontent.com/tokerr/markdownImage/master/%E5%AE%9E%E7%8E%B0Set%E6%88%96%E8%80%85List%E9%9B%86%E5%90%88%E7%9A%84%E5%8D%87-%E9%99%8D-%E6%8E%92%E5%BA%8F%EF%BC%88%E5%AE%9E%E7%8E%B0Comparable%E6%8E%A5%E5%8F%A3%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%89/img.png" alt=""></p><p>红黑树算法的规则: 左小右大。<br>既然TreeSet可以自然排序,那么TreeSet必定是有排序规则的。<br>让存入的元素自定义比较规则。</p><h3 id="二、案例演示"><a href="#二、案例演示" class="headerlink" title="二、案例演示"></a>二、案例演示</h3><pre><code>package com.nyt.change;import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.List;import java.util.TreeSet;import org.junit.Test;public class Test3 {    @Test    public  void sortByArrayList() {        User u1 = new User(1, 20);        User u2 = new User(3, 22);        User u3 = new User(4, 26);        User u4 = new User(2, 24);        User u5 = new User(1, 24);        User u6 = new User(2, 24);        List&lt;User&gt; list=new ArrayList&lt;User&gt;();        list.add(u1);        list.add(u2);        list.add(u3);        list.add(u4);        list.add(u5);        list.add(u6);        System.out.println(&quot;======排序之前=======&quot;);        for (User u : list) {            System.out.println(u);        }        //按照id升序，按照age降序(次要条件)        Collections.sort(list,new myComparator());        System.out.println(&quot;======排序之后=======&quot;);        for (User u : list) {            System.out.println(u);        }    }    /**sortByArrayList()运行结果     * ======排序之前=======        User [id=1, age=20]        User [id=3, age=22]        User [id=4, age=26]        User [id=2, age=24]        User [id=1, age=24]        User [id=2, age=24]        ======排序之后=======        User [id=1, age=24]        User [id=1, age=20]        User [id=2, age=24]        User [id=2, age=24]        User [id=3, age=22]        User [id=4, age=26]     *      */    /**     * 使用TreeSet集合排序     * @author tok     *     */    @Test    public void sortByTreeSet(){        TreeSet&lt;User&gt; set=new TreeSet&lt;User&gt;(new myComparator());//        Set&lt;User&gt; set=new TreeSet&lt;User&gt;(new myComparator());        set.add(new User(1, 20));        set.add(new User(3, 22));        set.add(new User(4, 26));        set.add(new User(2, 24));        set.add(new User(2, 24));        set.add(new User(1, 24));        for (User user : set) {            System.out.println(user);        }    }    /**sortByTreeSet()运行结果     *         User [id=1, age=24]        User [id=1, age=20]        User [id=2, age=24]        User [id=3, age=22]        User [id=4, age=26]     * @author Administrator     *     */    class myComparator implements Comparator{        @Override        public int compare(Object o1, Object o2) {            if (!(o1 instanceof User) || !(o2 instanceof User))             return 0;            User u1=(User)o1;            User u2=(User)o2;            /**             * 口诀:正正得正，正负得负，PS:自己体会             * 按照id升序排序             */            if(u1.getId()&lt;u2.getId())//注意两者的大小                return -1;//会按照id进行降序            if(u1.getId()&gt;u2.getId())//注意两者的大小                return 1;//会按照id进行降序            /**             * 按照age降序,次要条件             */            if((u1.getId()==u2.getId())){                if(u1.getAge()&gt;u2.getAge())                    return -1;                if(u1.getAge()&lt;u2.getAge())                    return 1;            }            /**             * 两个对象相等             *///            if(u1.getId()==u2.getId() &amp;&amp; u1.getAge()==u2.getAge())//            return 0;            //否则认为两个对象相等,如果是Set集合将会被过滤掉            return 0;        }    } }</code></pre><h3 id="三、疑惑解答"><a href="#三、疑惑解答" class="headerlink" title="三、疑惑解答"></a>三、疑惑解答</h3><p><strong>问题:</strong>为什么使用TreeSet存入字符串,字符串默认输出是按升序排列的?</p><p>答:<br>1.因为字符串实现了一个接口,叫做Comparable 接口.字符串重写了该接口的compareTo 方法,所以String对象具备了比较性.那么同样道理,我的自定义元素(例如Person类,Book类)想要存入TreeSet集合,就需要实现该接口,也就是要让自定义对象具备比较性.</p><p>2.存入TreeSet集合中的元素要具备比较性.<br>比较性要实现Comparable接口，重写该接口的compareTo方法<br>TreeSet属于Set集合，该集合的元素是不能重复的，TreeSet如何保证元素的唯一性<br>通过compareTo或者compare方法中的来保证元素的唯一性。</p><p>3.添加的元素必须要实现Comparable接口。当compareTo()函数返回值为0时，说明两个对象相等，此时该对象不会添加进来。</p><p>4.当Comparable比较方式，及Comparator比较方式同时存在，以Comparator比较方式为主。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、知识储备&quot;&gt;&lt;a href=&quot;#一、知识储备&quot; class=&quot;headerlink&quot; title=&quot;一、知识储备&quot;&gt;&lt;/a&gt;一、知识储备&lt;/h3&gt;&lt;h4 id=&quot;实现集合排序的两种方式：&quot;&gt;&lt;a href=&quot;#实现集合排序的两种方式：&quot; class=&quot;headerlink&quot; title=&quot;实现集合排序的两种方式：&quot;&gt;&lt;/a&gt;实现集合排序的两种方式：&lt;/h4&gt;&lt;p&gt;实现集合的排序有两种方式，下面以TreeSet集合为例:&lt;/p&gt;
&lt;p&gt;方式一：元素自身具备比较性&lt;br&gt;元素自身具备比较性，需要元素实现Comparable接口，重写compareTo方法，也就是让元素自身具备比较性，这种方式叫做元素的自然排序也叫做默认排序。&lt;/p&gt;
&lt;p&gt;方式二：容器具备比较性&lt;br&gt;当元素自身不具备比较性，或者自身具备的比较性不是所需要的。那么此时可以让容器自身具备。需要定义一个类实现接口Comparator，重写compare方法，并将该接口的子类实例对象作为参数传递给TreeMap集合的构造方法。&lt;br&gt;注意：在重写compareTo或者compare方法时，必须要明确比较的主要条件相等时要比较次要条件。（假设姓名和年龄一直的人为相同的人，如果想要对人按照年龄的大小来排序，如果年龄相同的人，需要如何处理？不能直接return 0，因为可能姓名不同（年龄相同姓名不同的人是不同的人）。此时就需要进行次要条件判断（需要判断姓名），只有姓名和年龄同时相等的才可以返回0.）&lt;br&gt;通过return 0来判断唯一性。&lt;br&gt;
    
    </summary>
    
    
      <category term="java" scheme="https://tokerr.github.io/tags/java/"/>
    
      <category term="集合" scheme="https://tokerr.github.io/tags/%E9%9B%86%E5%90%88/"/>
    
      <category term="Collection" scheme="https://tokerr.github.io/tags/Collection/"/>
    
      <category term="升序，降序" scheme="https://tokerr.github.io/tags/%E5%8D%87%E5%BA%8F%EF%BC%8C%E9%99%8D%E5%BA%8F/"/>
    
      <category term="Set" scheme="https://tokerr.github.io/tags/Set/"/>
    
      <category term="List" scheme="https://tokerr.github.io/tags/List/"/>
    
  </entry>
  
</feed>
